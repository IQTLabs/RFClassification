{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3edf9cdc",
   "metadata": {},
   "source": [
    "## Previous Custom DL method for documentation\n",
    "transferred to archive folder July 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4e062b",
   "metadata": {},
   "source": [
    "### Deep Learning Approaches for RF-based detection & classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df87784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# import the torch packages\n",
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LogSoftmax\n",
    "from torch import flatten\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# import custom functions\n",
    "\n",
    "# module_path = os.path.abspath(os.path.join('..'))\n",
    "# if module_path not in sys.path:\n",
    "#     sys.path.append(module_path)\n",
    "\n",
    "# import RFClassification\n",
    "\n",
    "import sys; sys.path.insert(0, '..') # add parent folder path where lib folder is\n",
    "# import RFClassification.helper_functions # store_load is a file on my library folder\n",
    "    \n",
    "from helper_functions import *\n",
    "from latency_helpers import *\n",
    "from loading_functions import *\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a4835a",
   "metadata": {},
   "source": [
    "### Load Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7710a0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 56/80 [01:09<01:12,  3.03s/it]"
     ]
    }
   ],
   "source": [
    "feat_folder = '../Features/'\n",
    "feat_name = 'SPEC'\n",
    "seg_len = 200\n",
    "# datestr = '2022-07-05'\n",
    "n_per_seg = 512\n",
    "interferences = ['CLEAN']\n",
    "dataset = load_dronedetect_features(feat_folder, feat_name, seg_len, n_per_seg, interferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b732f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size 948\n",
      "shape of each item torch.Size([1, 257, 26785])\n"
     ]
    }
   ],
   "source": [
    "print('dataset size', len(dataset))\n",
    "print('shape of each item', dataset.__getitem__(10)[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d85b6a",
   "metadata": {},
   "source": [
    "### 1. Custom NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25b3e63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model settings\n",
    "# Hyperparameters\n",
    "batch_size = 8 # the number of samples processed before the model is updated. (number of samples in the training data)\n",
    "num_classes = 7\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "\n",
    "# Device will determine whether to run the training on GPU or CPU.\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f02e381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a CNN class\n",
    "class ConvNeuralNet(nn.Module):\n",
    "    #  Determine what layers and their order in CNN object \n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.avpool0 = nn.AvgPool2d(kernel_size=(50,200))\n",
    "#         self.conv1 = nn.Conv2d(1, 8, 100)\n",
    "#         self.avgpool1 = nn.AvgPool2d(kernel_size=3)\n",
    "#         self.conv2 = nn.Conv2d(8, 8, 50)\n",
    "#         self.conv3 = nn.Conv1d(64,128, 3)\n",
    "#         self.conv4 = nn.Conv1d(128, 128, 3)\n",
    "        self.dense = nn.Linear(1670, num_classes)\n",
    "    \n",
    "    # Progresses data across layers    \n",
    "    def forward(self, x):\n",
    "         # Max pooling over a (2, 2) window\n",
    "        x = self.avpool0(x)\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.avgpool1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.avgpool1(x)\n",
    "#         x = nn.Dropout(p=0.25)(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.dense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6ecc46a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test a random input\n",
    "# batch_size = 8\n",
    "# input = torch.randn(batch_size, 1, 513, 13392)\n",
    "# # input_1d = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype = torch.float)\n",
    "\n",
    "# net = ConvNeuralNet(7)\n",
    "# out = net(input)\n",
    "# print(input.shape)\n",
    "# print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd6590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up Data\n",
    "train_split_percentage = 0.7\n",
    "split_lengths = [int(train_split_percentage*len(dataset)), len(dataset)-int(train_split_percentage*len(dataset))]\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, split_lengths)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_set,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_set,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "473c1b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNeuralNet(num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Set Loss function with criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set optimizer with optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  \n",
    "\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1cd183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "# We use the pre-defined number of epochs to determine how many iterations to train the network on\n",
    "for epoch in range(num_epochs):\n",
    "    #Load in the data in batches using the train_loader object\n",
    "    for i, (images, labels) in enumerate(train_loader): \n",
    "        labels = labels.type(torch.long)\n",
    "\n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1db00eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.822728157043457"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f831d304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0], device='cuda:0')\n",
      "Accuracy of the network on the 114 train images: 17.54385964912281 %\n"
     ]
    }
   ],
   "source": [
    "## Check accuracy\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "#         images = images.repeat(1,3,1)\n",
    "#         images = images.reshape(batch_size, 3, 1, 513)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        print(predicted)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print('Accuracy of the network on the {} train images: {} %'.format(total, 100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "71438924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6., 2.], device='cuda:0')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ceef8f",
   "metadata": {},
   "source": [
    "### 2. Transfer learning from Resnet50 & Apply Logistic Regression (Swinney paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47b6d844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pretrained resnet feature and just keep up to the last layer\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "modules=list(resnet50.children())[:-1]\n",
    "# resnet50=nn.Sequential(*modules)\n",
    "for p in resnet50.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "440b23cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test resnet\n",
    "input = torch.randn(1,1,30,300)\n",
    "inputr = input.repeat(1,3,1,1)\n",
    "resnet50(inputr).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5a73489",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet_feats = []\n",
    "resnet_y = []\n",
    "for n in range(len(dataset)):\n",
    "    d = dataset.__getitem__(n)\n",
    "    inarr = d[0]\n",
    "    inputr = inarr.repeat(1,3,1,1)  # repeat to have 3 channels of the same info\n",
    "    out = resnet50(inputr)\n",
    "    resnet_feats.append(np.array(out))\n",
    "    resnet_y.append(np.array(d[1]))\n",
    "\n",
    "resnet_feats = np.array(resnet_feats)\n",
    "resnet_y = np.array(resnet_y)\n",
    "\n",
    "# flatten the middle dimension\n",
    "resnet_feats = resnet_feats.reshape(resnet_feats.shape[0], resnet_feats.shape[-1])\n",
    "# invert labels back to categorical\n",
    "resnet_y_cat = dataset.le.inverse_transform(resnet_y.astype(np.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d3eea904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 64}\n",
      "Accuracy: 0.974,\t F1: 0.974\n",
      "{'C': 64}\n",
      "Accuracy: 0.921,\t F1: 0.923\n",
      "{'C': 256}\n",
      "Accuracy: 0.921,\t F1: 0.925\n",
      "{'C': 16}\n",
      "Accuracy: 0.895,\t F1: 0.891\n",
      "{'C': 16}\n",
      "Accuracy: 0.921,\t F1: 0.92\n",
      "{'C': 16}\n",
      "Accuracy: 0.947,\t F1: 0.948\n",
      "{'C': 64}\n",
      "Accuracy: 1.0,\t F1: 1.0\n",
      "{'C': 256}\n",
      "Accuracy: 0.974,\t F1: 0.973\n",
      "{'C': 256}\n",
      "Accuracy: 0.921,\t F1: 0.924\n",
      "{'C': 64}\n",
      "Accuracy: 0.892,\t F1: 0.89\n",
      "SPEC: ResNet+LR average test acc: 0.94, F1: 0.94, Run-time: 0.12ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split data into K-fold\n",
    "k_fold = 10\n",
    "cv = KFold(n_splits=k_fold, random_state=1, shuffle=True)\n",
    "\n",
    "# model parameters\n",
    "Cs=list(map(lambda x:pow(2,x),range(-10,10,2)))\n",
    "\n",
    "best_params_ls = []\n",
    "acc_ls = []\n",
    "f1_ls = []\n",
    "runt_ls = []\n",
    "\n",
    "parameters = {'C':Cs}\n",
    "\n",
    "for train_ix, test_ix in cv.split(resnet_feats):\n",
    "    \n",
    "    # find the optimal hypber parameters\n",
    "    lr = LogisticRegression(max_iter=10000)\n",
    "    clf = GridSearchCV(lr, parameters, n_jobs=1)\n",
    "    clf.fit(resnet_feats[train_ix], resnet_y_cat[train_ix])\n",
    "    \n",
    "    print(clf.best_params_)\n",
    "    best_params_ls.append(clf.best_params_)\n",
    "    \n",
    "    # predict on the test data\n",
    "    y_pred, runtimes = atomic_benchmark_estimator(clf, resnet_feats[test_ix], verbose=False)\n",
    "    runt_ls.append(np.mean(runtimes))\n",
    "    \n",
    "    acc = accuracy_score(y_arr[test_ix], y_pred)\n",
    "    f1 = f1_score(y_arr[test_ix], y_pred, average='weighted')\n",
    "    print('Accuracy: {:.3},\\t F1: {:.3}'.format(acc,f1))\n",
    "    acc_ls.append(acc)\n",
    "    f1_ls.append(f1)\n",
    "    \n",
    "out_msg = feat_name+': ResNet+LR average test acc: {:.2}, F1: {:.2}, Run-time: {:.2}ms'.format(np.mean(acc_ls), np.mean(f1_ls), np.mean(runt_ls)*1e3)\n",
    "print(out_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302d56ed",
   "metadata": {},
   "source": [
    "## 3. Apply resnet & a fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dfdbf77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379, 1000)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3ce6d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataset out of resnet features\n",
    "class ResNetFeatData(Dataset): ## NUMBERICAL DATA\n",
    "    def __init__(self, Xarr, yarr):\n",
    "        self.Xarr = Xarr\n",
    "        test_list=[]\n",
    "        self.le = preprocessing.LabelEncoder()\n",
    "        self.le.fit(yarr.flatten())\n",
    "        self.yarr = le.transform(yarr.flatten())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.yarr)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # all data must be in float and tensor format\n",
    "        X = torch.tensor((self.Xarr[index]))\n",
    "        X = X.unsqueeze(0)\n",
    "        y = torch.tensor(float(self.yarr[index]))\n",
    "        return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a939ae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdataset = ResNetFeatData(resnet_feats, y_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc22895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Network for fully connected layer\n",
    "class FCNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(FCNet, self).__init__()\n",
    "        self.fc_layer = nn.Linear(1000, num_classes)\n",
    "    \n",
    "    # Progresses data across layers    \n",
    "    def forward(self, x):\n",
    "        x = self.fc_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b6ce231d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [126]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     testloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m     31\u001b[0m                       resdataset,\n\u001b[1;32m     32\u001b[0m                       batch_size\u001b[38;5;241m=\u001b[39mbatch_size, sampler\u001b[38;5;241m=\u001b[39mtest_subsampler)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Init the neural network\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     network \u001b[38;5;241m=\u001b[39m \u001b[43mFCNet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#     network.apply(reset_weights)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# Initialize optimizer\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(fc_layer\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n",
      "Input \u001b[0;32mIn [125]\u001b[0m, in \u001b[0;36mFCNet.__init__\u001b[0;34m(self, num_classes)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_classes):\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mConvNeuralNet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_layer \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m1000\u001b[39m, num_classes)\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "# Configuration options\n",
    "k_folds = 10\n",
    "num_epochs = 10\n",
    "batch_size = 8\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# For fold results\n",
    "results = {}\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "# Start print\n",
    "print('--------------------------------')\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(resdataset)):\n",
    "    # Print\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      resdataset, \n",
    "                      batch_size=batch_size, sampler=train_subsampler)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      resdataset,\n",
    "                      batch_size=batch_size, sampler=test_subsampler)\n",
    "\n",
    "    # Init the neural network\n",
    "    network = FCNet(7)\n",
    "#     network.apply(reset_weights)\n",
    "\n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.Adam(fc_layer.parameters(), lr=1e-4)\n",
    "\n",
    "    # Run the training loop for defined number of epochs\n",
    "    for epoch in range(0, num_epochs):\n",
    "        # Print epoch\n",
    "        print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "        # Set current loss value\n",
    "        current_loss = 0.0\n",
    "\n",
    "        # Iterate over the DataLoader for training data\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # Get inputs\n",
    "            inputs, targets = data\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Perform forward pass\n",
    "            outputs = network(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            targets= targets.type(torch.long)\n",
    "            loss = loss_function(predicted, targets)\n",
    "\n",
    "            # Perform backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Perform optimization\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            current_loss += loss.item()\n",
    "            if i % 500 == 499:\n",
    "                print('Loss after mini-batch %5d: %.3f' %\n",
    "                      (i + 1, current_loss / 500))\n",
    "                current_loss = 0.0\n",
    "\n",
    "    # Process is complete.\n",
    "    print('Training process has finished. Saving trained model.')\n",
    "\n",
    "    # Print about testing\n",
    "    print('Starting testing')\n",
    "\n",
    "    # Saving the model\n",
    "#     save_path = f'./model-fold-{fold}.pth'\n",
    "#     torch.save(network.state_dict(), save_path)\n",
    "\n",
    "    # Evaluationfor this fold\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Iterate over the test data and generate predictions\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            # Get inputs\n",
    "            inputs, targets = data\n",
    "\n",
    "            # Generate outputs\n",
    "            outputs = fc_layer(inputs)\n",
    "\n",
    "            # Set total and correct\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "            # Print accuracy\n",
    "            print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "    print('--------------------------------')\n",
    "    results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "# Print fold results\n",
    "print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "print('--------------------------------')\n",
    "sum = 0.0\n",
    "for key, value in results.items():\n",
    "    print(f'Fold {key}: {value} %')\n",
    "    sum += value\n",
    "print(f'Average: {sum/len(results.items())} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "425b3ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3548563b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
