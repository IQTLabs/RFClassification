{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11845d27",
   "metadata": {},
   "source": [
    "### notebook to test FC Layer implementation after VGG and Resnet Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "542c574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the torch packages\n",
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LogSoftmax\n",
    "from torch import flatten\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "import sys; sys.path.insert(0, '..') # add parent folder path where lib folder is\n",
    "\n",
    "# import custom functions\n",
    "from helper_functions import *\n",
    "from latency_helpers import *\n",
    "from loading_functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40956d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Name:  ../../Features/IMG_SPEC_1024_20/\n"
     ]
    }
   ],
   "source": [
    "feat_folder = '../../Features/'\n",
    "feat_name = 'SPEC'\n",
    "seg_len = 20\n",
    "n_per_seg = 1024\n",
    "interferences = ['WIFI','CLEAN','BLUE','BOTH']\n",
    "output_name = 'drones'\n",
    "feat_format = 'IMG'\n",
    "\n",
    "dataset = DroneDetectTorch(feat_folder, feat_name, seg_len, n_per_seg, feat_format,\n",
    "                                output_name, interferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f5e3799",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGFC(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(VGGFC,self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.vggfull = models.vgg16(pretrained=True)\n",
    "        modules=list(self.vggfull.children())[:-1] # remove the fully connected layer & adaptive averaging\n",
    "        self.vggfeats=nn.Sequential(*modules)\n",
    "        \n",
    "        for param in self.vggfeats.parameters():\n",
    "            param.requires_grad_(False)\n",
    "        \n",
    "        self._fc = nn.Linear(25088, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = torch.moveaxis(x, 2, 0)\n",
    "        x = self.vggfeats(x)\n",
    "        x = x.flatten()\n",
    "        x = self._fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aed049f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = VGGFC(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b0d6ca2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0830, -0.1303, -0.2537,  0.2783, -0.0017, -0.1413,  0.1179],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = dataset.__getitem__(12)[0]\n",
    "# sample2 = torch.moveaxis(sample, 2, 0)\n",
    "Model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad067bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd390f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetFC(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResnetFC,self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.resnetfull = models.resnet50(pretrained=True)\n",
    "        modules=list(self.resnetfull.children())[:-2] # remove the fully connected layer & adaptive averaging\n",
    "        self.resnetfeats=nn.Sequential(*modules)\n",
    "        \n",
    "        for param in self.resnetfeats.parameters():\n",
    "            self.resnetfeats.requires_grad_(False)\n",
    "        \n",
    "        self._fc = nn.Linear(1505280, num_classes)\n",
    "    def forward(self, x):\n",
    "#         batch_size ,_,_ =x.shape\n",
    "        \n",
    "        # replicate the image to have 3 channels\n",
    "        x = x.repeat(1,3,1,1)\n",
    "        print(x.shape)\n",
    "        x = self.resnetfeats(x)\n",
    "        x = x.flatten()\n",
    "        print(x.shape)\n",
    "        x = self._fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab94dfcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
