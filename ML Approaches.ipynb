{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3398927f",
   "metadata": {},
   "source": [
    "## Notebook for machine learning methods for rf-based detection & classification\n",
    "-  exploring, SVM, Logistic regression with PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bb5637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from helper_functions import *\n",
    "from latency_helpers import *\n",
    "from loading_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9b6306",
   "metadata": {},
   "source": [
    "# DroneDetect Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae296122",
   "metadata": {},
   "source": [
    "### Load Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "964320ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Name:  ../Features/ARR_PSD_1024_20/\n"
     ]
    }
   ],
   "source": [
    "feat_folder = '../Features/'\n",
    "feat_name = 'PSD'\n",
    "seg_len = 20\n",
    "# datestr = '2022-07-05'\n",
    "n_per_seg = 1024\n",
    "interferences = ['WIFI', 'BLUE', 'BOTH', 'CLEAN']\n",
    "output_name = 'drones'\n",
    "feat_format = 'ARR'\n",
    "\n",
    "dataset = DroneDetectTorch(feat_folder, feat_name, seg_len, n_per_seg, feat_format,\n",
    "                                output_name, interferences)\n",
    "\n",
    "# Xs_arr, y_arr = load_dronedetect_features(feat_folder, feat_name, seg_len, \n",
    "#                                           n_per_seg, output_feat,interferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa5dc7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size 38978\n",
      "shape of each item (3, 1024)\n"
     ]
    }
   ],
   "source": [
    "print('dataset size', len(dataset))\n",
    "print('shape of each item', dataset.__getitem__([1,0,38977])[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "052bd00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx, ty = dataset.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc7880b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AIR'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fc65ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_all = range(len(dataset))\n",
    "X_use, y_use = dataset.__getitem__(i_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80184087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AIR', 'AIR', 'AIR', ..., 'DIS', 'DIS', 'DIS'], dtype='<U3')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97640c49",
   "metadata": {},
   "source": [
    "## Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b3aa731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into K-fold\n",
    "k_fold = 10\n",
    "kf = KFold(n_splits=k_fold, random_state=1, shuffle=True)\n",
    "\n",
    "# model parameters\n",
    "Cs=list(map(lambda x:pow(2,x),range(-3,10,2)))\n",
    "gammas=list(map(lambda x:pow(2,x),range(-3,10,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "260ea429",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241m.\u001b[39mfit(X_use[train_ix], y_use[train_ix],error_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "clf.fit(X_use[train_ix], y_use[train_ix],error_score='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c7c3f7",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d794a5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_ls = []\n",
    "acc_ls = []\n",
    "f1_ls = []\n",
    "runt_ls = []\n",
    "parameters = {'C':Cs, 'gamma':gammas}\n",
    "for train_ix, test_ix in kf.split(X_use):\n",
    "    \n",
    "    # find the optimal hypber parameters\n",
    "    svc = svm.SVC(kernel='rbf')\n",
    "    clf = GridSearchCV(svc, parameters, n_jobs=1)\n",
    "    clf.fit(X_use[train_ix], y_use[train_ix])\n",
    "    \n",
    "    print(clf.best_params_)\n",
    "    best_params_ls.append(clf.best_params_)\n",
    "    \n",
    "    # predict on the test data\n",
    "#     y_pred = clf.predict(Xs_use[test_ix])\n",
    "    y_pred, runtimes = atomic_benchmark_estimator(clf, X_use[test_ix], '<U3', verbose=False) # predict & measure time\n",
    "    runt_ls.append(np.mean(runtimes))\n",
    "    \n",
    "    acc = accuracy_score(y_use[test_ix], y_pred)\n",
    "    f1 = f1_score(y_use[test_ix], y_pred, average='weighted')\n",
    "    print('Accuracy: {:.3},\\t F1: {:.3}'.format(acc,f1))\n",
    "    acc_ls.append(acc)\n",
    "    f1_ls.append(f1)\n",
    "\n",
    "# print(feat_name+': SVM K-fold average test acc:', np.mean(acc_ls), 'F1:', np.mean(f1_ls), 'Run-time:', np.mean(runt_ls)*1e3,'ms')\n",
    "out_msg = feat_name+': SVM K-fold average test acc: {:.3}, F1: {:.3}, Run-time: {:.3}ms'.format(np.mean(acc_ls), np.mean(f1_ls), np.mean(runt_ls)*1e3)\n",
    "print(out_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27e0769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the size of the support vectors\n",
    "# clf.best_estimator_.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3be4871c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.125, 0.5, 2, 8, 32, 128, 512]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55668fe3",
   "metadata": {},
   "source": [
    "## SVM with fixed hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "411eb39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.798,\t F1: 0.807\n",
      "Accuracy: 0.796,\t F1: 0.804\n",
      "Accuracy: 0.792,\t F1: 0.8\n",
      "Accuracy: 0.792,\t F1: 0.8\n",
      "Accuracy: 0.788,\t F1: 0.797\n",
      "PSD: SVM K-fold average test acc: 0.79, F1: 0.8, Run-time: 1.4e+01ms\n"
     ]
    }
   ],
   "source": [
    "acc_ls = []\n",
    "f1_ls = []\n",
    "runt_ls = []\n",
    "\n",
    "k_fold = 5\n",
    "cv = KFold(n_splits=k_fold, random_state=1, shuffle=True)\n",
    "\n",
    "for train_ix, test_ix in cv.split(Xs_use):\n",
    "    svc = svm.SVC(kernel='rbf', C=512, gamma = 0.5)\n",
    "    svc.fit(Xs_use[train_ix], y_arr[train_ix])\n",
    "    # predict on the test data\n",
    "    y_pred, runtimes = atomic_benchmark_estimator(svc, Xs_use[test_ix], output_type='<U3', verbose=False)\n",
    "    runt_ls.append(np.mean(runtimes))\n",
    "    \n",
    "    acc = accuracy_score(y_arr[test_ix], y_pred)\n",
    "    f1 = f1_score(y_arr[test_ix], y_pred, average='weighted')\n",
    "    print('Accuracy: {:.3},\\t F1: {:.3}'.format(acc,f1))\n",
    "    acc_ls.append(acc)\n",
    "    f1_ls.append(f1)\n",
    "\n",
    "out_msg = feat_name+': SVM K-fold average test acc: {:.2}, F1: {:.2}, Run-time: {:.2}ms'.format(np.mean(acc_ls), np.mean(f1_ls), np.mean(runt_ls)*1e3)\n",
    "print(out_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1d2cf91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['INS', 'INS', 'INS', ..., 'MIN', 'MIN', 'MIN'], dtype='<U3')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.predict(Xs_use[test_ix\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb4d79ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3126, 513)\n"
     ]
    }
   ],
   "source": [
    "print(svc.support_vectors_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e7d671",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29956006",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_ls = []\n",
    "score_ls = []\n",
    "\n",
    "parameters = {'C':[0.01,0.1,1,10,100,1000,10000]}\n",
    "\n",
    "for train_ix, test_ix in cv.split(Xs_arr):\n",
    "    \n",
    "    # find the optimal hypber parameters\n",
    "    lr = LogisticRegression(max_iter=1000000)\n",
    "    clf = GridSearchCV(lr, parameters, n_jobs=1)\n",
    "    clf.fit(Xs_arr[train_ix], y_arr[train_ix])\n",
    "    \n",
    "    print(clf.best_params_)\n",
    "    best_params_ls.append(clf.best_params_)\n",
    "    \n",
    "    # predict on the test data\n",
    "    y_pred = clf.predict(Xs_arr[test_ix])\n",
    "    acc = accuracy_score(y_arr[test_ix], y_pred)\n",
    "    print(acc)\n",
    "    score_ls.append(acc)\n",
    "    \n",
    "print(feat_file_name+': LR K-fold average test score:', np.mean(score_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e044dc2b",
   "metadata": {},
   "source": [
    "# Drone RF Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b37906e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [00:00<00:00, 364.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1130, 513)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load features\n",
    "feat_folder = '../Features_DroneRF/'\n",
    "feat_name = 'PSD'\n",
    "highlow = 'H'\n",
    "seg_len = 50\n",
    "n_per_seg = 1024\n",
    "Xs_arr, y_arr = load_dronerf_features(feat_folder, feat_name, seg_len, n_per_seg, highlow, 'bi')\n",
    "\n",
    "\n",
    "## Apply normalization\n",
    "X_norm = Xs_arr\n",
    "for n in range(len(Xs_arr)):\n",
    "    X_norm[n] = Xs_arr[n]/max(Xs_arr[n])\n",
    "X_norm.shape\n",
    "y_arr = y_arr.reshape(len(y_arr),)\n",
    "\n",
    "Xs_use = X_norm # Use normalized features\n",
    "Xs_use.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5ab8510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 32, 'gamma': 0.5}\n",
      "Accuracy: 0.991,\t F1: 0.991\n",
      "{'C': 128, 'gamma': 0.5}\n",
      "Accuracy: 1.0,\t F1: 1.0\n",
      "{'C': 128, 'gamma': 0.125}\n",
      "Accuracy: 1.0,\t F1: 1.0\n",
      "{'C': 32, 'gamma': 0.5}\n",
      "Accuracy: 0.991,\t F1: 0.991\n",
      "{'C': 128, 'gamma': 0.125}\n",
      "Accuracy: 1.0,\t F1: 1.0\n",
      "{'C': 128, 'gamma': 0.125}\n",
      "Accuracy: 0.991,\t F1: 0.991\n",
      "{'C': 128, 'gamma': 0.125}\n",
      "Accuracy: 0.991,\t F1: 0.991\n",
      "{'C': 128, 'gamma': 0.125}\n",
      "Accuracy: 1.0,\t F1: 1.0\n",
      "{'C': 512, 'gamma': 0.125}\n",
      "Accuracy: 1.0,\t F1: 1.0\n",
      "{'C': 128, 'gamma': 0.125}\n",
      "Accuracy: 1.0,\t F1: 1.0\n",
      "PSD: SVM K-fold average test acc: 1.0, F1: 1.0, Run-time: 0.12ms\n"
     ]
    }
   ],
   "source": [
    "best_params_ls = []\n",
    "acc_ls = []\n",
    "f1_ls = []\n",
    "runt_ls = []\n",
    "parameters = {'C':Cs, 'gamma':gammas}\n",
    "for train_ix, test_ix in cv.split(Xs_use):\n",
    "    \n",
    "    # find the optimal hypber parameters\n",
    "    svc = svm.SVC(kernel='rbf')\n",
    "    clf = GridSearchCV(svc, parameters, n_jobs=1)\n",
    "    clf.fit(Xs_use[train_ix], y_arr[train_ix])\n",
    "    \n",
    "    print(clf.best_params_)\n",
    "    best_params_ls.append(clf.best_params_)\n",
    "    \n",
    "    # predict on the test data\n",
    "#     y_pred = clf.predict(Xs_use[test_ix])\n",
    "    y_pred, runtimes = atomic_benchmark_estimator(clf, Xs_use[test_ix], 'int', verbose=False) # predict & measure time\n",
    "    runt_ls.append(np.mean(runtimes))\n",
    "    \n",
    "    acc = accuracy_score(y_arr[test_ix], y_pred)\n",
    "    f1 = f1_score(y_arr[test_ix], y_pred, average='weighted')\n",
    "    print('Accuracy: {:.3},\\t F1: {:.3}'.format(acc,f1))\n",
    "    acc_ls.append(acc)\n",
    "    f1_ls.append(f1)\n",
    "\n",
    "# print(feat_name+': SVM K-fold average test acc:', np.mean(acc_ls), 'F1:', np.mean(f1_ls), 'Run-time:', np.mean(runt_ls)*1e3,'ms')\n",
    "out_msg = feat_name+': SVM K-fold average test acc: {:.2}, F1: {:.2}, Run-time: {:.2}ms'.format(np.mean(acc_ls), np.mean(f1_ls), np.mean(runt_ls)*1e3)\n",
    "print(out_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daabc33",
   "metadata": {},
   "source": [
    "## Try Model on Gamut data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1224a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 115/115 [00:00<00:00, 2255.41it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = '/home/kzhou/Data/S3/leesburg_worker1/Features/'\n",
    "Xgamut = load_gamut_features(data_path, 'psd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1580c037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize data\n",
    "## Apply normalization\n",
    "X_gamut_norm = Xgamut\n",
    "for n in range(len(Xgamut)):\n",
    "    X_gamut_norm[n] = Xgamut[n]/max(Xgamut[n])\n",
    "\n",
    "X_gamut_norm.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "700b4e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed data through trained SVM model\n",
    "y_gamut_pred = clf.predict(X_gamut_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5447b5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gamut_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5168eb32",
   "metadata": {},
   "source": [
    "## Save trained model for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c198ced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmodel = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8c1ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'test_save_model.sav'\n",
    "pickle.dump(bestmodel, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
