{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3398927f",
   "metadata": {},
   "source": [
    "## Notebook for machine learning methods for rf-based detection & classification\n",
    "-  exploring, SVM, Logistic regression with PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bb5637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from helper_functions import *\n",
    "from latency_helpers import *\n",
    "from loading_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9b6306",
   "metadata": {},
   "source": [
    "# DroneDetect Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae296122",
   "metadata": {},
   "source": [
    "### Load Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "964320ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Name:  ../Features/ARR_PSD_256_50/\n"
     ]
    }
   ],
   "source": [
    "feat_folder = '../Features/'\n",
    "feat_name = 'PSD'\n",
    "seg_len = 50\n",
    "n_per_seg = 256\n",
    "interferences = ['WIFI', 'BLUE', 'BOTH', 'CLEAN']\n",
    "output_name = 'drones'\n",
    "feat_format = 'ARR'\n",
    "\n",
    "dataset = DroneDetectTorch(feat_folder, feat_name, seg_len, n_per_seg, feat_format,\n",
    "                                output_name, interferences)\n",
    "\n",
    "# Xs_arr, y_arr = load_dronedetect_features(feat_folder, feat_name, seg_len, \n",
    "#                                           n_per_seg, output_feat,interferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fa5dc7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size 15591\n",
      "shape of each item (256,)\n"
     ]
    }
   ],
   "source": [
    "print('dataset size', len(dataset))\n",
    "print('shape of each item', dataset.__getitem__(0)[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c5006f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all to local memory\n",
    "i_all = list(range(len(dataset)))\n",
    "X_use, y_use = dataset.__getitem__(i_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97640c49",
   "metadata": {},
   "source": [
    "## Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4b3aa731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into K-fold\n",
    "k_fold = 5\n",
    "kf = KFold(n_splits=k_fold, random_state=1, shuffle=True)\n",
    "\n",
    "# model parameters\n",
    "Cs=list(map(lambda x:pow(2,x),range(-3,10,2)))\n",
    "gammas=list(map(lambda x:pow(2,x),range(-3,10,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c7c3f7",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d794a5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Not running for now- takes long time for gridsearchcv even with n_jobs -1\n",
    "### Run all combination of data parameters with fixed parameters first\n",
    "\n",
    "# best_params_ls = []\n",
    "# acc_ls = []\n",
    "# f1_ls = []\n",
    "# runt_ls = []\n",
    "# parameters = {'C':Cs, 'gamma':gammas}\n",
    "# for train_ix, test_ix in kf.split(X_use):\n",
    "    \n",
    "#     # find the optimal hypber parameters\n",
    "#     svc = svm.SVC(kernel='rbf')\n",
    "#     clf = GridSearchCV(svc, parameters, n_jobs=1)\n",
    "#     clf.fit(X_use[train_ix], y_use[train_ix])\n",
    "    \n",
    "#     print(clf.best_params_)\n",
    "#     best_params_ls.append(clf.best_params_)\n",
    "    \n",
    "#     # predict on the test data\n",
    "# #     y_pred = clf.predict(Xs_use[test_ix])\n",
    "#     y_pred, runtimes = atomic_benchmark_estimator(clf, X_use[test_ix], '<U3', verbose=False) # predict & measure time\n",
    "#     runt_ls.append(np.mean(runtimes))\n",
    "    \n",
    "#     acc = accuracy_score(y_use[test_ix], y_pred)\n",
    "#     f1 = f1_score(y_use[test_ix], y_pred, average='weighted')\n",
    "#     print('Accuracy: {:.3},\\t F1: {:.3}'.format(acc,f1))\n",
    "#     acc_ls.append(acc)\n",
    "#     f1_ls.append(f1)\n",
    "\n",
    "# # print(feat_name+': SVM K-fold average test acc:', np.mean(acc_ls), 'F1:', np.mean(f1_ls), 'Run-time:', np.mean(runt_ls)*1e3,'ms')\n",
    "# out_msg = feat_name+': SVM K-fold average test acc: {:.3}, F1: {:.3}, Run-time: {:.3}ms'.format(np.mean(acc_ls), np.mean(f1_ls), np.mean(runt_ls)*1e3)\n",
    "# print(out_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a27e0769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the size of the support vectors\n",
    "# clf.best_estimator_.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3be4871c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.125, 0.5, 2, 8, 32, 128, 512]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55668fe3",
   "metadata": {},
   "source": [
    "## SVM with fixed hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "411eb39e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.886,\t F1: 0.884\n",
      "Accuracy: 0.888,\t F1: 0.886\n",
      "Accuracy: 0.89,\t F1: 0.888\n",
      "Accuracy: 0.877,\t F1: 0.876\n",
      "Accuracy: 0.883,\t F1: 0.881\n",
      "PSD: SVM K-fold average test acc: 0.88, F1: 0.88, Run-time: 1.2ms\n"
     ]
    }
   ],
   "source": [
    "C_fix = 1 ##default params\n",
    "gamma_fix = 'scale'\n",
    "\n",
    "acc_ls = []\n",
    "f1_ls = []\n",
    "runt_ls = []\n",
    "\n",
    "k_fold = 5\n",
    "cv = KFold(n_splits=k_fold, random_state=None, shuffle=True)\n",
    "\n",
    "for train_ix, test_ix in cv.split(X_use):\n",
    "    svc = svm.SVC(kernel='rbf', C=C_fix, gamma = gamma_fix)\n",
    "    svc.fit(X_use[train_ix], y_use[train_ix])\n",
    "    # predict on the test data\n",
    "    y_pred, runtimes = atomic_benchmark_estimator(svc, X_use[test_ix], output_type='<U3', verbose=False)\n",
    "    runt_ls.append(np.mean(runtimes))\n",
    "    \n",
    "    acc = accuracy_score(y_use[test_ix], y_pred)\n",
    "    f1 = f1_score(y_use[test_ix], y_pred, average='weighted')\n",
    "    print('Accuracy: {:.3},\\t F1: {:.3}'.format(acc,f1))\n",
    "    acc_ls.append(acc)\n",
    "    f1_ls.append(f1)\n",
    "\n",
    "out_msg = feat_name+': SVM K-fold average test acc: {:.2}, F1: {:.2}, Run-time: {:.2}ms'.format(np.mean(acc_ls), np.mean(f1_ls), np.mean(runt_ls)*1e3)\n",
    "print(out_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb4d79ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4803, 256)\n"
     ]
    }
   ],
   "source": [
    "print(svc.support_vectors_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ef4f00",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1cb12d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as: SVM_PSD_256_50_1\n"
     ]
    }
   ],
   "source": [
    "# feat_name = 'PSD'\n",
    "# seg_len = 10\n",
    "# n_per_seg = 512\n",
    "import pickle\n",
    "to_train_all = True # whether to retrain using all the data\n",
    "model_name = 'SVM'+'_'+str(feat_name)+'_'+str(n_per_seg)+'_'+str(seg_len)+'_'+str(int(to_train_all))\n",
    "model_path = 'saved_models/'\n",
    "print('Model saved as:', model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8171d1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if to_train_all:\n",
    "    svc.fit(X_use, y_use)\n",
    "\n",
    "pickle.dump(svc, open(model_path+model_name, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e7d671",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29956006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params_ls = []\n",
    "# score_ls = []\n",
    "\n",
    "# parameters = {'C':[0.01,0.1,1,10,100,1000,10000]}\n",
    "\n",
    "# for train_ix, test_ix in cv.split(Xs_arr):\n",
    "    \n",
    "#     # find the optimal hypber parameters\n",
    "#     lr = LogisticRegression(max_iter=1000000)\n",
    "#     clf = GridSearchCV(lr, parameters, n_jobs=1)\n",
    "#     clf.fit(Xs_arr[train_ix], y_arr[train_ix])\n",
    "    \n",
    "#     print(clf.best_params_)\n",
    "#     best_params_ls.append(clf.best_params_)\n",
    "    \n",
    "#     # predict on the test data\n",
    "#     y_pred = clf.predict(Xs_arr[test_ix])\n",
    "#     acc = accuracy_score(y_arr[test_ix], y_pred)\n",
    "#     print(acc)\n",
    "#     score_ls.append(acc)\n",
    "    \n",
    "# print(feat_file_name+': LR K-fold average test score:', np.mean(score_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e044dc2b",
   "metadata": {},
   "source": [
    "# Drone RF Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b37906e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [00:00<00:00, 569.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1130, 513)  y shape: (1130,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load features\n",
    "feat_folder = '../Features_DroneRF/'\n",
    "feat_name = 'PSD'\n",
    "highlow = 'H'\n",
    "seg_len = 50\n",
    "n_per_seg = 1024\n",
    "Xs_arr, y_arr = load_dronerf_features(feat_folder, feat_name, seg_len, n_per_seg, highlow, 'bi')\n",
    "\n",
    "\n",
    "## Apply normalization\n",
    "X_norm = Xs_arr\n",
    "for n in range(len(Xs_arr)):\n",
    "    X_norm[n] = Xs_arr[n]/max(Xs_arr[n])\n",
    "X_norm.shape\n",
    "y_arr = y_arr.reshape(len(y_arr),)\n",
    "\n",
    "Xs_use = X_norm # Use normalized features\n",
    "Xs_use.shape\n",
    "\n",
    "print('X shape:', Xs_arr.shape, ' y shape:', y_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "412b0be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_arr.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5ab8510",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 245 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n245 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/kzhou/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/kzhou/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"/home/kzhou/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 739, in _validate_targets\n    raise ValueError(\nValueError: The number of classes has to be greater than one; got 1 class\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m svc \u001b[38;5;241m=\u001b[39m svm\u001b[38;5;241m.\u001b[39mSVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m clf \u001b[38;5;241m=\u001b[39m GridSearchCV(svc, parameters, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXs_use\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_ix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_arr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_ix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(clf\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[1;32m     14\u001b[0m best_params_ls\u001b[38;5;241m.\u001b[39mappend(clf\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1375\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1375\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/sklearn/model_selection/_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    849\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    850\u001b[0m     )\n\u001b[0;32m--> 852\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 245 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n245 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/kzhou/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/kzhou/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"/home/kzhou/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 739, in _validate_targets\n    raise ValueError(\nValueError: The number of classes has to be greater than one; got 1 class\n"
     ]
    }
   ],
   "source": [
    "best_params_ls = []\n",
    "acc_ls = []\n",
    "f1_ls = []\n",
    "runt_ls = []\n",
    "parameters = {'C':Cs, 'gamma':gammas}\n",
    "for train_ix, test_ix in cv.split(Xs_use):\n",
    "    \n",
    "    # find the optimal hypber parameters\n",
    "    svc = svm.SVC(kernel='rbf')\n",
    "    clf = GridSearchCV(svc, parameters, n_jobs=1)\n",
    "    clf.fit(Xs_use[train_ix], y_arr[train_ix])\n",
    "    \n",
    "    print(clf.best_params_)\n",
    "    best_params_ls.append(clf.best_params_)\n",
    "    \n",
    "    # predict on the test data\n",
    "#     y_pred = clf.predict(Xs_use[test_ix])\n",
    "    y_pred, runtimes = atomic_benchmark_estimator(clf, Xs_use[test_ix], 'int', verbose=False) # predict & measure time\n",
    "    runt_ls.append(np.mean(runtimes))\n",
    "    \n",
    "    acc = accuracy_score(y_arr[test_ix], y_pred)\n",
    "    f1 = f1_score(y_arr[test_ix], y_pred, average='weighted')\n",
    "    print('Accuracy: {:.3},\\t F1: {:.3}'.format(acc,f1))\n",
    "    acc_ls.append(acc)\n",
    "    f1_ls.append(f1)\n",
    "\n",
    "# print(feat_name+': SVM K-fold average test acc:', np.mean(acc_ls), 'F1:', np.mean(f1_ls), 'Run-time:', np.mean(runt_ls)*1e3,'ms')\n",
    "out_msg = feat_name+': SVM K-fold average test acc: {:.2}, F1: {:.2}, Run-time: {:.2}ms'.format(np.mean(acc_ls), np.mean(f1_ls), np.mean(runt_ls)*1e3)\n",
    "print(out_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daabc33",
   "metadata": {},
   "source": [
    "## Try Model on Gamut data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1224a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 115/115 [00:00<00:00, 2255.41it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = '/home/kzhou/Data/S3/leesburg_worker1/Features/'\n",
    "Xgamut = load_gamut_features(data_path, 'psd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1580c037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize data\n",
    "## Apply normalization\n",
    "X_gamut_norm = Xgamut\n",
    "for n in range(len(Xgamut)):\n",
    "    X_gamut_norm[n] = Xgamut[n]/max(Xgamut[n])\n",
    "\n",
    "X_gamut_norm.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "700b4e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed data through trained SVM model\n",
    "y_gamut_pred = clf.predict(X_gamut_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5447b5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gamut_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5168eb32",
   "metadata": {},
   "source": [
    "## Save trained model for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c198ced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmodel = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8c1ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'test_save_model.sav'\n",
    "pickle.dump(bestmodel, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
