{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a461472",
   "metadata": {},
   "source": [
    "## Notebook to running speed on Pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93014a3a",
   "metadata": {},
   "source": [
    "Notebook to draft code to test running on Pi\n",
    "\n",
    "0. Load model\n",
    "1. Feature generation (measure time)\n",
    "2. Make prediction (measure time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6a6928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..') # add parent folder path where lib folder is\n",
    "\n",
    "from gamutrf_feature_functions import *\n",
    "from gamutrf.sample_reader import read_recording\n",
    "from gamutrf.utils import parse_filename\n",
    "import pickle\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6ada99",
   "metadata": {},
   "source": [
    "## PSD+SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "364a60c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kzhou/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/scipy/signal/_spectral_py.py:1961: UserWarning: nperseg = 256 is greater than input length  = 240, using nperseg = 240\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature time: 9.693206787109375\n",
      "Prediction time: 2.5399672985076904\n",
      "average time for Feature Generation: 16.2ms, Prediction: 4.23ms\n"
     ]
    }
   ],
   "source": [
    "n_per_seg = 256\n",
    "t_seg = 20\n",
    "model_folder = '../saved_models/'\n",
    "model_file = 'SVM_PSD_'+str(n_per_seg)+'_'+str(t_seg)+'_1'\n",
    "win_type = 'hamming'\n",
    "\n",
    "## Load Model\n",
    "model = pickle.load(open(model_folder+model_file, 'rb'))\n",
    "\n",
    "## Generate features\n",
    "data_folder = 'sample_data/'\n",
    "\n",
    "for fi in os.listdir(data_folder):\n",
    "    full_file = data_folder+fi\n",
    "    if fi.endswith('.zst'):    # check if it is a compressed datafile\n",
    "       \n",
    "        freq_center, sample_rate, sample_dtype, sample_len, sample_type, sample_bits = parse_filename(full_file)\n",
    "        # read sample\n",
    "        samples = read_recording(full_file, sample_rate, sample_dtype, sample_len, t_seg/1e3)\n",
    "        \n",
    "        # get features\n",
    "        start_ft = time.time()\n",
    "        freqs, psds = get_PSD_from_samples(samples, sample_rate, win_type, n_per_seg)\n",
    "        \n",
    "        end_ft = time.time()\n",
    "        print('Feature time:', end_ft-start_ft)\n",
    "        \n",
    "        start_pd = time.time()\n",
    "        pout = model.predict(psds)\n",
    "        \n",
    "        end_pd = time.time()\n",
    "        print('Prediction time:', end_pd-start_pd)\n",
    "        \n",
    "        # print average time per sample\n",
    "        n_samps = pout.shape[0]\n",
    "        avg_time_feat = (end_ft-start_ft)/n_samps\n",
    "        avg_time_pred = (end_pd-start_pd)/n_samps\n",
    "        \n",
    "        print('average time for Feature Generation: {:.3}ms, Prediction: {:.3}ms'.format(avg_time_feat*1e3, avg_time_pred*1e3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1bd926",
   "metadata": {},
   "source": [
    "# NN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e43c63a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from Torch_Models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bde69add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class VGGFC(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(VGGFC,self).__init__()\n",
    "#         self.num_classes = num_classes\n",
    "#         self.vggfull = models.vgg16(pretrained=True)\n",
    "#         modules=list(self.vggfull.children())[:-1] # remove the fully connected layer & adaptive averaging\n",
    "#         self.vggfeats=nn.Sequential(*modules)\n",
    "        \n",
    "#         for param in self.vggfeats.parameters():\n",
    "#             param.requires_grad_(False)\n",
    "        \n",
    "#         self._fc = nn.Linear(25088, num_classes)\n",
    "#     def forward(self, x):\n",
    "#         if len(x.shape)==4:\n",
    "#             x = torch.moveaxis(x,-1, 1)\n",
    "#         else:\n",
    "#             x = torch.moveaxis(x, -1, 0)\n",
    "#         x = self.vggfeats(x)\n",
    "# #         print(x.shape)\n",
    "#         x = x.reshape(-1,25088)\n",
    "#         x = self._fc(x)\n",
    "        \n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62cd2689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../gamutrf_feature_functions.py:35: UserWarning: Only one segment is calculated since parameter NFFT (=1024) >= signal length (=240).\n",
      "  spec, _, _, _ = plt.specgram(sa, NFFT=n_per_seg, Fs=fs,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature time: 23.449873685836792\n",
      "Prediction time: 25.701370239257812\n",
      "average time for Feature Generation: 39.0ms, Prediction: 42.8ms\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 224x224 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_per_seg = 1024\n",
    "t_seg = 20\n",
    "model_folder = '../saved_models/'\n",
    "model_file = 'VGGFC_SPEC_'+str(n_per_seg)+'_'+str(t_seg)\n",
    "# win_type = 'hamming'\n",
    "\n",
    "## Load Model\n",
    "model = torch.load(model_folder+model_file)\n",
    "\n",
    "## Generate features\n",
    "data_folder = 'sample_data/'\n",
    "\n",
    "for fi in os.listdir(data_folder):\n",
    "    full_file = data_folder+fi\n",
    "    if fi.endswith('.zst'):    # check if it is a compressed datafile\n",
    "       \n",
    "        freq_center, sample_rate, sample_dtype, sample_len, sample_type, sample_bits = parse_filename(full_file)\n",
    "        # read sample\n",
    "        \n",
    "        samples = read_recording(full_file, sample_rate, sample_dtype, sample_len, t_seg/1e3)\n",
    "        \n",
    "        # get feature\n",
    "        start_ft = time.time()\n",
    "        return_array = True\n",
    "        rgbs = get_specs_from_samples(samples, sample_rate, n_per_seg, return_array)\n",
    "        \n",
    "        end_ft = time.time()\n",
    "        print('Feature time:', end_ft-start_ft)\n",
    "        \n",
    "        start_pd = time.time()\n",
    "        feat = torch.tensor(rgbs/255).float()\n",
    "        pout = model(feat)\n",
    "        \n",
    "        end_pd = time.time()\n",
    "        print('Prediction time:', end_pd-start_pd)\n",
    "        \n",
    "        # print average time per sample\n",
    "        n_samps = rgbs.shape[0]\n",
    "        avg_time_feat = (end_ft-start_ft)/n_samps\n",
    "        avg_time_pred = (end_pd-start_pd)/n_samps\n",
    "        \n",
    "        print('average time for Feature Generation: {:.3}ms, Prediction: {:.3}ms'.format(avg_time_feat*1e3, avg_time_pred*1e3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a40f208",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
