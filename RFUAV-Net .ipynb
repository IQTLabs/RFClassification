{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "654c897a",
   "metadata": {},
   "source": [
    "## Implementation of RFUAV-net\n",
    "July 1, 2022 \\\n",
    "efficient CNN method \\\n",
    "status: tested with a small sample, did not run the full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4983b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4327455",
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper functions\n",
    "def normalize_rf(rf):\n",
    "    \"\"\"apply normalization to data in the numpy array format\"\"\"\n",
    "    for i in range(len(rf)):\n",
    "        for j in range(2):\n",
    "            rf[i][j] = (rf[i][j] - np.min(rf[i][j]))/(np.max(rf[i][j])-np.min(rf[i][j]))\n",
    "\n",
    "    return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa9dd0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff 5 file name: 00000L_13.csv\n"
     ]
    }
   ],
   "source": [
    "## Import data -  Drone RF\n",
    "main_folder = '/home/kzhou/Data/DroneRF/'\n",
    "high_freq_files = os.listdir(main_folder+'High/')\n",
    "low_freq_files = os.listdir(main_folder+'Low/')\n",
    "\n",
    "high_freq_files.sort()\n",
    "low_freq_files.sort()\n",
    "fs = 40e6 #40 MHz\n",
    "\n",
    "# feature & results lists\n",
    "Xs = []\n",
    "ys = []\n",
    "y4s = []\n",
    "y10s = []\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    # load RF data\n",
    "    rf_data_h = pd.read_csv(main_folder+'High/'+high_freq_files[i], header=None).values\n",
    "    rf_data_h = rf_data_h.flatten()\n",
    "    \n",
    "    rf_data_l = pd.read_csv(main_folder+'Low/'+low_freq_files[i], header=None).values\n",
    "    rf_data_l = rf_data_l.flatten()\n",
    "    \n",
    "    if len(rf_data_h)!=len(rf_data_l):\n",
    "        print('diff', i, 'file name:', low_freq_files[i]) \n",
    "        # not sure why one pair of files have different lengths (ignore this for now)\n",
    "    else:\n",
    "        # stack the features and ys\n",
    "        rf_sig = np.vstack((rf_data_h, rf_data_l))\n",
    "        rf_sig = np.split(rf_sig, 1000, axis =1) # samples of 1e4\n",
    "        Xs.append(normalize_rf(rf_sig))\n",
    "        \n",
    "        y_rep = np.repeat(int(low_freq_files[i][0]),1000)\n",
    "        y4_rep = np.repeat(int(low_freq_files[i][:3]),1000)\n",
    "        y10_rep = np.repeat(int(low_freq_files[i][:5]),1000)\n",
    "\n",
    "        ys.append(y_rep) # 2 class\n",
    "        y4s.append(y4_rep) # 4 class\n",
    "        y10s.append(y10_rep) # 10 class\n",
    "\n",
    "        if int(high_freq_files[i][:5])!= int(low_freq_files[i][:5]):\n",
    "            raise Exception(\"File labels do not match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d441e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape the arrays\n",
    "Xs_arr = np.array(Xs)\n",
    "Xs_arr = Xs_arr.reshape(-1, *Xs_arr.shape[-2:])\n",
    "ys_arr = np.array(ys).flatten()\n",
    "y4s_arr = np.array(y4s).flatten()\n",
    "y10s_arr = np.array(y10s).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16920608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99000, 2, 10000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a2398d",
   "metadata": {},
   "source": [
    "### Apply Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50c681d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LogSoftmax\n",
    "from torch import flatten\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac25eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define dataset\n",
    "## Create a dataset class\n",
    "## Creating a custom dataset\n",
    "class DroneRFData(Dataset): ## NUMBERICAL DATA\n",
    "    def __init__(self, Xarr, yarr):\n",
    "        self.Xarr = Xarr\n",
    "        test_list=[]\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(yarr.flatten())\n",
    "        self.yarr = le.transform(yarr.flatten())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.yarr)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # all data must be in float and tensor format\n",
    "        X = torch.tensor((self.Xarr[index]))\n",
    "        X = X.unsqueeze(0)\n",
    "        y = torch.tensor(float(self.yarr[index]))\n",
    "        return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e7448bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DroneRFData(Xs_arr, ys_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23c44ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(10)[0][0][0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141e6038",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFUAVNet(nn.Module):\n",
    "    #  Determine what layers and their order in CNN object \n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.avpool0 = nn.AvgPool2d(kernel_size=(50,200))\n",
    "        self.dense = nn.Linear(1670, num_classes)\n",
    "    \n",
    "    # Progresses data across layers    \n",
    "    def forward(self, x):\n",
    "         # Max pooling over a (2, 2) window\n",
    "        x = self.avpool0(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.dense(x)\n",
    "        return x\n",
    "    \n",
    "    def runit(self,x):\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
