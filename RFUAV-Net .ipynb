{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d254ebea",
   "metadata": {},
   "source": [
    "## Implementation of RFUAV-net\n",
    "efficient CNN method - 1D convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e3259ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from helper_functions import *\n",
    "from loading_functions import *\n",
    "\n",
    "import time\n",
    "\n",
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LogSoftmax\n",
    "from torch import flatten\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "# from torchmetrics import F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "147ca17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload functions & modules\n",
    "import importlib\n",
    "import loading_functions\n",
    "importlib.reload(loading_functions)\n",
    "from loading_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56271efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff 5 file name: 00000L_13.csv\n"
     ]
    }
   ],
   "source": [
    "## Import data -  Drone RF\n",
    "main_folder = '/home/kzhou/Data/DroneRF/'\n",
    "t_seg = 0.25 #ms\n",
    "Xs_arr, ys_arr, y4s_arr, y10s_arr = load_dronerf_raw(main_folder, t_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39853356",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply normalization\n",
    "L_max = np.max(Xs_arr[:,1,:])\n",
    "L_min = np.min(Xs_arr[:,1,:])\n",
    "H_max = np.max(Xs_arr[:,0,:])\n",
    "H_min = np.min(Xs_arr[:,0,:])\n",
    "Maxes = np.vstack((H_max, L_max))\n",
    "Mins = np.vstack((H_min, L_min))\n",
    "\n",
    "Xs_norm = np.zeros(Xs_arr.shape)\n",
    "for ihl in range(2):\n",
    "    Xs_norm[:,ihl,:] = (Xs_arr[:,ihl,:]-Mins[ihl])/(Maxes[ihl]-Mins[ihl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed292ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check for nans in the data\n",
    "# tfall = np.isnan(y10s_arr)\n",
    "# tfall.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a9047d",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45b4212e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = DroneData(Xs_norm, y10s_arr)\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086be216",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c407a66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFUAVNet(nn.Module):\n",
    "    #  Determine what layers and their order in CNN object \n",
    "    def __init__(self, num_classes):\n",
    "        super(RFUAVNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.dense = nn.Linear(320, num_classes)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.smax = nn.Softmax(dim=1)\n",
    "        \n",
    "        # for r unit\n",
    "        self.conv1 = nn.Conv1d(in_channels=2, out_channels=64, kernel_size=5, stride=5)\n",
    "        self.norm1 = nn.BatchNorm1d(num_features=64)\n",
    "        self.elu1 = nn.ELU(alpha=1.0, inplace=False)\n",
    "        \n",
    "        # setup for components of the gunit\n",
    "        self.groupconvlist = []\n",
    "        self.norm2list = []\n",
    "        self.elu2list = []\n",
    "        for i in range(4):\n",
    "            self.groupconvlist.append( nn.Conv1d( \n",
    "                  in_channels=64,\n",
    "                  out_channels=64,\n",
    "                  kernel_size=3,\n",
    "                  stride = 2,\n",
    "                  groups=8,\n",
    "    #               bias=False,\n",
    "                  dtype=torch.float32\n",
    "                ))\n",
    "            self.norm2list.append(nn.BatchNorm1d(num_features=64))\n",
    "            self.elu2list.append(nn.ELU(alpha=1.0, inplace=False))\n",
    "        self.groupconv = nn.ModuleList(self.groupconvlist)\n",
    "        self.norm2 = nn.ModuleList(self.norm2list)\n",
    "        self.elu2 = nn.ModuleList(self.elu2list)\n",
    "        \n",
    "        # multi-gap implementation\n",
    "        self.avgpool1000 = nn.AvgPool1d(kernel_size=1000)\n",
    "        self.avgpool500 = nn.AvgPool1d(kernel_size=500)\n",
    "        self.avgpool250 = nn.AvgPool1d(kernel_size=250)\n",
    "        self.avgpool125 = nn.AvgPool1d(kernel_size=125)\n",
    "    \n",
    "    # Progresses data across layers    \n",
    "    def forward(self, x):\n",
    "        # runit first\n",
    "        x1 = self.runit(x)\n",
    "        xg1 = self.gunit(F.pad(x1, (1,0)), 0) \n",
    "        x2 = self.pool(x1)\n",
    "        x3 = xg1+x2\n",
    "        \n",
    "        # series of gunits\n",
    "        xg2 = self.gunit(F.pad(x3, (1,0)), 1)\n",
    "        x4 = self.pool(x3)\n",
    "        x5 = xg2+x4\n",
    "        \n",
    "        xg3 = self.gunit(F.pad(x5, (1,0)), 2)\n",
    "        x6 = self.pool(x5)\n",
    "        x7 = x6+xg3\n",
    "        \n",
    "        xg4 = self.gunit(F.pad(x7, (1,0)), 3)\n",
    "        x8 = self.pool(x7)\n",
    "        x_togap = x8+xg4\n",
    "        \n",
    "        \n",
    "        # gap and multi-gap\n",
    "        f_gap_1 = self.avgpool1000(xg1)\n",
    "        f_gap_2 = self.avgpool500(xg2)\n",
    "        f_gap_3 = self.avgpool250(xg3)\n",
    "        f_gap_4 = self.avgpool125(xg4)\n",
    "        \n",
    "        f_multigap = torch.cat((f_gap_1,f_gap_2, f_gap_3, f_gap_4), 1)\n",
    "        \n",
    "        f_gap_add = self.avgpool125(x_togap)\n",
    "    \n",
    "        f_final = torch.cat((f_multigap, f_gap_add),1)\n",
    "        f_flat = f_final.flatten(start_dim=1)\n",
    "    \n",
    "        out = self.dense(f_flat)\n",
    "#         out = self.smax(f_fc)\n",
    "        # fc_layer\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def runit(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.elu1(x)\n",
    "        return x\n",
    "        \n",
    "    def gunit(self, x, n):\n",
    "        # group convolution layer 8 by 8\n",
    "        # norm\n",
    "        # elu\n",
    "        # n indicates which gunit\n",
    "        x = self.groupconv[n](x) \n",
    "        x = self.norm2[n](x)\n",
    "        x = self.elu2[n](x)\n",
    "        return x\n",
    "    \n",
    "    def reset_weights(self):\n",
    "        for layer in self.children():\n",
    "            if hasattr(layer, 'reset_parameters'):\n",
    "                print(f'Reset trainable parameters of layer = {layer}')\n",
    "                layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94f62bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = RFUAVNet(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb85bb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1d(64, 64, kernel_size=(3,), stride=(2,), groups=8)\n",
      "Conv1d(64, 64, kernel_size=(3,), stride=(2,), groups=8)\n",
      "Conv1d(64, 64, kernel_size=(3,), stride=(2,), groups=8)\n",
      "Conv1d(64, 64, kernel_size=(3,), stride=(2,), groups=8)\n",
      "BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ELU(alpha=1.0)\n",
      "ELU(alpha=1.0)\n",
      "ELU(alpha=1.0)\n",
      "ELU(alpha=1.0)\n"
     ]
    }
   ],
   "source": [
    "for layer in net.children():\n",
    "    if isinstance(layer, nn.ModuleList):\n",
    "        for item in layer.children():\n",
    "            print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5b8288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39a2e9ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Test network\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m input1 \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;241m40\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# input1 = input1.float()\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# input1= input1.type(torch.float)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(input1\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "## Test network\n",
    "input1 = dataset.__getitem__(40)[0]\n",
    "# input1 = input1.float()\n",
    "# input1= input1.type(torch.float)\n",
    "print(input1.shape)\n",
    "input1 = torch.unsqueeze(input1, 0)\n",
    "# input = input.reshape(1, 2, 10000)\n",
    "# input1 = torch.rand(128, 2, 10000)\n",
    "\n",
    "# print(input1.shape)\n",
    "\n",
    "# input_1d = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype = torch.float)\n",
    "\n",
    "net = RFUAVNet(3)\n",
    "out = net(input1)\n",
    "\n",
    "# print(out.shape)\n",
    "# print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e55c3b",
   "metadata": {},
   "source": [
    "## Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1be75eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_functions import runkfoldcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8efa8a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Hyperparameters\n",
    "num_classes = 10\n",
    "batch_size = 128 # 128\n",
    "learning_rate = 0.01\n",
    "num_epochs = 5 # 0\n",
    "momentum = 0.95\n",
    "l2reg = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9293e9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up Model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "model = RFUAVNet(num_classes)\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "49948062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Linear(in_features=320, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Conv1d(2, 64, kernel_size=(5,), stride=(5,))\n",
      "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Starting epoch 1\n",
      "    Loss after mini-batch    50: 2.49069\n",
      "    Loss after mini-batch   100: 2.27579\n",
      "    Loss after mini-batch   150: 2.24068\n",
      "    Loss after mini-batch   200: 2.22313\n",
      "    Loss after mini-batch   250: 2.22259\n",
      "    Loss after mini-batch   300: 2.20085\n",
      "    Loss after mini-batch   350: 2.17846\n",
      "    Loss after mini-batch   400: 2.15084\n",
      "    Loss after mini-batch   450: 2.13397\n",
      "    Loss after mini-batch   500: 2.10239\n",
      "    Loss after mini-batch   550: 2.07546\n",
      "    Loss after mini-batch   600: 2.03393\n",
      "    Loss after mini-batch   650: 1.98937\n",
      "    Loss after mini-batch   700: 1.93313\n",
      "    Loss after mini-batch   750: 1.88816\n",
      "    Loss after mini-batch   800: 1.82947\n",
      "    Loss after mini-batch   850: 1.77085\n",
      "    Loss after mini-batch   900: 1.71697\n",
      "    Loss after mini-batch   950: 1.67325\n",
      "    Loss after mini-batch  1000: 1.62355\n",
      "    Loss after mini-batch  1050: 1.57005\n",
      "    Loss after mini-batch  1100: 1.51410\n",
      "    Loss after mini-batch  1150: 1.49265\n",
      "    Loss after mini-batch  1200: 1.45655\n",
      "    Loss after mini-batch  1250: 1.42448\n",
      "    Loss after mini-batch  1300: 1.40685\n",
      "    Loss after mini-batch  1350: 1.34492\n",
      "    Loss after mini-batch  1400: 1.31642\n",
      "Epoch [1/5], Loss: 1.2639\n",
      "Starting epoch 2\n",
      "    Loss after mini-batch    50: 1.25701\n",
      "    Loss after mini-batch   100: 1.24064\n",
      "    Loss after mini-batch   150: 1.19504\n",
      "    Loss after mini-batch   200: 1.16360\n",
      "    Loss after mini-batch   250: 1.13893\n",
      "    Loss after mini-batch   300: 1.10171\n",
      "    Loss after mini-batch   350: 1.08146\n",
      "    Loss after mini-batch   400: 1.05610\n",
      "    Loss after mini-batch   450: 1.02101\n",
      "    Loss after mini-batch   500: 1.00211\n",
      "    Loss after mini-batch   550: 0.98145\n",
      "    Loss after mini-batch   600: 0.95654\n",
      "    Loss after mini-batch   650: 0.94281\n",
      "    Loss after mini-batch   700: 0.92003\n",
      "    Loss after mini-batch   750: 0.91731\n",
      "    Loss after mini-batch   800: 0.91704\n",
      "    Loss after mini-batch   850: 0.86367\n",
      "    Loss after mini-batch   900: 0.84650\n",
      "    Loss after mini-batch   950: 0.84338\n",
      "    Loss after mini-batch  1000: 0.85499\n",
      "    Loss after mini-batch  1050: 0.84681\n",
      "    Loss after mini-batch  1100: 0.81781\n",
      "    Loss after mini-batch  1150: 0.82621\n",
      "    Loss after mini-batch  1200: 0.79913\n",
      "    Loss after mini-batch  1250: 0.79942\n",
      "    Loss after mini-batch  1300: 0.78441\n",
      "    Loss after mini-batch  1350: 0.76226\n",
      "    Loss after mini-batch  1400: 0.77059\n",
      "Epoch [2/5], Loss: 0.7238\n",
      "Starting epoch 3\n",
      "    Loss after mini-batch    50: 0.75117\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m k_folds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m----> 2\u001b[0m avg_acc, mean_f1s, mean_runtime \u001b[38;5;241m=\u001b[39m \u001b[43mrunkfoldcv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_folds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2reg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/main/RFClassification/nn_functions.py:78\u001b[0m, in \u001b[0;36mrunkfoldcv\u001b[0;34m(model, dataset, device, k_folds, batch_size, learning_rate, num_epochs, momentum, l2reg)\u001b[0m\n\u001b[1;32m     75\u001b[0m             current_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     77\u001b[0m             \u001b[38;5;66;03m# Iterate over the DataLoader for training data\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader):\n\u001b[1;32m     79\u001b[0m                 \u001b[38;5;66;03m# Get inputs\u001b[39;00m\n\u001b[1;32m     80\u001b[0m                 inputs, targets \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m#                 inputs = inputs.float()\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/main/RFClassification/loading_functions.py:585\u001b[0m, in \u001b[0;36mDroneData.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m    584\u001b[0m         \u001b[38;5;66;03m# all data must be in float and tensor format\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXarr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    586\u001b[0m \u001b[38;5;66;03m#         X = X.unsqueeze(0)\u001b[39;00m\n\u001b[1;32m    587\u001b[0m         y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myarr[index]))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k_folds = 5\n",
    "avg_acc, mean_f1s, mean_runtime = runkfoldcv(\n",
    "    model, dataset, device, k_folds, batch_size, learning_rate, num_epochs, momentum, l2reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ef0d6d",
   "metadata": {},
   "source": [
    "### Single fold train & test development code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b766e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data and parameters\n",
    "batch_size = 128\n",
    "num_classes = len(set(ys_arr))\n",
    "learning_rate = 0.01\n",
    "num_epochs = 5 # 0\n",
    "momentum = 0.95\n",
    "l2reg = 1e-4\n",
    "\n",
    "## Set up Data\n",
    "train_split_percentage = 0.9\n",
    "split_lengths = [int(train_split_percentage*len(dataset)), len(dataset)-int(train_split_percentage*len(dataset))]\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, split_lengths)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_set,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_set,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "\n",
    "## Set up Model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = RFUAVNet(num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Set Loss function with criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set optimizer with optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=l2reg, momentum = momentum)  \n",
    "\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b44a7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 2, 10000])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8136219d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqueeze(inputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#         labels = labels.type(torch.float)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m         \u001b[38;5;66;03m# Move tensors to the configured device\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m         labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "# Training\n",
    "# We use the pre-defined number of epochs to determine how many iterations to train the network on\n",
    "for epoch in range(num_epochs):\n",
    "    #Load in the data in batches using the train_loader object\n",
    "    for i, (inputs, labels) in enumerate(train_loader): \n",
    "        inputs = inputs.float()\n",
    "        inputs = torch.squeeze(inputs, 1)\n",
    "#         labels = labels.type(torch.float)\n",
    "\n",
    "        # Move tensors to the configured device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%50 == 49:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "953e1204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 22600 train images: 99.86725663716814 %\n"
     ]
    }
   ],
   "source": [
    "## Check accuracy\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        inputs = torch.squeeze(inputs, 1)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "#         print(predicted)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print('Accuracy of the network on the {} train images: {} %'.format(total, 100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc778345",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # KFoldCV original implementation\n",
    "# k_folds = 10\n",
    "\n",
    "# num_classes =10\n",
    "\n",
    "# if num_classes == 2:\n",
    "#     f1type = 'binary'\n",
    "# else:\n",
    "#     f1type = 'weighted' # is this the best choice\n",
    "\n",
    "\n",
    "# # For fold results\n",
    "# results = {}\n",
    "# runtimes = np.zeros(k_folds)\n",
    "# f1s = np.zeros(k_folds)\n",
    "\n",
    "# # Define the K-fold Cross Validator\n",
    "# kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "# # Start print\n",
    "# print('--------------------------------')\n",
    "\n",
    "# # K-fold Cross Validation model evaluation\n",
    "# for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "#     # Print\n",
    "#     print(f'FOLD {fold}')\n",
    "#     print('--------------------------------')\n",
    "\n",
    "#     # Sample elements randomly from a given list of ids, no replacement.\n",
    "#     train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "#     test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "#     # Define data loaders for training and testing data in this fold\n",
    "#     trainloader = torch.utils.data.DataLoader(\n",
    "#                       dataset, \n",
    "#                       batch_size=batch_size, sampler=train_subsampler)\n",
    "#     testloader = torch.utils.data.DataLoader(\n",
    "#                       dataset,\n",
    "#                       batch_size=batch_size, sampler=test_subsampler)\n",
    "\n",
    "#     # Init the neural network\n",
    "#     network = RFUAVNet(num_classes)\n",
    "#     network = network.to(device)\n",
    "# #     network.apply(reset_weights)\n",
    "\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize optimizer\n",
    "# #     optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "#     optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate, weight_decay=l2reg, momentum = momentum)  \n",
    "\n",
    "#     # Run the training loop for defined number of epochs\n",
    "#     for epoch in range(0, num_epochs):\n",
    "#         # Print epoch\n",
    "#         print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "#         # Set current loss value\n",
    "#         current_loss = 0.0\n",
    "\n",
    "#         # Iterate over the DataLoader for training data\n",
    "#         for i, data in enumerate(trainloader):\n",
    "#             # Get inputs\n",
    "#             inputs, targets = data\n",
    "#             targets= targets.type(torch.long)\n",
    "                        \n",
    "#             # Move tensors to configured device\n",
    "#             inputs = inputs.to(device)\n",
    "#             targets = targets.to(device)\n",
    "            \n",
    "#             # Perform forward pass\n",
    "#             outputs = network(inputs)\n",
    "            \n",
    "#             # Compute loss            \n",
    "#             loss = criterion(outputs, targets)\n",
    "\n",
    "#             # Zero the gradients\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             # Perform backward pass\n",
    "#             loss.backward()\n",
    "\n",
    "#             # Perform optimization\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Print statistics\n",
    "#             current_loss += loss.item()\n",
    "#             if i % 50 == 49:\n",
    "#                 print('    Loss after mini-batch %5d: %.5f' %\n",
    "#                       (i + 1, current_loss / 50))\n",
    "#                 current_loss = 0.0\n",
    "# #         print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "#     # Process is complete.\n",
    "# #     print('Training process has finished. Saving trained model.')\n",
    "\n",
    "#     # Print about testing\n",
    "#     print('Starting testing')\n",
    "#     print('----------------')\n",
    "\n",
    "#     # Saving the model\n",
    "# #     save_path = f'./model-fold-{fold}.pth'\n",
    "# #     torch.save(network.state_dict(), save_path)\n",
    "\n",
    "#     # Evaluation for this fold\n",
    "#     correct, total = 0, 0\n",
    "#     network.eval()\n",
    "#     with torch.no_grad():\n",
    "#         starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "#         runtimes_thisfold = []\n",
    "#         f1s_thisfold = []\n",
    "#         # Iterate over the test data and generate predictions\n",
    "#         for i, data in enumerate(testloader, 0):\n",
    "#             # Get inputs\n",
    "#             inputs, targets = data\n",
    "#             inputs = inputs.to(device)\n",
    "#             targets = targets.to(device)\n",
    "\n",
    "#             # Generate outputs\n",
    "#             n_instances = len(inputs)\n",
    "#             ys = torch.empty(n_instances)\n",
    "#             ys = ys.to(device)\n",
    "\n",
    "#             for i in range(n_instances):\n",
    "#                 instance = inputs[i]\n",
    "#                 instance = instance.float()\n",
    "#                 start = time.time()\n",
    "#                 starter.record()\n",
    "#                 yi = network(instance)\n",
    "#                 _,pred = torch.max(yi,1)\n",
    "#                 ender.record()\n",
    "                \n",
    "#                 torch.cuda.synchronize()\n",
    "#                 curr_time = starter.elapsed_time(ender) #miliseconds\n",
    "\n",
    "#                 runtimes_thisfold.append(curr_time*1e-3)\n",
    "#                 ys[i] = pred\n",
    "\n",
    "\n",
    "#             # Set total and correct\n",
    "#             total += targets.size(0)\n",
    "#             correct += (ys == targets).sum().item()\n",
    "#             f1i = f1_score(ys.cpu().numpy(), targets.cpu().numpy(), average=f1type)\n",
    "#             f1s_thisfold.append(f1i)\n",
    "            \n",
    "#         mean_runtime = np.mean(np.array(runtimes_thisfold))\n",
    "#         mean_f1 = np.mean(np.array(f1s_thisfold))\n",
    "\n",
    "#     # Summarize and print results\n",
    "#     results[fold] = 100.0 * (correct / total)\n",
    "#     runtimes[fold] = mean_runtime\n",
    "#     f1s[fold] = mean_f1\n",
    "#     print('Accuracy for fold %d: %.2f %%' % (fold, 100.0 * correct / total))\n",
    "#     print('F1 for fold %d: %.2f ' % (fold, mean_f1))\n",
    "#     print('Runtime for fold %d: %.4f s' % (fold, mean_runtime))\n",
    "#     print('--------------------------------')\n",
    "\n",
    "# # Print fold results\n",
    "# print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "# print('--------------------------------')\n",
    "# sum = 0.0\n",
    "# for key, value in results.items():\n",
    "#     print(f'Fold {key}: {value} %')\n",
    "#     sum += value\n",
    "# print(f'Average Accuracy: {sum/len(results.items())} %')\n",
    "# print(f'Average F1: {np.mean(f1s)}')\n",
    "# print(f'Average Runtime: {np.mean(runtimes)} s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
