{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d254ebea",
   "metadata": {},
   "source": [
    "## Implementation of RFUAV-net\n",
    "July 1, 2022 \\\n",
    "efficient CNN method \\\n",
    "status: testing with a small sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "3e3259ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "bf423e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper functions\n",
    "def normalize_rf(rf):\n",
    "    \"\"\"apply normalization to data in the numpy array format\"\"\"\n",
    "    rfnorm = []\n",
    "    for i in range(len(rf)):\n",
    "        rfnorm_i = np.zeros(rf[i].shape)\n",
    "        for j in range(2):\n",
    "#             print(rf[i][j])\n",
    "            r = (np.max(rf[i][j])-np.min(rf[i][j]))\n",
    "#             print('range:', r)\n",
    "            m = np.min(rf[i][j])\n",
    "#             print('m:', m)abs\n",
    "            rfnorm_i[j] = (rf[i][j]-m)/r\n",
    "#             print(rfnorm_i[j])\n",
    "        rfnorm.append(rfnorm_i)\n",
    "\n",
    "    return rfnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a39a0cf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff 5 file name: 00000L_13.csv\n"
     ]
    }
   ],
   "source": [
    "## Import data -  Drone RF\n",
    "main_folder = '/home/kzhou/Data/DroneRF/'\n",
    "high_freq_files = os.listdir(main_folder+'High/')\n",
    "low_freq_files = os.listdir(main_folder+'Low/')\n",
    "\n",
    "high_freq_files.sort()\n",
    "low_freq_files.sort()\n",
    "fs = 40e6 #40 MHz\n",
    "\n",
    "# feature & results lists\n",
    "Xs = []\n",
    "ys = []\n",
    "y4s = []\n",
    "y10s = []\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    # load RF data\n",
    "    rf_data_h = pd.read_csv(main_folder+'High/'+high_freq_files[i], header=None).values\n",
    "    rf_data_h = rf_data_h.flatten()\n",
    "    \n",
    "    rf_data_l = pd.read_csv(main_folder+'Low/'+low_freq_files[i], header=None).values\n",
    "    rf_data_l = rf_data_l.flatten()\n",
    "    \n",
    "    if len(rf_data_h)!=len(rf_data_l):\n",
    "        print('diff', i, 'file name:', low_freq_files[i]) \n",
    "        # not sure why one pair of files have different lengths (ignore this for now)\n",
    "    else:\n",
    "        # stack the features and ys\n",
    "        rf_sig = np.vstack((rf_data_h, rf_data_l))\n",
    "        rf_sig = np.split(rf_sig, 1000, axis =1) # samples of 1e4\n",
    "        Xs.append(normalize_rf(rf_sig))\n",
    "        \n",
    "        y_rep = np.repeat(int(low_freq_files[i][0]),1000)\n",
    "        y4_rep = np.repeat(int(low_freq_files[i][:3]),1000)\n",
    "        y10_rep = np.repeat(int(low_freq_files[i][:5]),1000)\n",
    "\n",
    "        ys.append(y_rep) # 2 class\n",
    "        y4s.append(y4_rep) # 4 class\n",
    "        y10s.append(y10_rep) # 10 class\n",
    "\n",
    "        if int(high_freq_files[i][:5])!= int(low_freq_files[i][:5]):\n",
    "            raise Exception(\"File labels do not match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8077daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape the arrays\n",
    "Xs_arr = np.array(Xs)\n",
    "Xs_arr = Xs_arr.reshape(-1, *Xs_arr.shape[-2:])\n",
    "ys_arr = np.array(ys).flatten()\n",
    "y4s_arr = np.array(y4s).flatten()\n",
    "y10s_arr = np.array(y10s).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3dfc9685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99000, 2, 10000)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086be216",
   "metadata": {},
   "source": [
    "### Apply Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45548d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LogSoftmax\n",
    "from torch import flatten\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "49dd0e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define dataset\n",
    "## Create a dataset class\n",
    "## Creating a custom dataset\n",
    "class DroneRFData(Dataset): ## NUMBERICAL DATA\n",
    "    def __init__(self, Xarr, yarr):\n",
    "        self.Xarr = Xarr.astype(np.float32)\n",
    "        self.le = preprocessing.LabelEncoder()\n",
    "        self.le.fit(yarr.flatten())\n",
    "        self.yarr = self.le.transform(yarr.flatten())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.yarr)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # all data must be in float and tensor format\n",
    "        X = torch.tensor((self.Xarr[index]))\n",
    "#         print(X.shape)\n",
    "        X = X.unsqueeze(0)\n",
    "        y = torch.tensor(float(self.yarr[index]))\n",
    "        return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "45b4212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DroneRFData(Xs_arr, ys_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "f03644a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcd2fd07d60>]"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAtx0lEQVR4nO3deZgU1fXw8e+ZGRh2GGBEhIFBBRUEBEcQV1BQxC0ak59ookYS3ywmbq9m1GiMeU2MJhr9aeKSuMSoxLhEBIwbqIgKDLJvMsqOMsO+Ccxy3z+6uumluru6p7q7qud8noeH6arq6lt1q07dWk5dMcaglFLK/wpyXQCllFLu0ICulFJ5QgO6UkrlCQ3oSimVJzSgK6VUnijK1Q937drVlJeX5+rnlVLKl+bOnbvZGFNqNy5nAb28vJyqqqpc/bxSSvmSiKyJN04vuSilVJ7QgK6UUnlCA7pSSuUJDehKKZUnNKArpVSeSBrQReQpEakRkcVxxouIPCwi1SKyUESGul9MpZRSyThpoT8DjE0w/hygr/XvGuCvTS+WUkqpVCUN6MaYD4GtCSa5EPiHCfgU6CQi3d0qoFJK5dLOfXW8Pn9DrovhiBvX0HsA68I+r7eGxRCRa0SkSkSqamtrXfhppZTKrF++vJDrJs5n+dc7c12UpLJ6U9QY84QxpsIYU1Faapu5qpRSnrJxxz4AvjnQkOOSJOdGQN8AlIV97mkNU0oplUVuBPRJwBXW0y4nAjuMMV+5MF+llFIpSPpyLhF5ERgJdBWR9cCvgRYAxpjHgKnAOKAa2Av8IFOFVUqpXPFD78tJA7oxZnyS8Qb4mWslUkopD5FcFyAFmimqlFJ5QgO6UkrlCQ3oSinlgPHBRXQN6Fn21Eer+Mk/50YMe2XuepZs3JGjEqVu+94DPDJtJYvW7+C1eetzXRxf+8cnq7n11UXU7NqX66JkRUOj4eH3VrJzX52r8/3w81reX1HD9BU1/ODp2Wzc/o3j71bX7OaFWWvjjpfQRXTDkx9+ydc79jF3zTamLPTew3w564Kuubp78tKYYTf9ewEAq+89N9vFScvtry1myqKv+OPbnwNw0ZCeOS6RP+2ra+DO15cAsHrzHl685sQclyjz3l22iQfe+Zx1W/dy/3cGuzbfK56aHfH56mfm8N/rT3P03XEPzeBAQyOXDe+VcLrVm/dyz9RlTF70FQvWbQfg3EHe2me1ha5Stnt/fa6LkHf2HGge6/RAfSMAe+sym3W5a5/z9XmgodHRdA2NgWsuu10+u3CTBnSVMh9cSlTKdcYHW74GdKVU3jEu3sEMXkIPzlLEu0+ma0BXKfPu5qxU86YBXaXM+yeeyqv8uO34qcwa0JVSWZfps7xMBOHgPL18hqoBXSmlEoi+hu5lGtCVUlnng9gYl4fviWpAt7OvroHKVxayZfd+x985UN/Ira8upGZn0zP+9uyv55aXF7Djmzo++WILf33/CwC+rN3NXZOW0NjYtN1hzZY9nP3ghzwybWXcaRoaDXf8ZzHrtu5t0m/ZeXR6NeMemsEXtbtdne/05TU8PXMVAHUNjdz22iK+2uE8YzBo9qqtnPKHaUxd5G4mYHXNbn7zxhLbJzAEqFq9lYffi18nmfKPT1bzztJNWfmtZLFw4uy1Ka33YD3H8++qdbz62fqIffONBRt5qWpdzLS3vbaI+oZGHnp3Jde+8BnTV9Twu6nLWPH1Lsflmbd2Gw+887nj6d2mmaI2Js3fyMQ562g0hvsucZbN9u6yTbw4ex07vqnjL5cf36Tff+7TNbxUtZ6Sti15/IMvAfjJyCO45rm5VNfs5vLhvejbrX3a87/2hXms2LSLFW/v4toz+tpOM2/tNp77dA1Lv9rJKz85Ke3fsnP/WysAmPDMHN6/eZRr8/3BM3MC/5/ch4+qN/PCrLVs2PYNz149LKX5fPfxTwD46fOfuZq9O+HZOazZspcrR5RT3rVtxDgDXPJY4Hd/caZ9nWRKKFvVA5nKla8GgrPTsgTrOVrwmHnzywtDw7btqeOx7x/Pz1+cB8B3K8oivvPCrLWMHXAoD74bCMiTo1L7nTyHftFfPgbgxjH9HJXfbdpCt5FOAoGb19fizSvYsmvqKZ8fEiTy0cHnmHNbjlzy+paXqG5C9efh26Ia0JXyAO+GiMxobsubLRrQfcTrrRuVPq3bNGVxxfmhjjSg+1Ju2zduplUrpdyjAd1lrsY6jZtN5sVVaLeN6CUIH/BBQ0YDukvcvNEVd17e3548w4sBsjnfDA3K1tldJm/8e7keNaB7ULJtvqkbVCp36TO5A3r5rXVKRfNDe0oDupfFiXfZaOT4Pdb6YedrjnJ5EG/y474+2Kh8G9D/u/hryiuncOO/5tuOnzh7LT974bPQ5/31DVzwyEfMWb01NGzI3W9TXjkl4ntXPzOHSQs2ArBnfwNj//why77aCcDkhRu5MqqrKwhkif70+c8ihjU2Gsorp1BeOYVHp1fHfOfPVvJCVVh5/jNvQ8S4YFJRiLVBjn7gA/709oqIUTOrN4d+7/63lgOwefd+xjzwAWu27OHqZ+bw+vwNXPX0bBZtONh/6Ybt3zD6gQ/Y5DDDdfXmPcxYuTnpdOWVUzj34Rl8c6CBcx+ewcL122OmWbV5D0ff8San3Ted//NcFQB7D9Qz7qEZLFqffh+r4f1Vhu/D9Q2NXPyXmXxcHVv+/y7+iu/9bZbt/HbsrePsBz+kuiZ5xuAPnw2s5+dnreEXVgILwMn3TmPNlsis2/AAsyDB8t7+2iJuemkB5ZVTUspCDK77YHdpQT99fq5tpmQ8f33/C8orp/D6/A224xet38G4h2awN81el1Zu2sXZD37Ijm8O1lt55ZTQfhf0949WMe6hGaHf2r2/PpRMFm3Tzv0R+xbAm4u/Zu0W9zOf7Vw/cR7PfbomZvjTM1dxs9XlZCb4NqD/2Opo+dV59htZ5auLIjpx/aJmDwvX7+CO/ywODdu2N7YrqWnLa5hZvQWAT77cwvKvd/Enq+/Ma1+Yxwef18Z8Z+3WPTHDwrvYCmZGhvvzu4EU71+Fled66+C0vz5Ol1hhLYT/nRZ5kLjxpfmhvx+dHnhVwOQFG1lZs5unPlrFtOU1XDdxPu+viCz/Pz9dQ3XNbl6e66yz58c//DL5RJYlG3eyYP12lmzcyf+bssx2mn11jazdupe3lgRSz+et3c7Sr3by+zftp3diZpwDztc79/HZ2u0R2YNBP/7nZ3xkE+gBpq+oYcWmXTHr3M67ywLr+fbXFocaBhA4cKbr+VlreeWzQP2k8mqA4Lq/Z2rkupy66GtusVkH8fzhv4EGwnUT59uOv2fqUpZ+tZP5UQcOp/783kpWbNrFh1H71o0vRQa+304O/E7wt2av2pJwvj/6R1XMsKesV0Nk2n/mb4yINUG/eWMp/3a4r6XDtwHdq4KnZU6vPRf4/dpGErk4TTVx/laqKfeEDmZqe3efbTYBPbPp7ulXcIFLNeB2OrJbgTi43p2Wzq3f9e4ud5Afrsm6LVFAzcbqyPdV3mwCelAqR9cmHc0dTpfSEyeJ5pOhCNbk1kia7y/xcCPIfzwYxcK3q0xVtd2225SDqAdXY4xmE9CbUpGZDC4FLs3bbjZubIBNfWzxYC8vGqGzze9rvKnbnv0+kXiefj9rajYBPSgTG3l4wE85+Oe4KRrv190ultP5ZfLSWFN3VvcuQyk3JGsk2G1zfg/YyTS7gJ6KdOo+1Q3GtRZ61g4MqS1gujuQWy16fe9M5qWziu3qJRt1laxvGGevz/UuRwFdRMaKyAoRqRaRSpvxvURkuojME5GFIjLO/aK6I5W4l+y95KF5pvDdaNl4yiWXd+VDN0VTLIIX39nu1+v6XlyX4bK7fXp7XTRV0oAuIoXAo8A5QH9gvIj0j5rsV8BLxpghwKXAX9wuaFM16Rq6i/NKNu+055OwZZG7Jwty0SlA+OK6GSy0sW8vnVXspF4ysb6TzTPReD9Uv5Mu6IYB1caYLwFEZCJwIbA0bBoDdLD+7ghsJIvKK6fwwc0jWb1lL1c+NZv7LhkUMS5cXUMj5ZVT+ON3BkdMs+ius2jfqkXEtMHMtbeXboroW/Pw26YC8MpPTuLbf/044jv/XRLIYL1t3NGOyl61Zpuj6a56ejarNkcmMP30+blMXfS17fTllVO4zkFXZsH+SiGQOWuXbNXvV29yoL6RX517DC/Ojs0wfGPBxlC3XtGusDJrP7IyWX930cC4ZSmvnMIvxwbWWzCrsqHR0Pf2qXzruB6hJLLxw8r4/cWDuPXVhSzasIPJPz81Yj4Pvvs51TWB/ko//LyWk++dFpHYs2H7N2zauY9uHVrxixfnRWTJzl4VmV0Yvv1MWrCR/3vWUbz/eQ13v7GUlfecEwpM//x0TUSSWNCc1Vs5obxzxLAvanYz6o/vJ1wPibz62fqYpJugL383jn6/epPLh/fi2U8CmYrxDqbTl9cw6uhDIj7/4Jk5zLtjDCVtW7Jg3XYufHRmTNlm33Ym7yzbxO2vBZa3RWFg/pc9OYuXfzyCp2auYsc3dXz/xN78+J+BDOpVvx/HgYbGUHLSJ19siVnOeIlLdt5fUcuIw7sknGbz7gMxw8IDdnnlFB4ePyRi/BU2meBBv50cCHnhx6K/f7SK305eysAeHRnYs2Pc727dc4Chv30n9PnF2WsZP6xXwvKnw8kllx5A+F683hoW7i7geyKyHpgK/NxuRiJyjYhUiUhVbW1sxmVTTF9ew5NWFmOiLLitewIBK5geH7R6c+KUYLsswgfeic0ADfrd1OVxx6UjOsMTiBvMg4Kp005bqXbBHAKvNgDiZnteN9E+mNtJ1KEvEMqIXL8tEID31zfQaCIzgoMHlRdnr2Pxhp0x8wgG8yC7LM1g4J60YCOzwoL4g0lS6z9YWctdk5ZQ32girsfe+XpsMAds+7t8c3HiekvGLvM4qK6xkfpGEwrmiTz+4Re2n5d9HVin8V4PMHfNtlBwA6hrOLgiXpi1lqmLvmZm9RYefu9gZm2jCfTpGbTZQQfsiTbbJz78Mq3T2+jLT39uYofOwfWwaMMO27oOWrIx8tUOjRk63XPrpuh44BljTE9gHPCciMTM2xjzhDGmwhhTUVpa6tJPh83fwUlRcCNJdX3q6XZ25PomptvXm7N9889u1vGWKSOXNNyfpauilzmd8nr5XoqTgL4BCO8eu6c1LNwE4CUAY8wnQCugqxsFdMppKzQ4lRsbXnN4tjrXO2im1nG85Ur2FETEPNKMiJlqnWWLIf7BIHzZonfJlG+MJ1tN6Txdk/pXfMVJQJ8D9BWRPiLSksBNz0lR06wFzgQQkWMIBHR3r6k44GQ/SbuFnvebQvoy+lIFDx4zU8o2djjMi9JZ96kcEHMhpoXu84NrtKQB3RhTD1wLvAUsI/A0yxIRuVtELrAmuwn4kYgsAF4ErjJZXlNONz5Js42eZ/UewysbdrYeYYu7vMmeU47z3VTWXiZXtZvzTueJDxOnhW6M8cT5rBsNs/CzRrfySNzi5CkXjDFTCdzsDB92Z9jfS4GT3S1aZhTEaaF7sSXYVG4sk5NZCJlrdWa7XpKmhscbHjdnIXZYJi+52JU/5Z9z6X0nMZfL3O6mMZ35ubzqCwuExobkM83W5dm8yRR1urrSbQF6o/2aGo80un3F2WW7pu2cXq2X6KCTzmLGO/PxyiK7cu8s4lUf3moJ5k1AT3Xrc+PutsfqMka2yueVndUNyZYlfJWmu9wZbaFnoTKMIe7CRyZ1RY5LtZWa6Gwp3U07+oDT1Nd7eO2SS/4EdIcO3hRNrSobG41nW1Zu8FpLI1ecbBeprCnbm6JN3I5SvbZd12iydo8k3sEqvfe9NLEwNty+aev01R3RB6dMXYKRXN0Mq6ioMFVVsV1EOTFv7TYu+svHySdM0ceVZ3DSvdNcny/A0Ye2Z/nXyfukVJF+cWbflLpd85qK3iWOs4HdcFS39qzYFLudXTmit6Nko6Y6q3833l66KeO/4yclbVrEJO2ddEQXXvjRiWnNT0TmGmMq7Mb5soU+M07fj01ltyO4RYN5evwczCGz21Qqv5eNYK7s2WVgf/xF4v5Q0+XLgK6U8qY8virpCxrQlVKuyef7TH6gAV0ppfKEBvRw2rpQSvmYBnSllMoTGtDD6aPYSjWRnubmkgZ0pTKpmcU3vSmaW74M6AvW70g+URo+ztDz7ar52rW/PtdFyKrpK2pyXYRmzXcBfd3WvbyToUy0J2esysh8lWouvP4+9Hznv4C+LXHfn0op1Vz5LqDrNTqllLLnu4DeoOd0Silly3cB3e8d7CqlVKZoQFdKqTzhv4DemOsSKKWUN/kuoDdoC10ppWz5LqDnqoclpZTyOt8FdH3IRSml7PkwoGtEV0opO74L6BrPlVLKnu8CulJKKXu+C+jaQFdKKXv+C+h6zUUppWz5LqArpZSypwFdKaXyhKOALiJjRWSFiFSLSGWcab4rIktFZImIvOBuMQ/SKy5KKWWvKNkEIlIIPAqMAdYDc0RkkjFmadg0fYFbgZONMdtE5JBMFdjobVGllLLlpIU+DKg2xnxpjDkATAQujJrmR8CjxphtAMaYjHUsWFevAV0ppew4Ceg9gHVhn9dbw8L1A/qJyEwR+VRExtrNSESuEZEqEamqra1Nq8D3v70ire8ppVS+c+umaBHQFxgJjAeeFJFO0RMZY54wxlQYYypKS0vT+qHaXfubUEyllMpfTgL6BqAs7HNPa1i49cAkY0ydMWYV8DmBAK+UUipLnAT0OUBfEekjIi2BS4FJUdP8h0DrHBHpSuASzJfuFVMppVQySQO6MaYeuBZ4C1gGvGSMWSIid4vIBdZkbwFbRGQpMB242RizJVOFVkopFSvpY4sAxpipwNSoYXeG/W2AG61/SimlckAzRZVSKk9oQFdKqTyhAV0ppfKEBnSllMoTvgvoZ/XvlusiKKWUJ/kuoB/bo2Oui6CUUp7ku4Cur89VSil7/gvo+vpcpZSy5b+ArvFcKaVs+S6gK6WUsue7gK4NdKWUsue7gK7XXJRSyp7vArqGc6WUsue7gP72kk25LoJSSnmS7wL6qs17cl0EpZTyJN8FdCTXBVBKKW/yXUDXeK6UUvZ8F9CVUkrZ811AF22iK6WULf8FdL3oopRStvwX0DWeK6WULd8FdKWUUvZ8F9C1ga6UUvZ8F9BbFPmuyEoplRW+i44PXzok10VQSqkm+c0FAzIyX98F9B4lrXNdBKWUapJDO7bKyHx9F9CVUsrvMvUWcA3oSimVJ3wX0LV/C6WUsue7gK6UUsqeDwO6NtGVUn6XmTjmKKCLyFgRWSEi1SJSmWC6b4uIEZEK94qolFL5JWc3RUWkEHgUOAfoD4wXkf4207UHrgNmuV1IpZRSyTlpoQ8Dqo0xXxpjDgATgQttpvst8Adgn4vlU0qpvNMyQxnvTubaA1gX9nm9NSxERIYCZcaYKYlmJCLXiEiViFTV1tamXFjlPcP7dM51EZTynVFHHZKR+Tb5MCEiBcADwE3JpjXGPGGMqTDGVJSWlqb1e358bHHkUektqx/cNu6YXBdB+djqe8/NdRGybvW951JQkJnXDDoJ6BuAsrDPPa1hQe2BY4H3RWQ1cCIwSW+MHpTPb4jU99Mr5R1OAvocoK+I9BGRlsClwKTgSGPMDmNMV2NMuTGmHPgUuMAYU5WREiullLKVNKAbY+qBa4G3gGXAS8aYJSJyt4hckOkCxpQn2z/oAj+WWSnlP0VOJjLGTAWmRg27M860I5teLOUX2serUt7hu0xRP94U9WOZnTJ6/qGUZ/guoPuRhjylVDZoQM8Ck8dNdL3kopR3aEDPgrLObXJdhIxp3bIw10VQyjcy9Pj5wflndvbe8NyEYRGf+3VrxxPfP75J8zykfTHtix3dU+au8wfQo5N913mXnlBmOzxVxWGpxL27tOHUvl1Dn884uulZadeP7ssNo/vx/RN7h4Y9e/Uwjjykne30Q3p1SjrPsQMOTbs8t407OvT3SUd0iRn/0KXHOZ7Xo5cN5ZD2xY6m/fP/OJ9vx9YtIj7/T4U7de1VXdq2TOt7L/xweMyw8wZ1b2pxkjq0Q2Q3cJOuPZk3rj0l6fc+rjyDq0/uwzHdO3D/JYM4vZ/zxMEPbxmVcjlT4buAns5NuFP7Rq7wt284nbPSDCajjwkEx3suGsiQ3iWOvtOyqICZlWfYjrv324PSKkfQsT06ADB+WC8ALh7agw9uHsVzEw7uJDeM7pd0PuGB2s71o/tx3ei+oYPDyKNKE27IToLXY98/nhaFqTVZyrsEznbG9D9Yf1edVB4z3XmDDnM0v67tWnLuoO60cXim8a0hPZJPZIkO/t0y1I9krnzruMh1fNnwXhwftk+UOjxInnRk14jP15x2OI9cNjTl8tx1fsw7AxMa079bxOdBPTsxsGfHiGHRQR+gW4dW3Hl+f9687lS+U1HGBYOdbWsAPUsye7buu4DuFcYYb14bz3CRcv1Ui9NfT/XMVjTltcmE3N4vSrUOnWzLdrOMHtTooTigAT1lB6vTQ/WYUCaCcLJdJ9Px0b3ZZy+Q6yEjs3J1TPZSGPBdQPdSEG1o9FBhLN4rUeY1x2X2gpj1HhVRsx1fUz4rc/ANuyliDhwe2gB9F9C9xAunWm49NphvVxycL0/m6jDXl6dywU9L7KR+nCyPF+JAkAb0JvBQPSbkZjmdzstvz6dno7T5dtCMlvPFy9IKjr5W76Uw4LuA7qUg2uClwmSZ128ier18zUE+VIGTRdAWep7wQkVG7zSefPImgVRb8j5bvLwWXXO5DuCp/rxb25KXtknfBfQOrZ0l82TK0Ye2BwLP2A44rENK300nSyzZ89EDDgs8NxudxBIu0bigooKDm8JpDhIlkh04nPbI4sZ15qbsUMeVdQJgUNTzx6mySxwrbRf5DHPvLrnLGC7MdIoi0Ktzm4h9It3LbuVd2qb1vVT76Ty81D4pLpyTM714SYO5kNvomIaeJW34z89OxhjDRX/52Haav1weyPy75LFPQsMW3XUWA+96O2K6GbeMYs7qrdz40gLHv3/96L6MPKqUIb1K6H9YBxas28GiDTtC41//2cl857FPONDQaFv2tVv3xp33TWP68ad3Pg99/sO3BzJ2QHdqdu2jqLCA6ctrGFzWiW//NbDcMyvPoGu7lny3oiert+yJmd8/Jwxn8cYdlHc9uIMMOKwDN47px7a9dQzs0ZG2xYXMXrWV6prdAJzer5Rnrx5GeWWge9jnJgxznAzx5nWncs5DM4DkO9fUX5yacPzLPx4RUX+PXDaE48o6cfnfZsX9zvG9S5i7ZlvC+U676XTaFRdR32iYv257qHvAe789iNP6ldKqRSE/ff4zAI4obcsXtbHr1c5zE4Zxxp8+CH3u0ak1A3t25JWfjGDrnjq6d2zFgMM6cGiH1ox/8lPbeTx06XFcN3E+AG9dfxoT56zl6Zmrk/72v388gsICoWVhAe+vqOGPb38eMf73Fw/ktc82MHv1Vn50ah/+54QyZq3aSp+ubbnsydj1WSAQ7wGuu87vz11vLA19vmDwYUxasJGTj+zCRUN6cO6g7pxQ3pkTyjuHttOgF3403Pb3IJB92dBo+GrHPk4oj0zYu3JEb0YedQi/fGUhNbv2h4Zfd2Zf+nVrz7ptezl/8GHMX7s9NO6x7w2lZ0kbzvvfjyLmdc9FxzK8TxdWbtrF2QMO5beTlxLt7RtOY/7a7Qwq68iEZyL76Znyi9hM0lEJMrHPHdSdMcd04/p/zY87jZt8F9DhYKvquxU9ealqfcz4cQNj04bbt4ptpabzjpWiwgIqygMdIxcXFTK4rGNEQB9c1okrRvTmbx+tijuPwgKxfeRxzIBuEQH9f04IZH92bBMoe59T+kRMH2wZDOlVEgro4XM9pW9XTukbmYVXVtKGM4+JzJDrWdKG+99aDhDamfp1a8fnm3ZT2r6YPl1jW0x2LZdjujs7YznpiC70T3J2E1zHACcf2cVR5qeT1PPwVtlhYS2rVi0KuXhoz4hp2zl8tQNAcYvIM6le1rZ1fO/ITrRH2LymIOjC43qEAvpRh7bn1+cPYNryGtZsid8IADghbF0d26MjT85YxY5v6sLGl/DaZ4FeI0cf040jD2nPkYcEzjRbtyjkm7oGzh7QjbeWbALg/MGH8fr8jba/dVhUazSYuTusvAsiQnFRIRceZ59N29f6zUTztdsnf3PhsUDsJZ0bxkRmQIcH9LbFRRzbI/as6/LhgYzoeK+sAOjXrT39utmXNXhG7FRZSRu+NaRH1gK67y65hPPStatUZOLae1OfKolXpEw8rRK+Y7ozf59uCDngZE053TyzvdaTbSvh25VfY0NT+Tug57oAacrkxpZs3k5vXGWyjE0J4onKleubct6V2opJpcGRaEq3qyMLtwFcl+1t0t8B3a8RPYfibWCpDk8m0U3TiJZUmodlu3LlcnuIXl63dmS3l8lJsRIG6TgL5mR5m7pOkt2gDB/bXA/u/g7oHmij5+tBJd5i5evy2vHroqZzcIk4a3JpwTUXIPt8HdB9u8dlQKb2nXizbcrPhe/obl6jz2X88HvwCm8ceaGhZCfZKs5EFfitWn0d0L2Q2OM1ydaI0wCayQSlXCWAZJOXyiwkD9Lh5c1U2ZsaG/0WXHPB1wHdQ/uMfyTZKaJ3Zj/sRF4Inl7O0I04I3JwDTxRQymXm0Pyxkhmn8jyA18H9PBnleNpShbXUAfdqA3tFdtr0eAy+++NspJYgl2vhU83vE9nOjvswqtru9ieYA7vGniuNjopI6hnSWA9nBCnl6XonWXkUYFkiY6tI8vUy3ruePjhidd9n65t6dYhUM7oLMXwXmDOGhB4Jv7MBMkZ4TtVcB12sPIKWoc9/+32I5anWD3pnFBewlFxnksOat0i9b5Vg8/Nh6+eYI9YTRHemxMkzhQOrv8Rhx98Pv70fpFlCPY8NLBHx1D9A1T0Lgk9622XNR3d9WGrqHXUoVXi5/wHR2XvJguu4Zm40c/LNxe+TCwK+t7wXozsV8qp900HYMGvz4pots/91eiYjSieogKh3kr2mXXbmRyob6RnSWvOf+QjFm/YCdj3U3nx0B4M69OZ0vbF7NwXSOY4f/BhHFfWic5tW7KvriE07R3n9efHI4+ga7tiln21M5S8MPv2M+nQqgWtWhTyceUZnHTvtIRlff/mkRyoj8xEHdizIzNuGRUK3NHeu+l0Fm/YGfcgFX1Kfus5RzPhlD4x3Yj169aej345KuJAGb7eF//mbFbV7mFgz45Mu2kkm3buo2v7Yg7UN/LItGqe+Xg1ZZ0PfveB7x7HHef1p1ObFmzfW8emnfs4IkFKdnAdlrRtybw7xlBUKHy0cnNofNWvRrNtzwEA5t85hroGg8Ew7J734s4znpvOOoqrTi6nQ6sWNBrD3gOBugzWV+2u/Yx+4AP21zfStriI/15/Kl/U7OFnL3zmaP4f3DKKA/WNFBUKjda29+jlQ9mxty7udyb//JRQ9uPSu88OlSnc7y8eyPWj+zJ/3XYG9uiYsKFw/yWDufWcY+jWoZhRRx9CUWEBPTq15tS+XfnBM3OortnN01edQLcOrWhXXETrloV89MtRGBNoJIgIM24ZZZsQ9Ovz+/Pcp2sA+PTWM2kblqg167bIz3YmXjOC3fvrQ5+D8fyNa0+x3c6P6d6BGVafncHyXHpCGRPnrANg3h1jYr4z+/YzwcQmhtlZeNdZSaeJlu0TN18HdBGJ2JCiWyJdbFqy8RzasRXrt30DBPoMDCoraRMK6Hat/fAyhB88gsPCN9qiwgK6dwzMY1DPTqHhh7Q/+HtOWhbtiovAZtESZb4WFxVG9PeYTFFhQdyyRL8KIHy9tysuCvXL2La4KCIz0+69NC2LCkLru1uHwoh1HxS+U4SvwxIrUIXvM13bFYfOYDq1Sa/T4qDCAomomzYtA3UZHBa9vo8+tANbdx9wPH+7eiwuKuSQDgfXU/iBtn2ryOzHNi2LQmUK17KogLLObRxlQrcsKuBQq6/T3mHvUAn/bsuigogDe3T9x/udosKDFwAOjepP1a6eo7VuWUjrsG0meLmoTXFhqO6jRZclvPNvu++E128yHWyyzZPJ9g1mX19yUe7J5vvL/f5ESK54vQegTAuWx8O3K3JOA3oKNA4pv8qLIBja/9zJZHX2k/7a6TWgqwh+3u+9dMDNxKm2G3P00jpKlS9b6Fkuqwb0JPy8A3hNutu2r+rA5bL6KnhlWIG1IWRzlTR128t29TkK6CIyVkRWiEi1iFTajL9RRJaKyEIReU9EertfVKXseSroZfSlZunz0ipKVzC4+imhMNv5CUkDuogUAo8C5wD9gfEi0j9qsnlAhTFmEPAycJ/bBfUGPzUVU+OrVnAcXloGr1579WapnAmuUx/F86xz0kIfBlQbY740xhwAJgIXhk9gjJlujAm+hf9ToCdKKeWi4AE7mwHdbwdAJwG9B7Au7PN6a1g8E4A37UaIyDUiUiUiVbW1tc5L6RK7HnU6Wb0Bfef4Mi4eErtYZw84mHVXFidpJxNOd9Cvp5tOOiKQFTm8T/Ls23QFMy/d/o2juwcStM6KypAMV9q+OGn/rOG+dVzyHpLgYA84RSm8rPtCh/OGwHYZNH5YoAerwzq2okVhaqHmgsGB30yll65gD06lKeRzZNLFQwP7ZzAD2YlEPUQ5ccnxgXWQbH0f28O+B65sn01Isms8InIJMNYY80Pr8/eB4caYa22m/R5wLXC6MWZ/9PhwFRUVpqqqKtEkjgX7v1x977kJp2toNBhjIhIeAA7UN9KiUDAGGoyhRdT4/fUNCJJyJ7TpqmtopFDEcUfLbtlf30BxUeop7Jn6jWC9nnxkF57/4YlNmm+8ureTyvo3xlDXYELbxsfVm7nsb7MYcXgXXrzGvsyNjcZ2O0s0fwgEFRFJaVnilTNT34kWvW863VfdLM/eA/UUFxWm1VG2MYb99Y20KCxI+P2GRkNDo+Gpmau4983loeETTunDHef1dzWGiMhcY0yF3TgnmaIbgLKwzz2tYdE/Mhq4HQfBPFcCFRJbKcGVLAIFNuMzHeSiOdnRMyEby5mp30g233h1byeV9S8itCyKnW+ixxYLCsR2O3M6/1SWJVk53f5OJqVbHrts2lR+08nrQwoLhMICiTlTC7aXsxVDnGy5c4C+ItJHRFoClwKTwicQkSHA48AFxpga94upmjOv3mC05aOiqvyTNKAbY+oJXEZ5C1gGvGSMWSIid4vIBdZk9wPtgH+LyHwRmRRndkoppTLE0bmIMWYqMDVq2J1hf492uVxKhXi1Bx2lktGXcykVRZ87Vn6V7W1XA7pSSrksV0luGtCVUsplubo3rgFdKaUyxHPvclFKORfse/Sqk8pzWxAPuX5039Dfp/btatv/aL4YafV5e98lgwG4IIWsYDf4ugs61Tx46aVbyXRpV5xWFmS+il4Xz00YnqOSZMeRh7QPLXPwtQHZpC10pZTKExrQlVIqT2hAV0qpPKEBXSml8oQGdKWUyhMa0JVSKk9oQFdKqTyhAV0ppfJEXiQW9e/egatP6ZPrYiilVE7lRUCfet2puS6CUkrlnF5yUZ6n70NXyhkN6EoplSc0oCulVJ7QgK6UUnlCA7ryPD+9PlepXNKArpRSeUIDulJK5QkN6EoplSc0oCvPOqR9MQA/P6NvkimVUqABXXlYu+JAInOpFdiVUolpQFdKqTyhAV0ppfKEBnSllMoTGtCVUipPaEBXSqk84Sigi8hYEVkhItUiUmkzvlhE/mWNnyUi5a6XVCmlVEJJA7qIFAKPAucA/YHxItI/arIJwDZjzJHAg8Af3C6oUkqpxJy00IcB1caYL40xB4CJwIVR01wIPGv9/TJwpoi+Ukk1TXGLQgB0Q1LKGScBvQewLuzzemuY7TTGmHpgB9AlekYico2IVIlIVW1tbXolVs3Gk1cczw2j+9Gna9tcF0UpX8jqTVFjzBPGmApjTEVpaWk2f1r5UM+SNlw3ui96sqeUM04C+gagLOxzT2uY7TQiUgR0BLa4UUCllFLOOAnoc4C+ItJHRFoClwKToqaZBFxp/X0JMM0Y7dpXKaWyqSjZBMaYehG5FngLKASeMsYsEZG7gSpjzCTg78BzIlINbCUQ9JVSSmVR0oAOYIyZCkyNGnZn2N/7gO+4WzSllFKp0ExRpZTKExrQlVIqT2hAV0qpPKEBXSml8oTk6ulCEakF1qT59a7AZheL4we6zM2DLnPz0JRl7m2Msc3MzFlAbwoRqTLGVOS6HNmky9w86DI3D5laZr3kopRSeUIDulJK5Qm/BvQncl2AHNBlbh50mZuHjCyzL6+hK6WUiuXXFrpSSqkoGtCVUipP+C6gJ+uw2i9EpExEpovIUhFZIiLXWcM7i8g7IrLS+r/EGi4i8rC13AtFZGjYvK60pl8pIlfG+02vEJFCEZknIpOtz32szsWrrc7GW1rD43Y+LiK3WsNXiMjZOVoUR0Skk4i8LCLLRWSZiIzI93oWkRus7XqxiLwoIq3yrZ5F5CkRqRGRxWHDXKtXETleRBZZ33lYnPT0YozxzT8Cr+/9AjgcaAksAPrnulxpLkt3YKj1d3vgcwKdcN8HVFrDK4E/WH+PA94k0MXmicAsa3hn4Evr/xLr75JcL1+SZb8ReAGYbH1+CbjU+vsx4CfW3z8FHrP+vhT4l/V3f6vui4E+1jZRmOvlSrC8zwI/tP5uCXTK53om0CXlKqB1WP1elW/1DJwGDAUWhw1zrV6B2da0Yn33nKRlyvVKSXEFjgDeCvt8K3Brrsvl0rK9DowBVgDdrWHdgRXW348D48OmX2GNHw88HjY8Yjqv/SPQ49V7wBnAZGtj3QwURdcxgXfwj7D+LrKmk+h6D5/Oa/8I9N61CusBhOj6y8d65mAfw52tepsMnJ2P9QyURwV0V+rVGrc8bHjEdPH++e2Si5MOq33HOsUcAswCuhljvrJGfQ10s/6Ot+x+Wyd/Bm4BGq3PXYDtJtC5OESWP17n435a5j5ALfC0dZnpbyLSljyuZ2PMBuCPwFrgKwL1Npf8rucgt+q1h/V39PCE/BbQ846ItANeAa43xuwMH2cCh+a8ea5URM4Daowxc3NdliwqInBa/ldjzBBgD4FT8ZA8rOcS4EICB7PDgLbA2JwWKgdyUa9+C+hOOqz2DRFpQSCYP2+MedUavElEulvjuwM11vB4y+6ndXIycIGIrAYmErjs8hDQSQKdi0Nk+eN1Pu6nZV4PrDfGzLI+v0wgwOdzPY8GVhljao0xdcCrBOo+n+s5yK163WD9HT08Ib8FdCcdVvuCdcf678AyY8wDYaPCO9y+ksC19eDwK6y75ScCO6xTu7eAs0SkxGoZnWUN8xxjzK3GmJ7GmHICdTfNGHM5MJ1A5+IQu8x2nY9PAi61no7oA/QlcAPJc4wxXwPrROQoa9CZwFLyuJ4JXGo5UUTaWNt5cJnztp7DuFKv1ridInKitQ6vCJtXfLm+qZDGTYhxBJ4I+QK4PdflacJynELgdGwhMN/6N47AtcP3gJXAu0Bna3oBHrWWexFQETavq4Fq698Pcr1sDpd/JAefcjmcwI5aDfwbKLaGt7I+V1vjDw/7/u3WuliBg7v/OV7W44Aqq67/Q+BphryuZ+A3wHJgMfAcgSdV8qqegRcJ3COoI3AmNsHNegUqrPX3BfAIUTfW7f5p6r9SSuUJv11yUUopFYcGdKWUyhMa0JVSKk9oQFdKqTyhAV0ppfKEBnSllMoTGtCVUipP/H/3Tke2Mooo0gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dataset.__getitem__(40)[0][0][1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "c407a66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFUAVNet(nn.Module):\n",
    "    #  Determine what layers and their order in CNN object \n",
    "    def __init__(self, num_classes):\n",
    "        super(RFUAVNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.dense = nn.Linear(320, num_classes)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.smax = nn.Softmax(dim=0)\n",
    "        \n",
    "        # for r unit\n",
    "        self.conv1 = nn.Conv1d(in_channels=2, out_channels=64, kernel_size=5, stride=5)\n",
    "        self.norm1 = nn.BatchNorm1d(num_features=64)\n",
    "        self.elu1 = nn.ELU(alpha=1.0, inplace=False)\n",
    "        \n",
    "        # setup for components of the gunit\n",
    "        self.groupconvlist = []\n",
    "        self.norm2list = []\n",
    "        self.elu2list = []\n",
    "        for i in range(4):\n",
    "            self.groupconvlist.append( nn.Conv1d( \n",
    "                  in_channels=64,\n",
    "                  out_channels=64,\n",
    "                  kernel_size=2,\n",
    "                    stride = 2,\n",
    "                  groups=8,\n",
    "    #               bias=False,\n",
    "                  dtype=torch.float32\n",
    "                ))\n",
    "            self.norm2list.append(nn.BatchNorm1d(num_features=64))\n",
    "            self.elu2list.append(nn.ELU(alpha=1.0, inplace=False))\n",
    "        self.groupconv = nn.ModuleList(self.groupconvlist)\n",
    "        self.norm2 = nn.ModuleList(self.norm2list)\n",
    "        self.elu2 = nn.ModuleList(self.elu2list)\n",
    "        \n",
    "        # multi-gap implementation\n",
    "        self.avgpool1000 = nn.AvgPool1d(kernel_size=1000)\n",
    "        self.avgpool500 = nn.AvgPool1d(kernel_size=500)\n",
    "        self.avgpool250 = nn.AvgPool1d(kernel_size=250)\n",
    "        self.avgpool125 = nn.AvgPool1d(kernel_size=125)\n",
    "    \n",
    "    # Progresses data across layers    \n",
    "    def forward(self, x):\n",
    "        # runit first\n",
    "        x1 = self.runit(x)\n",
    "# #         print('x1 shape', x1.shape)\n",
    "        xg1 = self.gunit(x1, 0) # output of this layer should be 1000, but why 999?\n",
    "        x2 = self.pool(x1)\n",
    "        x3 = xg1+x2\n",
    "        \n",
    "#         print('x3 shape', x3.shape)\n",
    "        xg2 = self.gunit(x3, 1)\n",
    "        x4 = self.pool(x3)\n",
    "        x5 = xg2+x4\n",
    "        \n",
    "#         print('x5 shape', x5.shape)\n",
    "        xg3 = self.gunit(x5, 2)\n",
    "        x6 = self.pool(x5)\n",
    "        x7 = x6+xg3\n",
    "        \n",
    "        xg4 = self.gunit(x7, 3)\n",
    "        x8 = self.pool(x7)\n",
    "        x_togap = x8+xg4\n",
    "        \n",
    "#         print('xg1 shape:', xg1.shape)\n",
    "        \n",
    "#         # CONTINUE from the gap and multi-gap implementation\n",
    "        f_gap_1 = self.avgpool1000(xg1)\n",
    "#         print('gap 1 shape', f_gap_1.shape)\n",
    "        f_gap_2 = self.avgpool500(xg2)\n",
    "#         print('gap 2 shape', f_gap_2.shape)\n",
    "        f_gap_3 = self.avgpool250(xg3)\n",
    "#         print('gap 3 shape', f_gap_3.shape)\n",
    "        f_gap_4 = self.avgpool125(xg4)\n",
    "#         print('gap 4 shape', f_gap_4.shape)\n",
    "        \n",
    "        f_multigap = torch.cat((f_gap_1,f_gap_2, f_gap_3, f_gap_4), 1)\n",
    "#         print('f_multigap shape:',f_multigap.shape)\n",
    "        \n",
    "#         print('shape of x to gap', x_togap.shape)\n",
    "        f_gap_add = self.avgpool125(x_togap)\n",
    "    \n",
    "        f_final = torch.cat((f_multigap, f_gap_add),1)\n",
    "#         print('avg pool:', self.avgpool1(xg3).shape)\n",
    "        f_flat = f_final.flatten(start_dim=1)\n",
    "    \n",
    "        f_fc = self.dense(f_flat)\n",
    "        out = self.smax(f_fc)\n",
    "        # fc_layer\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def runit(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.elu1(x)\n",
    "        return x\n",
    "        \n",
    "    def gunit(self, x, n):\n",
    "        # group convolution layer 8 by 8\n",
    "        # norm\n",
    "        # elu\n",
    "        # n indicates which gunit\n",
    "        x = self.groupconv[n](x) \n",
    "        x = self.norm2[n](x)\n",
    "        x = self.elu2[n](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "39a2e9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2, 10000])\n",
      "torch.Size([128, 2])\n"
     ]
    }
   ],
   "source": [
    "## Test network\n",
    "# input1 = dataset.__getitem__(40)[0]\n",
    "# input1= input1.type(torch.float)\n",
    "# input = input.reshape(1, 2, 10000)\n",
    "input1 = torch.rand(128, 2, 10000)\n",
    "\n",
    "print(input1.shape)\n",
    "\n",
    "# input_1d = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype = torch.float)\n",
    "\n",
    "net = RFUAVNet(2)\n",
    "out = net(input1)\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "b766e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data and parameters\n",
    "## Set up Data\n",
    "train_split_percentage = 0.9\n",
    "split_lengths = [int(train_split_percentage*len(dataset)), len(dataset)-int(train_split_percentage*len(dataset))]\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, split_lengths)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_set,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_set,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "\n",
    "## Set up Model\n",
    "# Hyperparameters\n",
    "batch_size = 128 # the number of samples processed before the model is updated. (number of samples in the training data)\n",
    "num_classes = 2\n",
    "learning_rate = 0.01\n",
    "num_epochs = 90\n",
    "momentum = 0.95\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = RFUAVNet(num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Set Loss function with criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set optimizer with optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4, momentum = momentum)  \n",
    "\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "8136219d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/90], Loss: 0.6991\n",
      "Epoch [11/90], Loss: 0.6264\n",
      "Epoch [21/90], Loss: 0.6203\n",
      "Epoch [31/90], Loss: 0.6169\n",
      "Epoch [41/90], Loss: 0.6214\n",
      "Epoch [51/90], Loss: 0.6218\n",
      "Epoch [61/90], Loss: 0.6184\n",
      "Epoch [71/90], Loss: 0.6158\n",
      "Epoch [81/90], Loss: 0.6198\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "# We use the pre-defined number of epochs to determine how many iterations to train the network on\n",
    "for epoch in range(num_epochs):\n",
    "    #Load in the data in batches using the train_loader object\n",
    "    for i, (images, labels) in enumerate(train_loader): \n",
    "        \n",
    "        labels = labels.type(torch.long)\n",
    "\n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        images = torch.squeeze(images, 1)\n",
    "#         images= images.type(torch.cuda.FloatTensor)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "953e1204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 9900 train images: 97.96969696969697 %\n"
     ]
    }
   ],
   "source": [
    "## Check accuracy\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        images = torch.squeeze(images, 1)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "#         print(predicted)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print('Accuracy of the network on the {} train images: {} %'.format(total, 100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "1ecb6851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "7694d01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6338"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc778345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kfold cross validation\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "# Start print\n",
    "print('--------------------------------')\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "\n",
    "# Print\n",
    "print(f'FOLD {fold}')\n",
    "print('--------------------------------')\n",
    "\n",
    "# Sample elements randomly from a given list of ids, no replacement.\n",
    "train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "# Define data loaders for training and testing data in this fold\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "                  dataset, \n",
    "                  batch_size=10, sampler=train_subsampler)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "                  dataset,\n",
    "                  batch_size=10, sampler=test_subsampler)\n",
    "\n",
    "# Init the neural network\n",
    "network = SimpleConvNet()\n",
    "network.apply(reset_weights)\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "\n",
    "# Run the training loop for defined number of epochs\n",
    "for epoch in range(0, num_epochs):\n",
    "\n",
    "  # Print epoch\n",
    "  print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "  # Set current loss value\n",
    "  current_loss = 0.0\n",
    "\n",
    "  # Iterate over the DataLoader for training data\n",
    "  for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "    # Get inputs\n",
    "    inputs, targets = data\n",
    "\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Perform forward pass\n",
    "    outputs = network(inputs)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = loss_function(outputs, targets)\n",
    "\n",
    "    # Perform backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Perform optimization\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print statistics\n",
    "    current_loss += loss.item()\n",
    "    if i % 500 == 499:\n",
    "        print('Loss after mini-batch %5d: %.3f' %\n",
    "              (i + 1, current_loss / 500))\n",
    "        current_loss = 0.0\n",
    "\n",
    "# Process is complete.\n",
    "print('Training process has finished. Saving trained model.')\n",
    "\n",
    "# Print about testing\n",
    "print('Starting testing')\n",
    "\n",
    "# Saving the model\n",
    "save_path = f'./model-fold-{fold}.pth'\n",
    "torch.save(network.state_dict(), save_path)\n",
    "\n",
    "# Evaluationfor this fold\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "\n",
    "  # Iterate over the test data and generate predictions\n",
    "  for i, data in enumerate(testloader, 0):\n",
    "\n",
    "    # Get inputs\n",
    "    inputs, targets = data\n",
    "\n",
    "    # Generate outputs\n",
    "    outputs = network(inputs)\n",
    "\n",
    "    # Set total and correct\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += targets.size(0)\n",
    "    correct += (predicted == targets).sum().item()\n",
    "\n",
    "  # Print accuracy\n",
    "  print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "  print('--------------------------------')\n",
    "  results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "# Print fold results\n",
    "print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "print('--------------------------------')\n",
    "sum = 0.0\n",
    "for key, value in results.items():\n",
    "print(f'Fold {key}: {value} %')\n",
    "sum += value\n",
    "print(f'Average: {sum/len(results.items())} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
