{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d254ebea",
   "metadata": {},
   "source": [
    "## Implementation of RFUAV-net\n",
    "efficient CNN method - 1D convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3e3259ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from helper_functions import *\n",
    "from loading_functions import *\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56271efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff 5 file name: 00000L_13.csv\n"
     ]
    }
   ],
   "source": [
    "## Import data -  Drone RF\n",
    "main_folder = '/home/kzhou/Data/DroneRF/'\n",
    "t_seg = 0.25 #ms\n",
    "Xs_arr, ys_arr, y4s_arr, y10s_arr = load_dronerf_raw(main_folder, t_seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086be216",
   "metadata": {},
   "source": [
    "### Apply Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45548d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LogSoftmax\n",
    "from torch import flatten\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45b4212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DroneData(Xs_arr, ys_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f03644a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc426b03310>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dataset.__getitem__(40)[0][0][1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c407a66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFUAVNet(nn.Module):\n",
    "    #  Determine what layers and their order in CNN object \n",
    "    def __init__(self, num_classes):\n",
    "        super(RFUAVNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.dense = nn.Linear(320, num_classes)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.smax = nn.Softmax(dim=0)\n",
    "        \n",
    "        # for r unit\n",
    "        self.conv1 = nn.Conv1d(in_channels=2, out_channels=64, kernel_size=5, stride=5)\n",
    "        self.norm1 = nn.BatchNorm1d(num_features=64)\n",
    "        self.elu1 = nn.ELU(alpha=1.0, inplace=False)\n",
    "        \n",
    "        # setup for components of the gunit\n",
    "        self.groupconvlist = []\n",
    "        self.norm2list = []\n",
    "        self.elu2list = []\n",
    "        for i in range(4):\n",
    "            self.groupconvlist.append( nn.Conv1d( \n",
    "                  in_channels=64,\n",
    "                  out_channels=64,\n",
    "                  kernel_size=3,\n",
    "                  stride = 2,\n",
    "                  groups=8,\n",
    "    #               bias=False,\n",
    "                  dtype=torch.float32\n",
    "                ))\n",
    "            self.norm2list.append(nn.BatchNorm1d(num_features=64))\n",
    "            self.elu2list.append(nn.ELU(alpha=1.0, inplace=False))\n",
    "        self.groupconv = nn.ModuleList(self.groupconvlist)\n",
    "        self.norm2 = nn.ModuleList(self.norm2list)\n",
    "        self.elu2 = nn.ModuleList(self.elu2list)\n",
    "        \n",
    "        # multi-gap implementation\n",
    "        self.avgpool1000 = nn.AvgPool1d(kernel_size=1000)\n",
    "        self.avgpool500 = nn.AvgPool1d(kernel_size=500)\n",
    "        self.avgpool250 = nn.AvgPool1d(kernel_size=250)\n",
    "        self.avgpool125 = nn.AvgPool1d(kernel_size=125)\n",
    "    \n",
    "    # Progresses data across layers    \n",
    "    def forward(self, x):\n",
    "        # runit first\n",
    "        x1 = self.runit(x)\n",
    "# #         print('x1 shape', x1.shape)\n",
    "        xg1 = self.gunit(F.pad(x1, (1,0)), 0) \n",
    "        x2 = self.pool(x1)\n",
    "        x3 = xg1+x2\n",
    "        \n",
    "#         print('x3 shape', x3.shape)\n",
    "        xg2 = self.gunit(F.pad(x3, (1,0)), 1)\n",
    "        x4 = self.pool(x3)\n",
    "        x5 = xg2+x4\n",
    "        \n",
    "#         print('x5 shape', x5.shape)\n",
    "        xg3 = self.gunit(F.pad(x5, (1,0)), 2)\n",
    "        x6 = self.pool(x5)\n",
    "        x7 = x6+xg3\n",
    "        \n",
    "        xg4 = self.gunit(F.pad(x7, (1,0)), 3)\n",
    "        x8 = self.pool(x7)\n",
    "        x_togap = x8+xg4\n",
    "        \n",
    "#         print('xg1 shape:', xg1.shape)\n",
    "        \n",
    "#         # CONTINUE from the gap and multi-gap implementation\n",
    "        f_gap_1 = self.avgpool1000(xg1)\n",
    "#         print('gap 1 shape', f_gap_1.shape)\n",
    "        f_gap_2 = self.avgpool500(xg2)\n",
    "#         print('gap 2 shape', f_gap_2.shape)\n",
    "        f_gap_3 = self.avgpool250(xg3)\n",
    "#         print('gap 3 shape', f_gap_3.shape)\n",
    "        f_gap_4 = self.avgpool125(xg4)\n",
    "#         print('gap 4 shape', f_gap_4.shape)\n",
    "        \n",
    "        f_multigap = torch.cat((f_gap_1,f_gap_2, f_gap_3, f_gap_4), 1)\n",
    "#         print('f_multigap shape:',f_multigap.shape)\n",
    "        \n",
    "#         print('shape of x to gap', x_togap.shape)\n",
    "        f_gap_add = self.avgpool125(x_togap)\n",
    "    \n",
    "        f_final = torch.cat((f_multigap, f_gap_add),1)\n",
    "#         print('avg pool:', self.avgpool1(xg3).shape)\n",
    "        f_flat = f_final.flatten(start_dim=1)\n",
    "    \n",
    "        f_fc = self.dense(f_flat)\n",
    "        out = self.smax(f_fc)\n",
    "        # fc_layer\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def runit(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.elu1(x)\n",
    "        return x\n",
    "        \n",
    "    def gunit(self, x, n):\n",
    "        # group convolution layer 8 by 8\n",
    "        # norm\n",
    "        # elu\n",
    "        # n indicates which gunit\n",
    "        x = self.groupconv[n](x) \n",
    "        x = self.norm2[n](x)\n",
    "        x = self.elu2[n](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "39a2e9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 10000])\n",
      "torch.Size([1, 2])\n",
      "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Test network\n",
    "# input1 = dataset.__getitem__(40)[0]\n",
    "# input1= input1.type(torch.float)\n",
    "# input = input.reshape(1, 2, 10000)\n",
    "input1 = torch.rand(1, 2, 10000)\n",
    "\n",
    "print(input1.shape)\n",
    "\n",
    "# input_1d = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype = torch.float)\n",
    "\n",
    "net = RFUAVNet(2)\n",
    "out = net(input1)\n",
    "\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a0fd48eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Hyperparameters\n",
    "\n",
    "batch_size = 128 # 128\n",
    "num_classes = 2\n",
    "learning_rate = 0.01\n",
    "num_epochs = 3 # 0\n",
    "momentum = 0.95\n",
    "l2reg = 1e-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b766e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data and parameters\n",
    "\n",
    "## Set up Data\n",
    "train_split_percentage = 0.9\n",
    "split_lengths = [int(train_split_percentage*len(dataset)), len(dataset)-int(train_split_percentage*len(dataset))]\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, split_lengths)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_set,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_set,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "\n",
    "## Set up Model\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = RFUAVNet(num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Set Loss function with criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set optimizer with optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=l2reg, momentum = momentum)  \n",
    "\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8136219d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 0.6932\n",
      "Epoch [1/3], Loss: 0.6932\n",
      "Epoch [1/3], Loss: 0.6932\n",
      "Epoch [1/3], Loss: 0.6930\n",
      "Epoch [1/3], Loss: 0.6931\n",
      "Epoch [1/3], Loss: 0.6931\n",
      "Epoch [1/3], Loss: 0.6930\n",
      "Epoch [1/3], Loss: 0.6931\n",
      "Epoch [1/3], Loss: 0.6931\n",
      "Epoch [1/3], Loss: 0.6931\n",
      "Epoch [1/3], Loss: 0.6930\n",
      "Epoch [1/3], Loss: 0.6932\n",
      "Epoch [1/3], Loss: 0.6930\n",
      "Epoch [1/3], Loss: 0.6931\n",
      "Epoch [1/3], Loss: 0.6930\n",
      "Epoch [1/3], Loss: 0.6929\n",
      "Epoch [1/3], Loss: 0.6928\n",
      "Epoch [1/3], Loss: 0.6931\n",
      "Epoch [1/3], Loss: 0.6929\n",
      "Epoch [1/3], Loss: 0.6927\n",
      "Epoch [1/3], Loss: 0.6927\n",
      "Epoch [1/3], Loss: 0.6929\n",
      "Epoch [1/3], Loss: 0.6923\n",
      "Epoch [1/3], Loss: 0.6923\n",
      "Epoch [1/3], Loss: 0.6928\n",
      "Epoch [1/3], Loss: 0.6928\n",
      "Epoch [1/3], Loss: 0.6924\n",
      "Epoch [1/3], Loss: 0.6924\n",
      "Epoch [1/3], Loss: 0.6923\n",
      "Epoch [1/3], Loss: 0.6925\n",
      "Epoch [1/3], Loss: 0.6920\n",
      "Epoch [2/3], Loss: 0.6872\n",
      "Epoch [2/3], Loss: 0.6916\n",
      "Epoch [2/3], Loss: 0.6907\n",
      "Epoch [2/3], Loss: 0.6920\n",
      "Epoch [2/3], Loss: 0.6928\n",
      "Epoch [2/3], Loss: 0.6884\n",
      "Epoch [2/3], Loss: 0.6920\n",
      "Epoch [2/3], Loss: 0.6942\n",
      "Epoch [2/3], Loss: 0.6901\n",
      "Epoch [2/3], Loss: 0.6922\n",
      "Epoch [2/3], Loss: 0.6935\n",
      "Epoch [2/3], Loss: 0.6939\n",
      "Epoch [2/3], Loss: 0.6925\n",
      "Epoch [2/3], Loss: 0.6922\n",
      "Epoch [2/3], Loss: 0.6868\n",
      "Epoch [2/3], Loss: 0.6909\n",
      "Epoch [2/3], Loss: 0.6870\n",
      "Epoch [2/3], Loss: 0.6870\n",
      "Epoch [2/3], Loss: 0.6874\n",
      "Epoch [2/3], Loss: 0.6921\n",
      "Epoch [2/3], Loss: 0.6882\n",
      "Epoch [2/3], Loss: 0.6876\n",
      "Epoch [2/3], Loss: 0.6941\n",
      "Epoch [2/3], Loss: 0.6870\n",
      "Epoch [2/3], Loss: 0.6917\n",
      "Epoch [2/3], Loss: 0.6943\n",
      "Epoch [2/3], Loss: 0.6916\n",
      "Epoch [2/3], Loss: 0.6940\n",
      "Epoch [2/3], Loss: 0.6869\n",
      "Epoch [2/3], Loss: 0.6908\n",
      "Epoch [2/3], Loss: 0.6915\n",
      "Epoch [3/3], Loss: 0.6872\n",
      "Epoch [3/3], Loss: 0.6888\n",
      "Epoch [3/3], Loss: 0.6919\n",
      "Epoch [3/3], Loss: 0.6943\n",
      "Epoch [3/3], Loss: 0.6888\n",
      "Epoch [3/3], Loss: 0.6908\n",
      "Epoch [3/3], Loss: 0.6912\n",
      "Epoch [3/3], Loss: 0.6915\n",
      "Epoch [3/3], Loss: 0.6910\n",
      "Epoch [3/3], Loss: 0.6886\n",
      "Epoch [3/3], Loss: 0.6926\n",
      "Epoch [3/3], Loss: 0.6919\n",
      "Epoch [3/3], Loss: 0.6906\n",
      "Epoch [3/3], Loss: 0.6906\n",
      "Epoch [3/3], Loss: 0.6904\n",
      "Epoch [3/3], Loss: 0.6925\n",
      "Epoch [3/3], Loss: 0.6902\n",
      "Epoch [3/3], Loss: 0.6919\n",
      "Epoch [3/3], Loss: 0.6876\n",
      "Epoch [3/3], Loss: 0.6897\n",
      "Epoch [3/3], Loss: 0.6896\n",
      "Epoch [3/3], Loss: 0.6887\n",
      "Epoch [3/3], Loss: 0.6899\n",
      "Epoch [3/3], Loss: 0.6910\n",
      "Epoch [3/3], Loss: 0.6898\n",
      "Epoch [3/3], Loss: 0.6882\n",
      "Epoch [3/3], Loss: 0.6879\n",
      "Epoch [3/3], Loss: 0.6882\n",
      "Epoch [3/3], Loss: 0.6887\n",
      "Epoch [3/3], Loss: 0.6873\n",
      "Epoch [3/3], Loss: 0.6873\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "# We use the pre-defined number of epochs to determine how many iterations to train the network on\n",
    "for epoch in range(num_epochs):\n",
    "    #Load in the data in batches using the train_loader object\n",
    "    for i, (inputs, labels) in enumerate(train_loader): \n",
    "        inputs = inputs.float()\n",
    "        inputs = torch.squeeze(inputs, 1)\n",
    "        labels = labels.type(torch.long)\n",
    "\n",
    "        # Move tensors to the configured device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%50 == 49:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "953e1204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 22600 train images: 88.24778761061947 %\n"
     ]
    }
   ],
   "source": [
    "## Check accuracy\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        inputs = inputs.float()\n",
    "        inputs = torch.squeeze(inputs, 1)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "#         print(predicted)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print('Accuracy of the network on the {} train images: {} %'.format(total, 100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7694d01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8386"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567cb92b",
   "metadata": {},
   "source": [
    "## K-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bc778345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Loss after mini-batch    50: 0.69303\n",
      "Loss after mini-batch   100: 0.69277\n",
      "Loss after mini-batch   150: 0.69237\n",
      "Loss after mini-batch   200: 0.69212\n",
      "Loss after mini-batch   250: 0.69187\n",
      "Loss after mini-batch   300: 0.69161\n",
      "Loss after mini-batch   350: 0.69136\n",
      "Loss after mini-batch   400: 0.69077\n",
      "Loss after mini-batch   450: 0.69015\n",
      "Loss after mini-batch   500: 0.68937\n",
      "Loss after mini-batch   550: 0.68865\n",
      "Loss after mini-batch   600: 0.68786\n",
      "Loss after mini-batch   650: 0.68749\n",
      "Loss after mini-batch   700: 0.68693\n",
      "Loss after mini-batch   750: 0.68665\n",
      "Loss after mini-batch   800: 0.68646\n",
      "Loss after mini-batch   850: 0.68635\n",
      "Starting epoch 2\n",
      "Loss after mini-batch    50: 0.68617\n",
      "Loss after mini-batch   100: 0.68610\n",
      "Loss after mini-batch   150: 0.68598\n",
      "Loss after mini-batch   200: 0.68593\n",
      "Loss after mini-batch   250: 0.68599\n",
      "Loss after mini-batch   300: 0.68598\n",
      "Loss after mini-batch   350: 0.68594\n",
      "Loss after mini-batch   400: 0.68594\n",
      "Loss after mini-batch   450: 0.68594\n",
      "Loss after mini-batch   500: 0.68593\n",
      "Loss after mini-batch   550: 0.68593\n",
      "Loss after mini-batch   600: 0.68586\n",
      "Loss after mini-batch   650: 0.68588\n",
      "Loss after mini-batch   700: 0.68589\n",
      "Loss after mini-batch   750: 0.68588\n",
      "Loss after mini-batch   800: 0.68585\n",
      "Loss after mini-batch   850: 0.68588\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    50: 0.68587\n",
      "Loss after mini-batch   100: 0.68585\n",
      "Loss after mini-batch   150: 0.68587\n",
      "Loss after mini-batch   200: 0.68584\n",
      "Loss after mini-batch   250: 0.68585\n",
      "Loss after mini-batch   300: 0.68586\n",
      "Loss after mini-batch   350: 0.68583\n",
      "Loss after mini-batch   400: 0.68583\n",
      "Loss after mini-batch   450: 0.68580\n",
      "Loss after mini-batch   500: 0.68590\n",
      "Loss after mini-batch   550: 0.68583\n",
      "Loss after mini-batch   600: 0.68584\n",
      "Loss after mini-batch   650: 0.68580\n",
      "Loss after mini-batch   700: 0.68587\n",
      "Loss after mini-batch   750: 0.68579\n",
      "Loss after mini-batch   800: 0.68582\n",
      "Loss after mini-batch   850: 0.68580\n",
      "Starting testing\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument weight in method wrapper___slow_conv2d_forward)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [115]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m instance \u001b[38;5;241m=\u001b[39m instance\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    113\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 114\u001b[0m yi \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m _,pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(yi,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    117\u001b[0m runtimes[i] \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mRFUAVNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;66;03m# runit first\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m         x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# #         print('x1 shape', x1.shape)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m         xg1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgunit(F\u001b[38;5;241m.\u001b[39mpad(x1, (\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m)), \u001b[38;5;241m0\u001b[39m) \n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mRFUAVNet.runit\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrunit\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 94\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x)\n\u001b[1;32m     96\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melu1(x)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/torch/nn/modules/conv.py:302\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/torch/nn/modules/conv.py:298\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    296\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    297\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument weight in method wrapper___slow_conv2d_forward)"
     ]
    }
   ],
   "source": [
    "# Configuration options\n",
    "k_folds = 2\n",
    "\n",
    "# For fold results\n",
    "results = {}\n",
    "runtimes = {}\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "# Start print\n",
    "print('--------------------------------')\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "    # Print\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      dataset, \n",
    "                      batch_size=batch_size, sampler=train_subsampler)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=batch_size, sampler=test_subsampler)\n",
    "\n",
    "    # Init the neural network\n",
    "    network = RFUAVNet(num_classes)\n",
    "    network = network.to(device)\n",
    "#     network.apply(reset_weights)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "#     optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate, weight_decay=l2reg, momentum = momentum)  \n",
    "\n",
    "    # Run the training loop for defined number of epochs\n",
    "    for epoch in range(0, num_epochs):\n",
    "        # Print epoch\n",
    "        print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "        # Set current loss value\n",
    "        current_loss = 0.0\n",
    "\n",
    "        # Iterate over the DataLoader for training data\n",
    "        for i, data in enumerate(trainloader):\n",
    "            # Get inputs\n",
    "            inputs, targets = data\n",
    "            inputs = inputs.float()\n",
    "            inputs = torch.squeeze(inputs, 1)\n",
    "            targets= targets.type(torch.long)\n",
    "                        \n",
    "            # Move tensors to configured device\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Perform forward pass\n",
    "            outputs = network(inputs)\n",
    "            \n",
    "            # Compute loss            \n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Perform backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Perform optimization\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            current_loss += loss.item()\n",
    "            if i % 50 == 49:\n",
    "                print('    Loss after mini-batch %5d: %.5f' %\n",
    "                      (i + 1, current_loss / 50))\n",
    "                current_loss = 0.0\n",
    "#         print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "    # Process is complete.\n",
    "#     print('Training process has finished. Saving trained model.')\n",
    "\n",
    "    # Print about testing\n",
    "    print('Starting testing')\n",
    "\n",
    "    # Saving the model\n",
    "#     save_path = f'./model-fold-{fold}.pth'\n",
    "#     torch.save(network.state_dict(), save_path)\n",
    "\n",
    "    # Evaluation for this fold\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "        runtimes_all = np.zeros(len(testloader), dtype=float)\n",
    "        # Iterate over the test data and generate predictions\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            # Get inputs\n",
    "            inputs, targets = data\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Generate outputs\n",
    "            n_instances = len(inputs)\n",
    "            runtimes = np.zeros(n_instances, dtype=float)\n",
    "            ys = torch.empty(n_instances)\n",
    "            ys = ys.to(device)\n",
    "\n",
    "            for i in range(n_instances):\n",
    "                instance = inputs[i]\n",
    "                instance = instance.float()\n",
    "                start = time.time()\n",
    "                starter.record()\n",
    "                yi = network(instance)\n",
    "                _,pred = torch.max(yi,1)\n",
    "                ender.record()\n",
    "                \n",
    "                torch.cuda.synchronize()\n",
    "                curr_time = starter.elapsed_time(ender) #miliseconds\n",
    "\n",
    "                runtimes[i] = curr_time*1e-3\n",
    "                ys[i] = pred\n",
    "\n",
    "\n",
    "            # Set total and correct\n",
    "            total += targets.size(0)\n",
    "            correct += (ys == targets).sum().item()\n",
    "            mean_runtime = np.mean(runtimes)\n",
    "\n",
    "            # Print accuracy\n",
    "            print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "    print('--------------------------------')\n",
    "    results[fold] = 100.0 * (correct / total)\n",
    "    runtimes_all[fold] = mean_runtime\n",
    "\n",
    "# Print fold results\n",
    "print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "print('--------------------------------')\n",
    "sum = 0.0\n",
    "for key, value in results.items():\n",
    "    print(f'Fold {key}: {value} %')\n",
    "    sum += value\n",
    "print(f'Average Accuracy: {sum/len(results.items())} %')\n",
    "print(f'Average Runtime: {sum/len(runtimes_all.items())} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "565e0d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "inputs = torch.squeeze(inputs,1)\n",
    "inputs = inputs.to(device)\n",
    "inputs = inputs.float()\n",
    "\n",
    "starter.record()\n",
    "outtest = network(inputs)\n",
    "\n",
    "ender.record()\n",
    "# WAIT FOR GPU SYNC\n",
    "torch.cuda.synchronize()\n",
    "curr_time = starter.elapsed_time(ender) #miliseconds\n",
    "# timings[rep] = curr_time\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6b1f4129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00120854, 0.00115561, 0.00112224, 0.00117898, 0.00116229,\n",
       "       0.00115919, 0.00115228, 0.00117373, 0.00114274, 0.00116444,\n",
       "       0.0011754 , 0.00115967, 0.00116277, 0.00115824, 0.00117183,\n",
       "       0.00115681, 0.00115895, 0.00117326, 0.00114083, 0.0011189 ,\n",
       "       0.00114775, 0.00115991, 0.00112081, 0.00111628, 0.00117564,\n",
       "       0.00113463, 0.00112319, 0.00115609, 0.001158  , 0.00111437,\n",
       "       0.00111818, 0.00118017, 0.00113297, 0.00111723, 0.00113511,\n",
       "       0.00111723, 0.00111938, 0.00111723, 0.00113392, 0.00112081,\n",
       "       0.00112319, 0.00116372, 0.00111938, 0.00111842, 0.00112844,\n",
       "       0.00111699, 0.00111961, 0.00112081, 0.00117087, 0.00114298,\n",
       "       0.00111985, 0.00112748, 0.00112724, 0.00111508, 0.00111985,\n",
       "       0.00117445, 0.00114036, 0.00111866, 0.00112987, 0.00111723,\n",
       "       0.00112104, 0.00111389, 0.00113177, 0.00111771, 0.001122  ,\n",
       "       0.00112605, 0.00112152, 0.00113869, 0.00116134, 0.00117326,\n",
       "       0.00113177, 0.00114965, 0.00117469, 0.00115919, 0.00116253,\n",
       "       0.00116396, 0.00116277, 0.00116014, 0.00116229, 0.00120974,\n",
       "       0.00116611, 0.0067215 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtimes[i] = curr_time*1e-3\n",
    "runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "75c5836f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        False,  True,  True, False,  True,  True, False, False,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False,  True],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_,pred = torch.max(outtest,1)\n",
    "pred == targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "4741cf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([7.5869e-08, 5.9106e-03], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([[False, False]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# prediction on one instance to measure inference time\n",
    "\n",
    "testdata =next(iter(testloader))\n",
    "batchdata, batchtarget  = testdata\n",
    "# print(batchdata.shape)\n",
    "\n",
    "i = 15\n",
    "\n",
    "instance = batchdata[i]\n",
    "\n",
    "# prediction on an instance\n",
    "instance = instance.float()\n",
    "onepred = network(instance.to(device))\n",
    "print(onepred)\n",
    "\n",
    "# prediction on a batch\n",
    "batchdata = batchdata.to(device)\n",
    "batchdata = batchdata.float()\n",
    "batchdata = torch.squeeze(batchdata,1)\n",
    "batchpred = network(batchdata)\n",
    "\n",
    "print(batchpred[i])\n",
    "\n",
    "print (onepred == batchpred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb7ab35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
