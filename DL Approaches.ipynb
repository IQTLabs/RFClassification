{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d4e062b",
   "metadata": {},
   "source": [
    "## Deep Learning Approaches for RF-based detection & classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7df87784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "# import the torch packages\n",
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LogSoftmax\n",
    "from torch import flatten\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# import custom functions\n",
    "from helper_functions import *\n",
    "from latency_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a4835a",
   "metadata": {},
   "source": [
    "### Load Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7710a0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [01:22<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "feat_folder = '../Features/'\n",
    "feat_name = 'SPEC'\n",
    "seg_len = 500\n",
    "datestr = '2022-06-30'\n",
    "n_per_seg = 1024\n",
    "interferences = ['CLEAN']\n",
    "Xs_arr, y_arr = load_features_arr(feat_folder, feat_name, seg_len, datestr, n_per_seg, interferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1360d2",
   "metadata": {},
   "source": [
    "### Dataset classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "545ebb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a dataset class\n",
    "## Creating a custom dataset\n",
    "class DroneDetectData(Dataset): ## NUMBERICAL DATA\n",
    "    def __init__(self, Xarr, yarr):\n",
    "        self.Xarr = Xarr\n",
    "        test_list=[]\n",
    "        self.le = preprocessing.LabelEncoder()\n",
    "        self.le.fit(yarr.flatten())\n",
    "        self.yarr = le.transform(yarr.flatten())\n",
    "                \n",
    "#         for ya in yarr:\n",
    "#             if ya == 'AIR':\n",
    "#                 num= 1.\n",
    "#             if ya == 'DIS':\n",
    "#                 num= 2.\n",
    "#             if ya == 'INS':\n",
    "#                 num= 3.\n",
    "#             if ya == 'MIN':\n",
    "#                 num= 4.\n",
    "#             if ya == 'MP1':\n",
    "#                 num= 5.\n",
    "#             if ya == 'MP2':\n",
    "#                 num= 6.\n",
    "#             if ya == 'PHA':\n",
    "#                 num= 0.\n",
    "#             test_list.append(num)\n",
    "#         self.yarr = np.array(test_list)\n",
    "#         print(len(self.yarr))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.yarr)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # all data must be in float and tensor format\n",
    "        X = torch.tensor((self.Xarr[index]))\n",
    "        X = X.unsqueeze(0)\n",
    "        y = torch.tensor(float(self.yarr[index]))\n",
    "        return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07ea8c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DroneDetectData(Xs_arr, y_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f52b104f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 513, 33482])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(10)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d85b6a",
   "metadata": {},
   "source": [
    "### 1. Custom NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25b3e63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model settings\n",
    "# Hyperparameters\n",
    "batch_size = 8 # the number of samples processed before the model is updated. (number of samples in the training data)\n",
    "num_classes = 7\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "\n",
    "# Device will determine whether to run the training on GPU or CPU.\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f02e381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a CNN class\n",
    "class ConvNeuralNet(nn.Module):\n",
    "    #  Determine what layers and their order in CNN object \n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.avpool0 = nn.AvgPool2d(kernel_size=(50,200))\n",
    "#         self.conv1 = nn.Conv2d(1, 8, 100)\n",
    "#         self.avgpool1 = nn.AvgPool2d(kernel_size=3)\n",
    "#         self.conv2 = nn.Conv2d(8, 8, 50)\n",
    "#         self.conv3 = nn.Conv1d(64,128, 3)\n",
    "#         self.conv4 = nn.Conv1d(128, 128, 3)\n",
    "        self.dense = nn.Linear(1670, num_classes)\n",
    "    \n",
    "    # Progresses data across layers    \n",
    "    def forward(self, x):\n",
    "         # Max pooling over a (2, 2) window\n",
    "        x = self.avpool0(x)\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.avgpool1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.avgpool1(x)\n",
    "#         x = nn.Dropout(p=0.25)(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.dense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ecc46a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test a random input\n",
    "# batch_size = 8\n",
    "# input = torch.randn(batch_size, 1, 513, 13392)\n",
    "# # input_1d = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype = torch.float)\n",
    "\n",
    "# net = ConvNeuralNet(7)\n",
    "# out = net(input)\n",
    "# print(input.shape)\n",
    "# print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd6590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up Data\n",
    "train_split_percentage = 0.7\n",
    "split_lengths = [int(train_split_percentage*len(dataset)), len(dataset)-int(train_split_percentage*len(dataset))]\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, split_lengths)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_set,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_set,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "473c1b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNeuralNet(num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Set Loss function with criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set optimizer with optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  \n",
    "\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1cd183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "# We use the pre-defined number of epochs to determine how many iterations to train the network on\n",
    "for epoch in range(num_epochs):\n",
    "    #Load in the data in batches using the train_loader object\n",
    "    for i, (images, labels) in enumerate(train_loader): \n",
    "        labels = labels.type(torch.long)\n",
    "\n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if i%10 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1db00eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.822728157043457"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f831d304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0], device='cuda:0')\n",
      "Accuracy of the network on the 114 train images: 17.54385964912281 %\n"
     ]
    }
   ],
   "source": [
    "## Check accuracy\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "#         images = images.repeat(1,3,1)\n",
    "#         images = images.reshape(batch_size, 3, 1, 513)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        print(predicted)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print('Accuracy of the network on the {} train images: {} %'.format(total, 100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ceef8f",
   "metadata": {},
   "source": [
    "### 2. Transfer learning from Resnet50 & Apply Logistic Regression (Swinney paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47b6d844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pretrained resnet feature and just keep up to the last layer\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "modules=list(resnet50.children())[:-1]\n",
    "# resnet50=nn.Sequential(*modules)\n",
    "for p in resnet50.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "440b23cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test resnet\n",
    "input = torch.randn(1,1,30,300)\n",
    "inputr = input.repeat(1,3,1,1)\n",
    "resnet50(inputr).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5a73489",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet_feats = []\n",
    "resnet_y = []\n",
    "for n in range(len(dataset)):\n",
    "    d = dataset.__getitem__(n)\n",
    "    inarr = d[0]\n",
    "    inputr = inarr.repeat(1,3,1,1)  # repeat to have 3 channels of the same info\n",
    "    out = resnet50(inputr)\n",
    "    resnet_feats.append(np.array(out))\n",
    "    resnet_y.append(np.array(d[1]))\n",
    "\n",
    "resnet_feats = np.array(resnet_feats)\n",
    "resnet_y = np.array(resnet_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "08e35067",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_feats = resnet_feats.reshape(resnet_feats.shape[0], resnet_feats.shape[-1])# flatten the middle dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "268a23da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert labels back to categorical\n",
    "resnet_y_cat = dataset.le.inverse_transform(resnet_y.astype(np.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d3eea904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 64}\n",
      "Accuracy: 0.974,\t F1: 0.974\n",
      "{'C': 64}\n",
      "Accuracy: 0.921,\t F1: 0.923\n",
      "{'C': 256}\n",
      "Accuracy: 0.921,\t F1: 0.925\n",
      "{'C': 16}\n",
      "Accuracy: 0.895,\t F1: 0.891\n",
      "{'C': 16}\n",
      "Accuracy: 0.921,\t F1: 0.92\n",
      "{'C': 16}\n",
      "Accuracy: 0.947,\t F1: 0.948\n",
      "{'C': 64}\n",
      "Accuracy: 1.0,\t F1: 1.0\n",
      "{'C': 256}\n",
      "Accuracy: 0.974,\t F1: 0.973\n",
      "{'C': 256}\n",
      "Accuracy: 0.921,\t F1: 0.924\n",
      "{'C': 64}\n",
      "Accuracy: 0.892,\t F1: 0.89\n",
      "SPEC: ResNet+LR average test acc: 0.94, F1: 0.94, Run-time: 0.12ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split data into K-fold\n",
    "k_fold = 10\n",
    "cv = KFold(n_splits=k_fold, random_state=1, shuffle=True)\n",
    "\n",
    "# model parameters\n",
    "Cs=list(map(lambda x:pow(2,x),range(-10,10,2)))\n",
    "\n",
    "best_params_ls = []\n",
    "acc_ls = []\n",
    "f1_ls = []\n",
    "runt_ls = []\n",
    "\n",
    "parameters = {'C':Cs}\n",
    "\n",
    "for train_ix, test_ix in cv.split(resnet_feats):\n",
    "    \n",
    "    # find the optimal hypber parameters\n",
    "    lr = LogisticRegression(max_iter=10000)\n",
    "    clf = GridSearchCV(lr, parameters, n_jobs=1)\n",
    "    clf.fit(resnet_feats[train_ix], resnet_y_cat[train_ix])\n",
    "    \n",
    "    print(clf.best_params_)\n",
    "    best_params_ls.append(clf.best_params_)\n",
    "    \n",
    "    # predict on the test data\n",
    "    y_pred, runtimes = atomic_benchmark_estimator(clf, resnet_feats[test_ix], verbose=False)\n",
    "    runt_ls.append(np.mean(runtimes))\n",
    "    \n",
    "    acc = accuracy_score(y_arr[test_ix], y_pred)\n",
    "    f1 = f1_score(y_arr[test_ix], y_pred, average='weighted')\n",
    "    print('Accuracy: {:.3},\\t F1: {:.3}'.format(acc,f1))\n",
    "    acc_ls.append(acc)\n",
    "    f1_ls.append(f1)\n",
    "    \n",
    "out_msg = feat_name+': ResNet+LR average test acc: {:.2}, F1: {:.2}, Run-time: {:.2}ms'.format(np.mean(acc_ls), np.mean(f1_ls), np.mean(runt_ls)*1e3)\n",
    "print(out_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91660fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
