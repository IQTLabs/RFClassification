{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d4e062b",
   "metadata": {},
   "source": [
    "## Deep Learning Approaches for RF-based detection & classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df87784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "# import the torch packages\n",
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LogSoftmax\n",
    "from torch import flatten\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm\n",
    "\n",
    "# import custom functions\n",
    "from helper_functions import *\n",
    "from latency_helpers import *\n",
    "from loading_functions import *\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a4835a",
   "metadata": {},
   "source": [
    "### Load Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7710a0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Name:  ../Features/IMG_SPEC_1024_20/\n"
     ]
    }
   ],
   "source": [
    "feat_folder = '../Features/'\n",
    "feat_name = 'SPEC'\n",
    "seg_len = 20\n",
    "n_per_seg = 1024\n",
    "interferences = ['WIFI','CLEAN','BLUE','BOTH']\n",
    "output_name = 'drones'\n",
    "feat_format = 'IMG'\n",
    "\n",
    "dataset = DroneDetectTorch(feat_folder, feat_name, seg_len, n_per_seg, feat_format,\n",
    "                                output_name, interferences)\n",
    "\n",
    "# dataset = load_dronedetect_data(feat_folder, feat_name, seg_len, n_per_seg, feat_format,\n",
    "#                                 output_name, interferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b732f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size 36778\n",
      "shape of each item torch.Size([224, 224, 3])\n"
     ]
    }
   ],
   "source": [
    "print('dataset size', len(dataset))\n",
    "print('shape of each item', dataset.__getitem__(12)[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4bf51c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = dataset.__getitem__(4)[0]\n",
    "plt.imshow(d)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ad3ec6",
   "metadata": {},
   "source": [
    "## VGG16 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3fd24d89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16()\n",
    "# summary(vgg16, (3,224,224))\n",
    "\n",
    "modules=list(vgg16.children())[:-1]\n",
    "vggmodel=nn.Sequential(*modules)\n",
    "\n",
    "for p in vggmodel.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81a79389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0196, 0.0182,  ..., 0.0562, 0.0534, 0.0152])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test one input\n",
    "d = dataset.__getitem__(0)\n",
    "inarr = d[0]\n",
    "inarr = torch.moveaxis(inarr, 2, 0)\n",
    "# print(inarr.shape)\n",
    "# postmove = inarr[0]\n",
    "# print(premove==postmove) # confirm it is the same channel\n",
    "\n",
    "# WHEN using single channel array format\n",
    "# inputr = inarr.repeat(1,3,1,1)\n",
    "# inputr = inputr.to(device)\n",
    "out = vggmodel(inarr)\n",
    "\n",
    "# reshape the output\n",
    "out.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85a4b583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 36778/36778 [02:07<00:00, 288.79it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "vggmodel = vggmodel.to(device) #set model to device\n",
    "\n",
    "Vgg_Feats = []\n",
    "Vgg_y_num = [] # numerical values for y\n",
    "for n in tqdm(range(len(dataset))):\n",
    "    d = dataset.__getitem__(n)\n",
    "    inarr = d[0]\n",
    "#     inputr = inarr.repeat(1,3,1,1)  # repeat to have 3 channels of the same info\n",
    "    inputr = torch.moveaxis(inarr, 2, 0) # move axis to have channels come first\n",
    "    inputr = inputr.to(device)\n",
    "    out = vggmodel(inputr)\n",
    "    \n",
    "    Vgg_Feats.append(out.cpu().numpy().flatten())\n",
    "    Vgg_y_num.append(np.array(d[1]))\n",
    "\n",
    "Vgg_Feats = np.array(Vgg_Feats)\n",
    "Vgg_y_num = np.array(Vgg_y_num)\n",
    "\n",
    "# flatten the middle dimension\n",
    "Vgg_Feats = Vgg_Feats.reshape(Vgg_Feats.shape[0], Vgg_Feats.shape[-1])\n",
    "# invert labels back to categorical\n",
    "# vgg_y_cat = dataset.le.inverse_transform(vgg_y.astype(np.int64))\n",
    "Vgg_y_cat = np.array([dataset.idx_to_class[i] for i in Vgg_y_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4da21074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save VGG features\n",
    "# vgg_save = {'feats': vgg_feats, 'y_cat':vgg_y_cat, 'y':vgg_y}\n",
    "# file_name = 'transfer_learning_feats/VggFeats_'+str(seg_len)+'_'+str(n_per_seg)+'correct_psd_img'\n",
    "# np.save(file_name, vgg_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e445e2e",
   "metadata": {},
   "source": [
    "## Resnet Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "47b6d844",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transfer learning from Resnet50 & Apply Logistic Regression (Swinney paper)\n",
    "\n",
    "# use pretrained resnet feature and just keep up to the last layer\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "modules=list(resnet50.children())[:-1]\n",
    "resnet50=nn.Sequential(*modules)\n",
    "for p in resnet50.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "440b23cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test resnet\n",
    "# input = torch.randn(1,1,30,300)\n",
    "d = dataset.__getitem__(0)\n",
    "inarr = d[0]\n",
    "resnet50(inarr).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c5a73489",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ResNet_Feats = []\n",
    "y_num = []\n",
    "for n in range(len(dataset)):\n",
    "    d = dataset.__getitem__(n)\n",
    "    inarr = d[0]\n",
    "    inputr = torch.moveaxis(inarr, 2, 0) # move axis to have channels come first\n",
    "    inputr = inputr.to(device)\n",
    "    \n",
    "    out = resnet50(inputr)\n",
    "    ResNet_Feats.append(np.array(out))\n",
    "    y_num.append(np.array(d[1]))\n",
    "\n",
    "ResNet_Feats = np.array(ResNet_Feats)\n",
    "y_num = np.array(y_num)\n",
    "\n",
    "# flatten the middle dimension\n",
    "ResNet_Feats = resnet_feats.reshape(ResNet_Feats.shape[0], ResNet_Feats.shape[-1])\n",
    "# invert labels back to categorical\n",
    "# y_cat = dataset.le.inverse_transform(y_num.astype(np.int64))\n",
    "resnet_y_cat = np.array([dataset.idx_to_class[i] for i in ResNet_Feats])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be6ec2",
   "metadata": {},
   "source": [
    "### Run Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b769a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Input Features: (n sample x n feats): (36778, 25088)\n"
     ]
    }
   ],
   "source": [
    "Xs_feat = Vgg_Feats # which features to use for logit reg\n",
    "y_cat = Vgg_y_cat\n",
    "print('Shape of Input Features: (n sample x n feats):', Xs_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eea904",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cs: [0.01, 0.1, 1, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "# split data into K-fold\n",
    "k_fold = 5\n",
    "cv = KFold(n_splits=k_fold, random_state=1, shuffle=True)\n",
    "\n",
    "# model parameters\n",
    "Cs=list(map(lambda x:pow(10,x),range(-2,2,1)))\n",
    "print('Cs:', Cs)\n",
    "\n",
    "best_params_ls = []\n",
    "acc_ls = []\n",
    "f1_ls = []\n",
    "runt_ls = []\n",
    "\n",
    "parameters = {'C':Cs}\n",
    "\n",
    "for train_ix, test_ix in tqdm(cv.split(Xs_feat)):\n",
    "    \n",
    "    # find the optimal hypber parameters\n",
    "    lr = LogisticRegression(solver='saga')\n",
    "#     clf = GridSearchCV(lr, parameters, n_jobs=1) # gridsearch cv\n",
    "    clf = LogisticRegression(C =1.0, max_iter=1000, class_weight = 'balanced',n_jobs=1) # fixed parameter\n",
    "    \n",
    "    scaler = preprocessing.StandardScaler().fit(Xs_feat[train_ix])\n",
    "    X_train_scale = scaler.transform(Xs_feat[train_ix])\n",
    "    \n",
    "    clf.fit(X_train_scale, y_cat[train_ix])\n",
    "    \n",
    "#     print(clf.best_params_)\n",
    "#     best_params_ls.append(clf.best_params_)\n",
    "    \n",
    "    # predict on the test data\n",
    "    X_test_scale = scaler.transform(Xs_feat[test_ix])\n",
    "    y_pred, runtimes = atomic_benchmark_estimator(clf, X_test_scale, output_type= '<U3', \n",
    "                                                  verbose=False)\n",
    "    runt_ls.append(np.mean(runtimes))\n",
    "    \n",
    "    acc = accuracy_score(y_cat[test_ix], y_pred)\n",
    "    f1 = f1_score(y_cat[test_ix], y_pred, average='weighted')\n",
    "    print('Accuracy: {:.3},\\t F1: {:.3}'.format(acc,f1))\n",
    "    acc_ls.append(acc)\n",
    "    f1_ls.append(f1)\n",
    "    \n",
    "out_msg = 'Net+LR: average test acc: {:.2}, F1: {:.2}, Run-time: {:.2}ms'.format(np.mean(acc_ls), np.mean(f1_ls), np.mean(runt_ls)*1e3)\n",
    "print(out_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7017a2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe2c7e6",
   "metadata": {},
   "source": [
    "## Run kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ce4b401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# neigh = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfedc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of neighbours: [100]\n"
     ]
    }
   ],
   "source": [
    "## Fixed parameter kNN\n",
    "k_fold = 5\n",
    "cv = KFold(n_splits=k_fold, random_state=10, shuffle=True)\n",
    "\n",
    "# Ns=list(range(2,100,20))\n",
    "# Ns = [100]\n",
    "parameters = {'n_neighbors':Ns}\n",
    "print('list of neighbours:', Ns)\n",
    "\n",
    "Xs_arr = Vgg_Feats\n",
    "y_arr = Vgg_y_cat\n",
    "\n",
    "best_params_ls = []\n",
    "score_ls = []\n",
    "f1_ls = []\n",
    "\n",
    "for train_ix, test_ix in cv.split(Xs_arr):\n",
    "    # scale data\n",
    "    scaler = preprocessing.StandardScaler().fit(Xs_arr[train_ix])\n",
    "    X_train_scale = scaler.transform(Xs_arr[train_ix])\n",
    "    \n",
    "    # find the optimal hypber parameters\n",
    "    clf = KNeighborsClassifier(n_neighbors=5)\n",
    "#     clf = GridSearchCV(neigh, parameters, n_jobs=1)\n",
    "    clf.fit(X_train_scale, y_arr[train_ix])\n",
    "#     print(clf.best_parameters)\n",
    "    \n",
    "    # predict on the test data\n",
    "    X_test_scale = scaler.transform(Xs_arr[test_ix])\n",
    "#     y_pred = clf.predict(X_test_scale)\n",
    "    y_pred, runtimes = atomic_benchmark_estimator(clf, X_test_scale, output_type= '<U3', \n",
    "                                                  verbose=False)\n",
    "    acc = accuracy_score(y_arr[test_ix], y_pred)\n",
    "    f1 = f1_score(y_arr[test_ix], y_pred, average='weighted')\n",
    "    f1_ls.append(f1)\n",
    "    print('Accuracy: {:.3},\\t F1: {:.3}'.format(acc,f1))\n",
    "    score_ls.append(acc)\n",
    "    \n",
    "print('VGG feats+kNN K-fold average test score:', np.mean(score_ls))\n",
    "print('VGG feats+kNN K-fold average test F1:', np.mean(f1_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80076188",
   "metadata": {},
   "source": [
    "## Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8392adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGFC(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(VGGFC,self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.vggfull = models.vgg16(pretrained=True)\n",
    "        modules=list(self.vggfull.children())[:-1] # remove the fully connected layer & adaptive averaging\n",
    "        self.vggfeats=nn.Sequential(*modules)\n",
    "        \n",
    "        for param in self.vggfeats.parameters():\n",
    "            param.requires_grad_(False)\n",
    "        \n",
    "        self._fc = nn.Linear(25088, num_classes)\n",
    "    def forward(self, x):\n",
    "        if len(x.shape)==4:\n",
    "            x = torch.moveaxis(x,-1, 1)\n",
    "        else:\n",
    "            x = torch.moveaxis(x, -1, 0)\n",
    "        x = self.vggfeats(x)\n",
    "        x = x.reshape(x.shape[0],25088)\n",
    "        x = self._fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057fdafd",
   "metadata": {},
   "source": [
    "### Kfold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c1f7ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_functions import runkfoldcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d595fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f67796ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration options\n",
    "k_folds = 5\n",
    "\n",
    "batch_size = 128 # 128\n",
    "num_classes = 7\n",
    "learning_rate = 0.01\n",
    "num_epochs = 25 # 0\n",
    "momentum = 0.95\n",
    "l2reg = 1e-4\n",
    "\n",
    "Model = VGGFC(num_classes)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ece73702",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "    Loss after mini-batch    50: 1.35745\n",
      "    Loss after mini-batch   100: 0.97597\n",
      "    Loss after mini-batch   150: 0.87031\n",
      "    Loss after mini-batch   200: 0.81131\n",
      "Starting epoch 2\n",
      "    Loss after mini-batch    50: 0.71293\n",
      "    Loss after mini-batch   100: 0.67999\n",
      "    Loss after mini-batch   150: 0.65161\n",
      "    Loss after mini-batch   200: 0.63998\n",
      "Starting epoch 3\n",
      "    Loss after mini-batch    50: 0.59697\n",
      "    Loss after mini-batch   100: 0.58523\n",
      "    Loss after mini-batch   150: 0.56022\n",
      "    Loss after mini-batch   200: 0.57325\n",
      "Starting epoch 4\n",
      "    Loss after mini-batch    50: 0.52805\n",
      "    Loss after mini-batch   100: 0.53279\n",
      "    Loss after mini-batch   150: 0.51023\n",
      "    Loss after mini-batch   200: 0.52119\n",
      "Starting epoch 5\n",
      "    Loss after mini-batch    50: 0.48830\n",
      "    Loss after mini-batch   100: 0.49656\n",
      "    Loss after mini-batch   150: 0.47366\n",
      "    Loss after mini-batch   200: 0.48392\n",
      "Starting epoch 6\n",
      "    Loss after mini-batch    50: 0.45607\n",
      "    Loss after mini-batch   100: 0.46250\n",
      "    Loss after mini-batch   150: 0.46127\n",
      "    Loss after mini-batch   200: 0.45727\n",
      "Starting epoch 7\n",
      "    Loss after mini-batch    50: 0.44021\n",
      "    Loss after mini-batch   100: 0.44100\n",
      "    Loss after mini-batch   150: 0.43077\n",
      "    Loss after mini-batch   200: 0.42710\n",
      "Starting epoch 8\n",
      "    Loss after mini-batch    50: 0.42100\n",
      "    Loss after mini-batch   100: 0.40698\n",
      "    Loss after mini-batch   150: 0.42020\n",
      "    Loss after mini-batch   200: 0.42134\n",
      "Starting epoch 9\n",
      "    Loss after mini-batch    50: 0.41086\n",
      "    Loss after mini-batch   100: 0.39595\n",
      "    Loss after mini-batch   150: 0.39677\n",
      "    Loss after mini-batch   200: 0.38873\n",
      "Starting epoch 10\n",
      "    Loss after mini-batch    50: 0.38832\n",
      "    Loss after mini-batch   100: 0.38371\n",
      "    Loss after mini-batch   150: 0.38259\n",
      "    Loss after mini-batch   200: 0.38247\n",
      "Starting epoch 11\n",
      "    Loss after mini-batch    50: 0.38041\n",
      "    Loss after mini-batch   100: 0.37331\n",
      "    Loss after mini-batch   150: 0.35976\n",
      "    Loss after mini-batch   200: 0.36788\n",
      "Starting epoch 12\n",
      "    Loss after mini-batch    50: 0.35887\n",
      "    Loss after mini-batch   100: 0.35666\n",
      "    Loss after mini-batch   150: 0.35911\n",
      "    Loss after mini-batch   200: 0.36003\n",
      "Starting epoch 13\n",
      "    Loss after mini-batch    50: 0.35761\n",
      "    Loss after mini-batch   100: 0.34087\n",
      "    Loss after mini-batch   150: 0.34617\n",
      "    Loss after mini-batch   200: 0.35125\n",
      "Starting epoch 14\n",
      "    Loss after mini-batch    50: 0.34431\n",
      "    Loss after mini-batch   100: 0.34045\n",
      "    Loss after mini-batch   150: 0.32690\n",
      "    Loss after mini-batch   200: 0.33955\n",
      "Starting epoch 15\n",
      "    Loss after mini-batch    50: 0.33460\n",
      "    Loss after mini-batch   100: 0.32159\n",
      "    Loss after mini-batch   150: 0.33166\n",
      "    Loss after mini-batch   200: 0.32557\n",
      "Starting epoch 16\n",
      "    Loss after mini-batch    50: 0.32709\n",
      "    Loss after mini-batch   100: 0.31866\n",
      "    Loss after mini-batch   150: 0.32320\n",
      "    Loss after mini-batch   200: 0.32321\n",
      "Starting epoch 17\n",
      "    Loss after mini-batch    50: 0.30703\n",
      "    Loss after mini-batch   100: 0.31808\n",
      "    Loss after mini-batch   150: 0.32036\n",
      "    Loss after mini-batch   200: 0.31008\n",
      "Starting epoch 18\n",
      "    Loss after mini-batch    50: 0.29773\n",
      "    Loss after mini-batch   100: 0.31314\n",
      "    Loss after mini-batch   150: 0.29868\n",
      "    Loss after mini-batch   200: 0.31397\n",
      "Starting epoch 19\n",
      "    Loss after mini-batch    50: 0.30899\n",
      "    Loss after mini-batch   100: 0.29424\n",
      "    Loss after mini-batch   150: 0.29894\n",
      "    Loss after mini-batch   200: 0.30330\n",
      "Starting epoch 20\n",
      "    Loss after mini-batch    50: 0.28666\n",
      "    Loss after mini-batch   100: 0.29796\n",
      "    Loss after mini-batch   150: 0.29209\n",
      "    Loss after mini-batch   200: 0.29575\n",
      "Starting epoch 21\n",
      "    Loss after mini-batch    50: 0.28400\n",
      "    Loss after mini-batch   100: 0.28599\n",
      "    Loss after mini-batch   150: 0.29259\n",
      "    Loss after mini-batch   200: 0.28387\n",
      "Starting epoch 22\n",
      "    Loss after mini-batch    50: 0.27921\n",
      "    Loss after mini-batch   100: 0.27625\n",
      "    Loss after mini-batch   150: 0.28696\n",
      "    Loss after mini-batch   200: 0.28282\n",
      "Starting epoch 23\n",
      "    Loss after mini-batch    50: 0.27449\n",
      "    Loss after mini-batch   100: 0.26896\n",
      "    Loss after mini-batch   150: 0.28289\n",
      "    Loss after mini-batch   200: 0.27671\n",
      "Starting epoch 24\n",
      "    Loss after mini-batch    50: 0.27473\n",
      "    Loss after mini-batch   100: 0.26807\n",
      "    Loss after mini-batch   150: 0.26990\n",
      "    Loss after mini-batch   200: 0.26951\n",
      "Starting epoch 25\n",
      "    Loss after mini-batch    50: 0.27118\n",
      "    Loss after mini-batch   100: 0.26028\n",
      "    Loss after mini-batch   150: 0.26723\n",
      "    Loss after mini-batch   200: 0.25915\n",
      "Starting testing\n",
      "----------------\n",
      "Accuracy for fold 0: 85.97 %\n",
      "F1 for fold 0: 0.86 \n",
      "Runtime for fold 0: 0.0057 s\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "    Loss after mini-batch    50: 0.29311\n",
      "    Loss after mini-batch   100: 0.28709\n",
      "    Loss after mini-batch   150: 0.28309\n",
      "    Loss after mini-batch   200: 0.28158\n",
      "Starting epoch 2\n",
      "    Loss after mini-batch    50: 0.27088\n",
      "    Loss after mini-batch   100: 0.28214\n",
      "    Loss after mini-batch   150: 0.28124\n",
      "    Loss after mini-batch   200: 0.27659\n",
      "Starting epoch 3\n",
      "    Loss after mini-batch    50: 0.27422\n",
      "    Loss after mini-batch   100: 0.28205\n",
      "    Loss after mini-batch   150: 0.26379\n",
      "    Loss after mini-batch   200: 0.27223\n",
      "Starting epoch 4\n",
      "    Loss after mini-batch    50: 0.26853\n",
      "    Loss after mini-batch   100: 0.26590\n",
      "    Loss after mini-batch   150: 0.26569\n",
      "    Loss after mini-batch   200: 0.26755\n",
      "Starting epoch 5\n",
      "    Loss after mini-batch    50: 0.26149\n",
      "    Loss after mini-batch   100: 0.25969\n",
      "    Loss after mini-batch   150: 0.25518\n",
      "    Loss after mini-batch   200: 0.27201\n",
      "Starting epoch 6\n",
      "    Loss after mini-batch    50: 0.25137\n",
      "    Loss after mini-batch   100: 0.25772\n",
      "    Loss after mini-batch   150: 0.25952\n",
      "    Loss after mini-batch   200: 0.25504\n",
      "Starting epoch 7\n",
      "    Loss after mini-batch    50: 0.25252\n",
      "    Loss after mini-batch   100: 0.25985\n",
      "    Loss after mini-batch   150: 0.24746\n",
      "    Loss after mini-batch   200: 0.24972\n",
      "Starting epoch 8\n",
      "    Loss after mini-batch    50: 0.24412\n",
      "    Loss after mini-batch   100: 0.25613\n",
      "    Loss after mini-batch   150: 0.23910\n",
      "    Loss after mini-batch   200: 0.25074\n",
      "Starting epoch 9\n",
      "    Loss after mini-batch    50: 0.25180\n",
      "    Loss after mini-batch   100: 0.24936\n",
      "    Loss after mini-batch   150: 0.23794\n",
      "    Loss after mini-batch   200: 0.22906\n",
      "Starting epoch 10\n",
      "    Loss after mini-batch    50: 0.23586\n",
      "    Loss after mini-batch   100: 0.23677\n",
      "    Loss after mini-batch   150: 0.24381\n",
      "    Loss after mini-batch   200: 0.24461\n",
      "Starting epoch 11\n",
      "    Loss after mini-batch    50: 0.23578\n",
      "    Loss after mini-batch   100: 0.22526\n",
      "    Loss after mini-batch   150: 0.24132\n",
      "    Loss after mini-batch   200: 0.24112\n",
      "Starting epoch 12\n",
      "    Loss after mini-batch    50: 0.23674\n",
      "    Loss after mini-batch   100: 0.22967\n",
      "    Loss after mini-batch   150: 0.23324\n",
      "    Loss after mini-batch   200: 0.23152\n",
      "Starting epoch 13\n",
      "    Loss after mini-batch    50: 0.23468\n",
      "    Loss after mini-batch   100: 0.21592\n",
      "    Loss after mini-batch   150: 0.23109\n",
      "    Loss after mini-batch   200: 0.22409\n",
      "Starting epoch 14\n",
      "    Loss after mini-batch    50: 0.22255\n",
      "    Loss after mini-batch   100: 0.22497\n",
      "    Loss after mini-batch   150: 0.22779\n",
      "    Loss after mini-batch   200: 0.22109\n",
      "Starting epoch 15\n",
      "    Loss after mini-batch    50: 0.21917\n",
      "    Loss after mini-batch   100: 0.22061\n",
      "    Loss after mini-batch   150: 0.22735\n",
      "    Loss after mini-batch   200: 0.21612\n",
      "Starting epoch 16\n",
      "    Loss after mini-batch    50: 0.21110\n",
      "    Loss after mini-batch   100: 0.21900\n",
      "    Loss after mini-batch   150: 0.22437\n",
      "    Loss after mini-batch   200: 0.21916\n",
      "Starting epoch 17\n",
      "    Loss after mini-batch    50: 0.20479\n",
      "    Loss after mini-batch   100: 0.21914\n",
      "    Loss after mini-batch   150: 0.22310\n",
      "    Loss after mini-batch   200: 0.21872\n",
      "Starting epoch 18\n",
      "    Loss after mini-batch    50: 0.20832\n",
      "    Loss after mini-batch   100: 0.21550\n",
      "    Loss after mini-batch   150: 0.21198\n",
      "    Loss after mini-batch   200: 0.20367\n",
      "Starting epoch 19\n",
      "    Loss after mini-batch    50: 0.21320\n",
      "    Loss after mini-batch   100: 0.20570\n",
      "    Loss after mini-batch   150: 0.20107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Loss after mini-batch   200: 0.21454\n",
      "Starting epoch 20\n",
      "    Loss after mini-batch    50: 0.20795\n",
      "    Loss after mini-batch   100: 0.21217\n",
      "    Loss after mini-batch   150: 0.20373\n",
      "    Loss after mini-batch   200: 0.20223\n",
      "Starting epoch 21\n",
      "    Loss after mini-batch    50: 0.19951\n",
      "    Loss after mini-batch   100: 0.20002\n",
      "    Loss after mini-batch   150: 0.20935\n",
      "    Loss after mini-batch   200: 0.20462\n",
      "Starting epoch 22\n",
      "    Loss after mini-batch    50: 0.20382\n",
      "    Loss after mini-batch   100: 0.19489\n",
      "    Loss after mini-batch   150: 0.20153\n",
      "    Loss after mini-batch   200: 0.20080\n",
      "Starting epoch 23\n",
      "    Loss after mini-batch    50: 0.19604\n",
      "    Loss after mini-batch   100: 0.19991\n",
      "    Loss after mini-batch   150: 0.20048\n",
      "    Loss after mini-batch   200: 0.19746\n",
      "Starting epoch 24\n",
      "    Loss after mini-batch    50: 0.19027\n",
      "    Loss after mini-batch   100: 0.19358\n",
      "    Loss after mini-batch   150: 0.20289\n",
      "    Loss after mini-batch   200: 0.19654\n",
      "Starting epoch 25\n",
      "    Loss after mini-batch    50: 0.18923\n",
      "    Loss after mini-batch   100: 0.19003\n",
      "    Loss after mini-batch   150: 0.19258\n",
      "    Loss after mini-batch   200: 0.20204\n",
      "Starting testing\n",
      "----------------\n",
      "Accuracy for fold 1: 89.76 %\n",
      "F1 for fold 1: 0.90 \n",
      "Runtime for fold 1: 0.0057 s\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "    Loss after mini-batch    50: 0.20612\n",
      "    Loss after mini-batch   100: 0.21557\n",
      "    Loss after mini-batch   150: 0.21183\n",
      "    Loss after mini-batch   200: 0.21636\n",
      "Starting epoch 2\n",
      "    Loss after mini-batch    50: 0.19951\n",
      "    Loss after mini-batch   100: 0.20874\n",
      "    Loss after mini-batch   150: 0.20552\n",
      "    Loss after mini-batch   200: 0.21534\n",
      "Starting epoch 3\n",
      "    Loss after mini-batch    50: 0.20637\n",
      "    Loss after mini-batch   100: 0.19898\n",
      "    Loss after mini-batch   150: 0.20173\n",
      "    Loss after mini-batch   200: 0.20294\n",
      "Starting epoch 4\n",
      "    Loss after mini-batch    50: 0.19562\n",
      "    Loss after mini-batch   100: 0.19407\n",
      "    Loss after mini-batch   150: 0.20813\n",
      "    Loss after mini-batch   200: 0.19390\n",
      "Starting epoch 5\n",
      "    Loss after mini-batch    50: 0.19619\n",
      "    Loss after mini-batch   100: 0.19359\n",
      "    Loss after mini-batch   150: 0.20439\n",
      "    Loss after mini-batch   200: 0.19579\n",
      "Starting epoch 6\n",
      "    Loss after mini-batch    50: 0.19734\n",
      "    Loss after mini-batch   100: 0.18843\n",
      "    Loss after mini-batch   150: 0.18981\n",
      "    Loss after mini-batch   200: 0.19526\n",
      "Starting epoch 7\n",
      "    Loss after mini-batch    50: 0.19199\n",
      "    Loss after mini-batch   100: 0.19074\n",
      "    Loss after mini-batch   150: 0.18970\n",
      "    Loss after mini-batch   200: 0.19049\n",
      "Starting epoch 8\n",
      "    Loss after mini-batch    50: 0.18470\n",
      "    Loss after mini-batch   100: 0.18882\n",
      "    Loss after mini-batch   150: 0.19118\n",
      "    Loss after mini-batch   200: 0.18913\n",
      "Starting epoch 9\n",
      "    Loss after mini-batch    50: 0.18703\n",
      "    Loss after mini-batch   100: 0.18311\n",
      "    Loss after mini-batch   150: 0.18515\n",
      "    Loss after mini-batch   200: 0.18204\n",
      "Starting epoch 10\n",
      "    Loss after mini-batch    50: 0.18207\n",
      "    Loss after mini-batch   100: 0.18221\n",
      "    Loss after mini-batch   150: 0.18724\n",
      "    Loss after mini-batch   200: 0.18242\n",
      "Starting epoch 11\n",
      "    Loss after mini-batch    50: 0.17724\n",
      "    Loss after mini-batch   100: 0.17792\n",
      "    Loss after mini-batch   150: 0.18369\n",
      "    Loss after mini-batch   200: 0.18156\n",
      "Starting epoch 12\n",
      "    Loss after mini-batch    50: 0.17569\n",
      "    Loss after mini-batch   100: 0.17952\n",
      "    Loss after mini-batch   150: 0.18851\n",
      "    Loss after mini-batch   200: 0.17122\n",
      "Starting epoch 13\n",
      "    Loss after mini-batch    50: 0.17824\n",
      "    Loss after mini-batch   100: 0.17186\n",
      "    Loss after mini-batch   150: 0.17754\n",
      "    Loss after mini-batch   200: 0.17849\n",
      "Starting epoch 14\n",
      "    Loss after mini-batch    50: 0.17938\n",
      "    Loss after mini-batch   100: 0.17007\n",
      "    Loss after mini-batch   150: 0.18087\n",
      "    Loss after mini-batch   200: 0.17048\n",
      "Starting epoch 15\n",
      "    Loss after mini-batch    50: 0.17303\n",
      "    Loss after mini-batch   100: 0.17155\n",
      "    Loss after mini-batch   150: 0.16879\n",
      "    Loss after mini-batch   200: 0.17493\n",
      "Starting epoch 16\n",
      "    Loss after mini-batch    50: 0.16482\n",
      "    Loss after mini-batch   100: 0.18434\n",
      "    Loss after mini-batch   150: 0.17103\n",
      "    Loss after mini-batch   200: 0.16461\n",
      "Starting epoch 17\n",
      "    Loss after mini-batch    50: 0.16324\n",
      "    Loss after mini-batch   100: 0.16941\n",
      "    Loss after mini-batch   150: 0.17212\n",
      "    Loss after mini-batch   200: 0.16608\n",
      "Starting epoch 18\n",
      "    Loss after mini-batch    50: 0.15925\n",
      "    Loss after mini-batch   100: 0.16993\n",
      "    Loss after mini-batch   150: 0.16551\n",
      "    Loss after mini-batch   200: 0.17061\n",
      "Starting epoch 19\n",
      "    Loss after mini-batch    50: 0.15974\n",
      "    Loss after mini-batch   100: 0.16655\n",
      "    Loss after mini-batch   150: 0.16607\n",
      "    Loss after mini-batch   200: 0.16905\n",
      "Starting epoch 20\n",
      "    Loss after mini-batch    50: 0.15091\n",
      "    Loss after mini-batch   100: 0.16817\n",
      "    Loss after mini-batch   150: 0.17113\n",
      "    Loss after mini-batch   200: 0.16297\n",
      "Starting epoch 21\n",
      "    Loss after mini-batch    50: 0.16059\n",
      "    Loss after mini-batch   100: 0.16339\n",
      "    Loss after mini-batch   150: 0.15900\n",
      "    Loss after mini-batch   200: 0.16007\n",
      "Starting epoch 22\n",
      "    Loss after mini-batch    50: 0.15571\n",
      "    Loss after mini-batch   100: 0.16173\n",
      "    Loss after mini-batch   150: 0.16136\n",
      "    Loss after mini-batch   200: 0.15909\n",
      "Starting epoch 23\n",
      "    Loss after mini-batch    50: 0.15256\n",
      "    Loss after mini-batch   100: 0.15333\n",
      "    Loss after mini-batch   150: 0.15853\n",
      "    Loss after mini-batch   200: 0.16478\n",
      "Starting epoch 24\n",
      "    Loss after mini-batch    50: 0.15653\n",
      "    Loss after mini-batch   100: 0.15502\n",
      "    Loss after mini-batch   150: 0.15729\n",
      "    Loss after mini-batch   200: 0.15657\n",
      "Starting epoch 25\n",
      "    Loss after mini-batch    50: 0.15333\n",
      "    Loss after mini-batch   100: 0.15945\n",
      "    Loss after mini-batch   150: 0.15308\n",
      "    Loss after mini-batch   200: 0.15136\n",
      "Starting testing\n",
      "----------------\n",
      "Accuracy for fold 2: 92.20 %\n",
      "F1 for fold 2: 0.92 \n",
      "Runtime for fold 2: 0.0057 s\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "    Loss after mini-batch    50: 0.16740\n",
      "    Loss after mini-batch   100: 0.16601\n",
      "    Loss after mini-batch   150: 0.17893\n",
      "    Loss after mini-batch   200: 0.16899\n",
      "Starting epoch 2\n",
      "    Loss after mini-batch    50: 0.16467\n",
      "    Loss after mini-batch   100: 0.17260\n",
      "    Loss after mini-batch   150: 0.16850\n",
      "    Loss after mini-batch   200: 0.16515\n",
      "Starting epoch 3\n",
      "    Loss after mini-batch    50: 0.16614\n",
      "    Loss after mini-batch   100: 0.16313\n",
      "    Loss after mini-batch   150: 0.16590\n",
      "    Loss after mini-batch   200: 0.16141\n",
      "Starting epoch 4\n",
      "    Loss after mini-batch    50: 0.16207\n",
      "    Loss after mini-batch   100: 0.16597\n",
      "    Loss after mini-batch   150: 0.16380\n",
      "    Loss after mini-batch   200: 0.15855\n",
      "Starting epoch 5\n",
      "    Loss after mini-batch    50: 0.15476\n",
      "    Loss after mini-batch   100: 0.16313\n",
      "    Loss after mini-batch   150: 0.16587\n",
      "    Loss after mini-batch   200: 0.15804\n",
      "Starting epoch 6\n",
      "    Loss after mini-batch    50: 0.15541\n",
      "    Loss after mini-batch   100: 0.16291\n",
      "    Loss after mini-batch   150: 0.15062\n",
      "    Loss after mini-batch   200: 0.15934\n",
      "Starting epoch 7\n",
      "    Loss after mini-batch    50: 0.15433\n",
      "    Loss after mini-batch   100: 0.15409\n",
      "    Loss after mini-batch   150: 0.15783\n",
      "    Loss after mini-batch   200: 0.15634\n",
      "Starting epoch 8\n",
      "    Loss after mini-batch    50: 0.15581\n",
      "    Loss after mini-batch   100: 0.15224\n",
      "    Loss after mini-batch   150: 0.15600\n",
      "    Loss after mini-batch   200: 0.15702\n",
      "Starting epoch 9\n",
      "    Loss after mini-batch    50: 0.15489\n",
      "    Loss after mini-batch   100: 0.14932\n",
      "    Loss after mini-batch   150: 0.15408\n",
      "    Loss after mini-batch   200: 0.14912\n",
      "Starting epoch 10\n",
      "    Loss after mini-batch    50: 0.15107\n",
      "    Loss after mini-batch   100: 0.15707\n",
      "    Loss after mini-batch   150: 0.14491\n",
      "    Loss after mini-batch   200: 0.14868\n",
      "Starting epoch 11\n",
      "    Loss after mini-batch    50: 0.15194\n",
      "    Loss after mini-batch   100: 0.14234\n",
      "    Loss after mini-batch   150: 0.14693\n",
      "    Loss after mini-batch   200: 0.15667\n",
      "Starting epoch 12\n",
      "    Loss after mini-batch    50: 0.14402\n",
      "    Loss after mini-batch   100: 0.14691\n",
      "    Loss after mini-batch   150: 0.15086\n",
      "    Loss after mini-batch   200: 0.14465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 13\n",
      "    Loss after mini-batch    50: 0.14752\n",
      "    Loss after mini-batch   100: 0.14779\n",
      "    Loss after mini-batch   150: 0.13991\n",
      "    Loss after mini-batch   200: 0.14463\n",
      "Starting epoch 14\n",
      "    Loss after mini-batch    50: 0.14440\n",
      "    Loss after mini-batch   100: 0.15256\n",
      "    Loss after mini-batch   150: 0.14032\n",
      "    Loss after mini-batch   200: 0.14323\n",
      "Starting epoch 15\n",
      "    Loss after mini-batch    50: 0.14660\n",
      "    Loss after mini-batch   100: 0.13953\n",
      "    Loss after mini-batch   150: 0.14616\n",
      "    Loss after mini-batch   200: 0.14201\n",
      "Starting epoch 16\n",
      "    Loss after mini-batch    50: 0.14499\n",
      "    Loss after mini-batch   100: 0.13876\n",
      "    Loss after mini-batch   150: 0.14268\n",
      "    Loss after mini-batch   200: 0.13908\n",
      "Starting epoch 17\n",
      "    Loss after mini-batch    50: 0.14270\n",
      "    Loss after mini-batch   100: 0.13898\n",
      "    Loss after mini-batch   150: 0.13914\n",
      "    Loss after mini-batch   200: 0.13885\n",
      "Starting epoch 18\n",
      "    Loss after mini-batch    50: 0.13862\n",
      "    Loss after mini-batch   100: 0.14062\n",
      "    Loss after mini-batch   150: 0.13955\n",
      "    Loss after mini-batch   200: 0.13572\n",
      "Starting epoch 19\n",
      "    Loss after mini-batch    50: 0.13424\n",
      "    Loss after mini-batch   100: 0.13384\n",
      "    Loss after mini-batch   150: 0.14133\n",
      "    Loss after mini-batch   200: 0.13783\n",
      "Starting epoch 20\n",
      "    Loss after mini-batch    50: 0.13358\n",
      "    Loss after mini-batch   100: 0.13443\n",
      "    Loss after mini-batch   150: 0.14157\n",
      "    Loss after mini-batch   200: 0.13380\n",
      "Starting epoch 21\n",
      "    Loss after mini-batch    50: 0.12931\n",
      "    Loss after mini-batch   100: 0.13266\n",
      "    Loss after mini-batch   150: 0.13726\n",
      "    Loss after mini-batch   200: 0.13527\n",
      "Starting epoch 22\n",
      "    Loss after mini-batch    50: 0.13157\n",
      "    Loss after mini-batch   100: 0.12983\n",
      "    Loss after mini-batch   150: 0.13720\n",
      "    Loss after mini-batch   200: 0.13256\n",
      "Starting epoch 23\n",
      "    Loss after mini-batch    50: 0.12615\n",
      "    Loss after mini-batch   100: 0.13600\n",
      "    Loss after mini-batch   150: 0.13180\n",
      "    Loss after mini-batch   200: 0.13362\n",
      "Starting epoch 24\n",
      "    Loss after mini-batch    50: 0.13344\n",
      "    Loss after mini-batch   100: 0.12894\n",
      "    Loss after mini-batch   150: 0.13348\n",
      "    Loss after mini-batch   200: 0.12728\n",
      "Starting epoch 25\n",
      "    Loss after mini-batch    50: 0.13326\n",
      "    Loss after mini-batch   100: 0.12893\n",
      "    Loss after mini-batch   150: 0.13315\n",
      "    Loss after mini-batch   200: 0.12510\n",
      "Starting testing\n",
      "----------------\n",
      "Accuracy for fold 3: 94.17 %\n",
      "F1 for fold 3: 0.94 \n",
      "Runtime for fold 3: 0.0057 s\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "    Loss after mini-batch    50: 0.13718\n",
      "    Loss after mini-batch   100: 0.14405\n",
      "    Loss after mini-batch   150: 0.14117\n",
      "    Loss after mini-batch   200: 0.14441\n",
      "Starting epoch 2\n",
      "    Loss after mini-batch    50: 0.13823\n",
      "    Loss after mini-batch   100: 0.13883\n",
      "    Loss after mini-batch   150: 0.13376\n",
      "    Loss after mini-batch   200: 0.14081\n",
      "Starting epoch 3\n",
      "    Loss after mini-batch    50: 0.13819\n",
      "    Loss after mini-batch   100: 0.13621\n",
      "    Loss after mini-batch   150: 0.13744\n",
      "    Loss after mini-batch   200: 0.13525\n",
      "Starting epoch 4\n",
      "    Loss after mini-batch    50: 0.13580\n",
      "    Loss after mini-batch   100: 0.13084\n",
      "    Loss after mini-batch   150: 0.13745\n",
      "    Loss after mini-batch   200: 0.12686\n",
      "Starting epoch 5\n",
      "    Loss after mini-batch    50: 0.12634\n",
      "    Loss after mini-batch   100: 0.12939\n",
      "    Loss after mini-batch   150: 0.13606\n",
      "    Loss after mini-batch   200: 0.13890\n",
      "Starting epoch 6\n",
      "    Loss after mini-batch    50: 0.12359\n",
      "    Loss after mini-batch   100: 0.13541\n",
      "    Loss after mini-batch   150: 0.13065\n",
      "    Loss after mini-batch   200: 0.13232\n",
      "Starting epoch 7\n",
      "    Loss after mini-batch    50: 0.12983\n",
      "    Loss after mini-batch   100: 0.12261\n",
      "    Loss after mini-batch   150: 0.13520\n",
      "    Loss after mini-batch   200: 0.13204\n",
      "Starting epoch 8\n",
      "    Loss after mini-batch    50: 0.12739\n",
      "    Loss after mini-batch   100: 0.12634\n",
      "    Loss after mini-batch   150: 0.12828\n",
      "    Loss after mini-batch   200: 0.13355\n",
      "Starting epoch 9\n",
      "    Loss after mini-batch    50: 0.12624\n",
      "    Loss after mini-batch   100: 0.12682\n",
      "    Loss after mini-batch   150: 0.12839\n",
      "    Loss after mini-batch   200: 0.12511\n",
      "Starting epoch 10\n",
      "    Loss after mini-batch    50: 0.12055\n",
      "    Loss after mini-batch   100: 0.12952\n",
      "    Loss after mini-batch   150: 0.12048\n",
      "    Loss after mini-batch   200: 0.13246\n",
      "Starting epoch 11\n",
      "    Loss after mini-batch    50: 0.12862\n",
      "    Loss after mini-batch   100: 0.12312\n",
      "    Loss after mini-batch   150: 0.12438\n",
      "    Loss after mini-batch   200: 0.12421\n",
      "Starting epoch 12\n",
      "    Loss after mini-batch    50: 0.12059\n",
      "    Loss after mini-batch   100: 0.12596\n",
      "    Loss after mini-batch   150: 0.12099\n",
      "    Loss after mini-batch   200: 0.12185\n",
      "Starting epoch 13\n",
      "    Loss after mini-batch    50: 0.11934\n",
      "    Loss after mini-batch   100: 0.12086\n",
      "    Loss after mini-batch   150: 0.11733\n",
      "    Loss after mini-batch   200: 0.12473\n",
      "Starting epoch 14\n",
      "    Loss after mini-batch    50: 0.11458\n",
      "    Loss after mini-batch   100: 0.12145\n",
      "    Loss after mini-batch   150: 0.12604\n",
      "    Loss after mini-batch   200: 0.11876\n",
      "Starting epoch 15\n",
      "    Loss after mini-batch    50: 0.11437\n",
      "    Loss after mini-batch   100: 0.11523\n",
      "    Loss after mini-batch   150: 0.12051\n",
      "    Loss after mini-batch   200: 0.12392\n",
      "Starting epoch 16\n",
      "    Loss after mini-batch    50: 0.11977\n",
      "    Loss after mini-batch   100: 0.11571\n",
      "    Loss after mini-batch   150: 0.11819\n",
      "    Loss after mini-batch   200: 0.11699\n",
      "Starting epoch 17\n",
      "    Loss after mini-batch    50: 0.11225\n",
      "    Loss after mini-batch   100: 0.11604\n",
      "    Loss after mini-batch   150: 0.11800\n",
      "    Loss after mini-batch   200: 0.12049\n",
      "Starting epoch 18\n",
      "    Loss after mini-batch    50: 0.11398\n",
      "    Loss after mini-batch   100: 0.11456\n",
      "    Loss after mini-batch   150: 0.11950\n",
      "    Loss after mini-batch   200: 0.11443\n",
      "Starting epoch 19\n",
      "    Loss after mini-batch    50: 0.11020\n",
      "    Loss after mini-batch   100: 0.11385\n",
      "    Loss after mini-batch   150: 0.11424\n",
      "    Loss after mini-batch   200: 0.11882\n",
      "Starting epoch 20\n",
      "    Loss after mini-batch    50: 0.10809\n",
      "    Loss after mini-batch   100: 0.11561\n",
      "    Loss after mini-batch   150: 0.11645\n",
      "    Loss after mini-batch   200: 0.11425\n",
      "Starting epoch 21\n",
      "    Loss after mini-batch    50: 0.11619\n",
      "    Loss after mini-batch   100: 0.10912\n",
      "    Loss after mini-batch   150: 0.10795\n",
      "    Loss after mini-batch   200: 0.11454\n",
      "Starting epoch 22\n",
      "    Loss after mini-batch    50: 0.10543\n",
      "    Loss after mini-batch   100: 0.11104\n",
      "    Loss after mini-batch   150: 0.11305\n",
      "    Loss after mini-batch   200: 0.11841\n",
      "Starting epoch 23\n",
      "    Loss after mini-batch    50: 0.11065\n",
      "    Loss after mini-batch   100: 0.11063\n",
      "    Loss after mini-batch   150: 0.10988\n",
      "    Loss after mini-batch   200: 0.10799\n",
      "Starting epoch 24\n",
      "    Loss after mini-batch    50: 0.10857\n",
      "    Loss after mini-batch   100: 0.10869\n",
      "    Loss after mini-batch   150: 0.10937\n",
      "    Loss after mini-batch   200: 0.11294\n",
      "Starting epoch 25\n",
      "    Loss after mini-batch    50: 0.10949\n",
      "    Loss after mini-batch   100: 0.10713\n",
      "    Loss after mini-batch   150: 0.10821\n",
      "    Loss after mini-batch   200: 0.11120\n",
      "Starting testing\n",
      "----------------\n",
      "Accuracy for fold 4: 94.74 %\n",
      "F1 for fold 4: 0.95 \n",
      "Runtime for fold 4: 0.0057 s\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 85.97063621533442 %\n",
      "Fold 1: 89.76345840130506 %\n",
      "Fold 2: 92.19684611201741 %\n",
      "Fold 3: 94.16723317471109 %\n",
      "Fold 4: 94.73827328348062 %\n",
      "Average Accuracy: 91.36728943736972 %\n",
      "Average F1: 0.913539936546195\n",
      "Average Runtime: 0.005702200392324619 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(91.36728943736972, 0.913539936546195, 0.005702200392324619)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runkfoldcv(Model, dataset, device, k_folds, batch_size, learning_rate, num_epochs, momentum, l2reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8ef036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload modules for testing\n",
    "# import importlib\n",
    "# import nn_functions\n",
    "# importlib.reload(nn_functions)\n",
    "# from nn_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302d56ed",
   "metadata": {},
   "source": [
    " ### resnet & a fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4117cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define network\n",
    "# model = torch.hub.load('pytorch/vision:v0.6.0', 'vgg19', pretrained=True)\n",
    "# model.classifier = nn.Linear(model.classifier[0].in_features, num_classes)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dfdbf77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetFC(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResnetFC,self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.resnetfull = models.resnet50(pretrained=True)\n",
    "        modules=list(self.resnetfull.children())[:-2] # remove the fully connected layer & adaptive averaging\n",
    "        self.resnetfeats=nn.Sequential(*modules)\n",
    "        \n",
    "        for param in self.resnetfeats.parameters():\n",
    "            self.resnetfeats.requires_grad_(False)\n",
    "        \n",
    "        self._fc = nn.Linear(1505280, num_classes)\n",
    "    def forward(self, x):\n",
    "#         batch_size ,_,_ =x.shape\n",
    "        \n",
    "        # replicate the image to have 3 channels\n",
    "        x = x.repeat(1,3,1,1)\n",
    "        print(x.shape)\n",
    "        x = self.resnetfeats(x)\n",
    "        x = x.flatten()\n",
    "        print(x.shape)\n",
    "        x = self._fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6815adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fctest = ResnetFC(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2b30169b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([129, 4687])\n"
     ]
    }
   ],
   "source": [
    "test_input = dataset.__getitem__(10)[0]\n",
    "print(test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d3d4b299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 129, 4687])\n",
      "torch.Size([1, 3, 129, 4687])\n",
      "torch.Size([1505280])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3626,  0.2002,  0.4983, -0.0624, -0.0184, -0.0807,  0.5689],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test an input\n",
    "test_input = dataset.__getitem__(10)[0]\n",
    "# test_input = torch.rand(1, 129, 4687)\n",
    "\n",
    "test_input = test_input.unsqueeze(axis=0)\n",
    "print(test_input.shape)\n",
    "fctest.forward(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5fef9683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 25,557,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.56\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 384.62\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "fctest.resnetfeats.cuda()\n",
    "FULLRES = models.resnet50(pretrained=True)\n",
    "FULLRES = FULLRES.cuda()\n",
    "summary(FULLRES, (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eb190f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False), Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "), AdaptiveAvgPool2d(output_size=(1, 1)), Linear(in_features=2048, out_features=1000, bias=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(FULLRES.children()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
