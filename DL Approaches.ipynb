{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d4e062b",
   "metadata": {},
   "source": [
    "## Deep Learning Approaches for RF-based detection & classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7df87784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "# import the torch packages\n",
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LogSoftmax\n",
    "from torch import flatten\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm\n",
    "\n",
    "# import custom functions\n",
    "from helper_functions import *\n",
    "from latency_helpers import *\n",
    "from loading_functions import *\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a4835a",
   "metadata": {},
   "source": [
    "### Load Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7710a0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [02:08<00:00,  1.60s/it]\n"
     ]
    }
   ],
   "source": [
    "feat_folder = '../Features/'\n",
    "feat_name = 'SPEC'\n",
    "seg_len = 20\n",
    "# datestr = '2022-07-05'\n",
    "n_per_seg = 256\n",
    "interferences = ['CLEAN']\n",
    "dataset = load_dronedetect_data(feat_folder, feat_name, seg_len, n_per_seg, interferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b732f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size 9487\n",
      "shape of each item torch.Size([129, 4687])\n"
     ]
    }
   ],
   "source": [
    "print('dataset size', len(dataset))\n",
    "print('shape of each item', dataset.__getitem__(10)[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ceef8f",
   "metadata": {},
   "source": [
    "## Transfer learning from Resnet50 & Apply Logistic Regression (Swinney paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47b6d844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pretrained resnet feature and just keep up to the last layer\n",
    "# resnet50 = models.resnet50(pretrained=True)\n",
    "# modules=list(resnet50.children())[:-1]\n",
    "# # resnet50=nn.Sequential(*modules)\n",
    "# for p in resnet50.parameters():\n",
    "#     p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "440b23cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test resnet\n",
    "# input = torch.randn(1,1,30,300)\n",
    "# inputr = input.repeat(1,3,1,1)\n",
    "# resnet50(inputr).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5a73489",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# resnet_feats = []\n",
    "# resnet_y = []\n",
    "# for n in range(len(dataset)):\n",
    "#     d = dataset.__getitem__(n)\n",
    "#     inarr = d[0]\n",
    "#     inputr = inarr.repeat(1,3,1,1)  # repeat to have 3 channels of the same info\n",
    "#     out = resnet50(inputr)\n",
    "#     resnet_feats.append(np.array(out))\n",
    "#     resnet_y.append(np.array(d[1]))\n",
    "\n",
    "# resnet_feats = np.array(resnet_feats)\n",
    "# resnet_y = np.array(resnet_y)\n",
    "\n",
    "# # flatten the middle dimension\n",
    "# resnet_feats = resnet_feats.reshape(resnet_feats.shape[0], resnet_feats.shape[-1])\n",
    "# # invert labels back to categorical\n",
    "# resnet_y_cat = dataset.le.inverse_transform(resnet_y.astype(np.int64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ad3ec6",
   "metadata": {},
   "source": [
    "## Transfer learning VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fd24d89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16()\n",
    "# summary(vgg16, (3,224,224))\n",
    "\n",
    "modules=list(vgg16.children())[:-1]\n",
    "vggfeats=nn.Sequential(*modules)\n",
    "\n",
    "for p in vggfeats.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81a79389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.0510e-10, 5.0208e-10, 2.3334e-09,  ..., 8.1137e-12, 2.3012e-10,\n",
       "        5.5576e-10])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test one input\n",
    "d = dataset.__getitem__(0)\n",
    "inarr = d[0]\n",
    "inputr = inarr.repeat(1,3,1,1)\n",
    "# inputr = inputr.to(device)\n",
    "out = vggfeats(inputr)\n",
    "\n",
    "# reshape the output\n",
    "out.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca7abeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9487/9487 [1:51:14<00:00,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "vgg_feats = []\n",
    "vgg_y = []\n",
    "for n in tqdm(range(len(dataset))):\n",
    "    d = dataset.__getitem__(n)\n",
    "    inarr = d[0]\n",
    "    inputr = inarr.repeat(1,3,1,1)  # repeat to have 3 channels of the same info\n",
    "    out = vggfeats(inputr)\n",
    "    vgg_feats.append(np.array(out.flatten()))\n",
    "    vgg_y.append(np.array(d[1]))\n",
    "\n",
    "vgg_feats = np.array(vgg_feats)\n",
    "vgg_y = np.array(vgg_y)\n",
    "\n",
    "# flatten the middle dimension\n",
    "vgg_feats = vgg_feats.reshape(vgg_feats.shape[0], vgg_feats.shape[-1])\n",
    "# invert labels back to categorical\n",
    "vgg_y_cat = dataset.le.inverse_transform(vgg_y.astype(np.int64))\n",
    "\n",
    "### TO DO: Save these features to be easily loaded [ this took almost 2 hours]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4da21074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save VGG features\n",
    "# vgg_save = {'feats': vgg_feats, 'y_cat':vgg_y_cat, 'y':vgg_y}\n",
    "# file_name = 'VggFeats_'+str(seg_len)+'_'+str(n_per_seg)\n",
    "# np.save(file_name, vgg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b769a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9487, 25088)\n"
     ]
    }
   ],
   "source": [
    "feats_lr = vgg_feats # which features to use for logit reg\n",
    "y_cat = vgg_y_cat\n",
    "print(feats_lr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3eea904",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:34, 34.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.15,\t F1: 0.0394\n",
      "{'C': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [01:08, 34.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.155,\t F1: 0.0414\n",
      "{'C': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [01:39, 33.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.151,\t F1: 0.0394\n",
      "SPEC: ResNet+LR average test acc: 0.15, F1: 0.04, Run-time: 0.13ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# split data into K-fold\n",
    "k_fold = 3\n",
    "cv = KFold(n_splits=k_fold, random_state=1, shuffle=True)\n",
    "\n",
    "# model parameters\n",
    "Cs=list(map(lambda x:pow(2,x),range(-2,10,5)))\n",
    "\n",
    "best_params_ls = []\n",
    "acc_ls = []\n",
    "f1_ls = []\n",
    "runt_ls = []\n",
    "\n",
    "parameters = {'C':Cs}\n",
    "\n",
    "for train_ix, test_ix in tqdm(cv.split(feats_lr)):\n",
    "    \n",
    "    # find the optimal hypber parameters\n",
    "    lr = LogisticRegression()\n",
    "    clf = GridSearchCV(lr, parameters, n_jobs=1)\n",
    "    clf.fit(feats_lr[train_ix], y_cat[train_ix])\n",
    "    \n",
    "    print(clf.best_params_)\n",
    "    best_params_ls.append(clf.best_params_)\n",
    "    \n",
    "    # predict on the test data\n",
    "    y_pred, runtimes = atomic_benchmark_estimator(clf, feats_lr[test_ix], output_type= '<U3', \n",
    "                                                  verbose=False)\n",
    "    runt_ls.append(np.mean(runtimes))\n",
    "    \n",
    "    acc = accuracy_score(y_cat[test_ix], y_pred)\n",
    "    f1 = f1_score(y_cat[test_ix], y_pred, average='weighted')\n",
    "    print('Accuracy: {:.3},\\t F1: {:.3}'.format(acc,f1))\n",
    "    acc_ls.append(acc)\n",
    "    f1_ls.append(f1)\n",
    "    \n",
    "out_msg = feat_name+': ResNet+LR average test acc: {:.2}, F1: {:.2}, Run-time: {:.2}ms'.format(np.mean(acc_ls), np.mean(f1_ls), np.mean(runt_ls)*1e3)\n",
    "print(out_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "83ad3b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.141,\t F1: 0.139\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_cat[test_ix], y_pred)\n",
    "f1 = f1_score(y_cat[test_ix], y_pred, average='weighted')\n",
    "print('Accuracy: {:.3},\\t F1: {:.3}'.format(acc,f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cf43bbc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9487, 25088)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Apply normalization\n",
    "X_norm = feats_lr\n",
    "for n in range(len(Xs_arr)):\n",
    "    X_norm[n] = feats_lr[n]/max(feats_lr[n])\n",
    "X_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c83afe0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [116]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_ix, test_ix \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(Xs_arr):\n\u001b[1;32m     15\u001b[0m     \n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# find the optimal hypber parameters\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#     clf = LogisticRegressi on(C =1e-5, class_weight = 'balanced')\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     clf \u001b[38;5;241m=\u001b[39m svm\u001b[38;5;241m.\u001b[39mSVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXs_arr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_ix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_arr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_ix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# predict on the test data\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(Xs_arr[test_ix])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/sklearn/svm/_base.py:251\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    250\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[0;32m--> 251\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/sklearn/svm/_base.py:333\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    319\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[1;32m    323\u001b[0m (\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[0;32m--> 333\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mlibsvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprobability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrinking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### FIXED PARAMETER LOGISTIC REGRESSION ###\n",
    "k_fold = 3\n",
    "cv = KFold(n_splits=k_fold, random_state=10, shuffle=True)\n",
    "\n",
    "Xs_arr = X_norm\n",
    "y_arr = vgg_y\n",
    "\n",
    "\n",
    "best_params_ls = []\n",
    "score_ls = []\n",
    "\n",
    "parameters = {'C':[0.01,0.1,1,10,100,1000,10000]}\n",
    "\n",
    "for train_ix, test_ix in cv.split(Xs_arr):\n",
    "    \n",
    "    # find the optimal hypber parameters\n",
    "#     clf = LogisticRegressi on(C =1e-5, class_weight = 'balanced')\n",
    "    clf = svm.SVC(kernel='rbf', C=512, gamma = 0.5)\n",
    "    clf.fit(Xs_arr[train_ix], y_arr[train_ix])\n",
    "    \n",
    "    # predict on the test data\n",
    "    y_pred = clf.predict(Xs_arr[test_ix])\n",
    "    acc = accuracy_score(y_arr[test_ix], y_pred)\n",
    "    print(acc)\n",
    "    score_ls.append(acc)\n",
    "    \n",
    "print('VGG feats+LR K-fold average test score:', np.mean(score_ls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7863e158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dataset.le.transform(y_cat) == vgg_y).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4fb1ac9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f007d09e850>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(vgg_y[test_ix])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302d56ed",
   "metadata": {},
   "source": [
    "## 3. Apply resnet & a fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4117cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define network\n",
    "# model = torch.hub.load('pytorch/vision:v0.6.0', 'vgg19', pretrained=True)\n",
    "# model.classifier = nn.Linear(model.classifier[0].in_features, num_classes)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dfdbf77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetFC(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResnetFC,self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.resnetfull = models.resnet50(pretrained=True)\n",
    "        modules=list(self.resnetfull.children())[:-2] # remove the fully connected layer & adaptive averaging\n",
    "        self.resnetfeats=nn.Sequential(*modules)\n",
    "        \n",
    "        for param in self.resnetfeats.parameters():\n",
    "            self.resnetfeats.requires_grad_(False)\n",
    "        \n",
    "        self._fc = nn.Linear(1505280, num_classes)\n",
    "    def forward(self, x):\n",
    "#         batch_size ,_,_ =x.shape\n",
    "        \n",
    "        # replicate the image to have 3 channels\n",
    "        x = x.repeat(1,3,1,1)\n",
    "        print(x.shape)\n",
    "        x = self.resnetfeats(x)\n",
    "        x = x.flatten()\n",
    "        print(x.shape)\n",
    "        x = self._fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6815adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fctest = ResnetFC(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2b30169b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([129, 4687])\n"
     ]
    }
   ],
   "source": [
    "test_input = dataset.__getitem__(10)[0]\n",
    "print(test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d3d4b299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 129, 4687])\n",
      "torch.Size([1, 3, 129, 4687])\n",
      "torch.Size([1505280])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3626,  0.2002,  0.4983, -0.0624, -0.0184, -0.0807,  0.5689],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test an input\n",
    "test_input = dataset.__getitem__(10)[0]\n",
    "# test_input = torch.rand(1, 129, 4687)\n",
    "\n",
    "\n",
    "test_input = test_input.unsqueeze(axis=0)\n",
    "print(test_input.shape)\n",
    "fctest.forward(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5fef9683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 25,557,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.56\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 384.62\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "fctest.resnetfeats.cuda()\n",
    "FULLRES = models.resnet50(pretrained=True)\n",
    "FULLRES = FULLRES.cuda()\n",
    "summary(FULLRES, (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eb190f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False), Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "), AdaptiveAvgPool2d(output_size=(1, 1)), Linear(in_features=2048, out_features=1000, bias=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(FULLRES.children()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057fdafd",
   "metadata": {},
   "source": [
    "### Kfold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c1f7ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_functions import runkfoldcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67796ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration options\n",
    "k_folds = 2\n",
    "\n",
    "batch_size = 8 # 128\n",
    "num_classes = 7\n",
    "learning_rate = 0.01\n",
    "num_epochs = 1 # 0\n",
    "momentum = 0.95\n",
    "l2reg = 1e-4\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ece73702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Starting epoch 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 4.65 GiB (GPU 0; 23.65 GiB total capacity; 11.67 GiB already allocated; 2.77 GiB free; 11.69 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrunkfoldcv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfctest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_folds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2reg\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36mrunkfoldcv\u001b[0;34m(model, dataset, device, k_folds, batch_size, learning_rate, num_epochs, momentum, l2reg)\u001b[0m\n\u001b[1;32m     61\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Perform forward pass\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Compute loss            \u001b[39;00m\n\u001b[1;32m     69\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36mResnetFC.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#         batch_size ,_,_ =x.shape\u001b[39;00m\n\u001b[1;32m     13\u001b[0m         \n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# replicate the image to have 3 channels\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fc(x)\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/torchvision/models/resnet.py:283\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/torchvision/models/resnet.py:267\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;66;03m# See note [TorchScript super()]\u001b[39;00m\n\u001b[1;32m    266\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[0;32m--> 267\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m    269\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/torch/nn/functional.py:2421\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2419\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2422\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2423\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 4.65 GiB (GPU 0; 23.65 GiB total capacity; 11.67 GiB already allocated; 2.77 GiB free; 11.69 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "runkfoldcv(fctest, dataset, device, k_folds, batch_size, learning_rate, num_epochs, momentum, l2reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef036d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
