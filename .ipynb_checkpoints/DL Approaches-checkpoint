{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d4e062b",
   "metadata": {},
   "source": [
    "## Deep Learning Approaches for RF-based detection & classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df87784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "# import the torch packages\n",
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LogSoftmax\n",
    "from torch import flatten\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm\n",
    "\n",
    "# import custom functions\n",
    "from helper_functions import *\n",
    "from latency_helpers import *\n",
    "from loading_functions import *\n",
    "\n",
    "from Torch_Models import *\n",
    "\n",
    "# from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a4835a",
   "metadata": {},
   "source": [
    "### Load Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7710a0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Name:  ../Features/IMG_PSD_1024_20/\n"
     ]
    }
   ],
   "source": [
    "feat_folder = '../Features/'\n",
    "feat_name = 'PSD'\n",
    "seg_len = 20\n",
    "n_per_seg = 1024\n",
    "interferences = ['WIFI','CLEAN','BLUE','BOTH']\n",
    "output_name = 'drones'\n",
    "feat_format = 'IMG'\n",
    "\n",
    "dataset = DroneDetectTorch(feat_folder, feat_name, seg_len, n_per_seg, feat_format,\n",
    "                                output_name, interferences)\n",
    "\n",
    "# dataset = load_dronedetect_data(feat_folder, feat_name, seg_len, n_per_seg, feat_format,\n",
    "#                                 output_name, interferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b732f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size 38978\n",
      "shape of each item torch.Size([224, 224, 3])\n"
     ]
    }
   ],
   "source": [
    "print('dataset size', len(dataset))\n",
    "print('shape of each item', dataset.__getitem__(12)[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4bf51c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = dataset.__getitem__(4)[0]\n",
    "plt.imshow(d)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ad3ec6",
   "metadata": {},
   "source": [
    "## VGG16 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3fd24d89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16()\n",
    "# summary(vgg16, (3,224,224))\n",
    "\n",
    "modules=list(vgg16.children())[:-1]\n",
    "vggmodel=nn.Sequential(*modules)\n",
    "\n",
    "for p in vggmodel.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81a79389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0196, 0.0182,  ..., 0.0562, 0.0534, 0.0152])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test one input\n",
    "d = dataset.__getitem__(0)\n",
    "inarr = d[0]\n",
    "inarr = torch.moveaxis(inarr, 2, 0)\n",
    "# print(inarr.shape)\n",
    "# postmove = inarr[0]\n",
    "# print(premove==postmove) # confirm it is the same channel\n",
    "\n",
    "# WHEN using single channel array format\n",
    "# inputr = inarr.repeat(1,3,1,1)\n",
    "# inputr = inputr.to(device)\n",
    "out = vggmodel(inarr)\n",
    "\n",
    "# reshape the output\n",
    "out.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85a4b583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 36778/36778 [02:07<00:00, 288.79it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "vggmodel = vggmodel.to(device) #set model to device\n",
    "\n",
    "Vgg_Feats = []\n",
    "Vgg_y_num = [] # numerical values for y\n",
    "for n in tqdm(range(len(dataset))):\n",
    "    d = dataset.__getitem__(n)\n",
    "    inarr = d[0]\n",
    "#     inputr = inarr.repeat(1,3,1,1)  # repeat to have 3 channels of the same info\n",
    "    inputr = torch.moveaxis(inarr, 2, 0) # move axis to have channels come first\n",
    "    inputr = inputr.to(device)\n",
    "    out = vggmodel(inputr)\n",
    "    \n",
    "    Vgg_Feats.append(out.cpu().numpy().flatten())\n",
    "    Vgg_y_num.append(np.array(d[1]))\n",
    "\n",
    "Vgg_Feats = np.array(Vgg_Feats)\n",
    "Vgg_y_num = np.array(Vgg_y_num)\n",
    "\n",
    "# flatten the middle dimension\n",
    "Vgg_Feats = Vgg_Feats.reshape(Vgg_Feats.shape[0], Vgg_Feats.shape[-1])\n",
    "# invert labels back to categorical\n",
    "# vgg_y_cat = dataset.le.inverse_transform(vgg_y.astype(np.int64))\n",
    "Vgg_y_cat = np.array([dataset.idx_to_class[i] for i in Vgg_y_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4da21074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save VGG features\n",
    "# vgg_save = {'feats': vgg_feats, 'y_cat':vgg_y_cat, 'y':vgg_y}\n",
    "# file_name = 'transfer_learning_feats/VggFeats_'+str(seg_len)+'_'+str(n_per_seg)+'correct_psd_img'\n",
    "# np.save(file_name, vgg_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e445e2e",
   "metadata": {},
   "source": [
    "## Resnet Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "47b6d844",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transfer learning from Resnet50 & Apply Logistic Regression (Swinney paper)\n",
    "\n",
    "# use pretrained resnet feature and just keep up to the last layer\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "modules=list(resnet50.children())[:-1]\n",
    "resnet50=nn.Sequential(*modules)\n",
    "for p in resnet50.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "440b23cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test resnet\n",
    "# input = torch.randn(1,1,30,300)\n",
    "d = dataset.__getitem__(0)\n",
    "inarr = d[0]\n",
    "resnet50(inarr).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c5a73489",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ResNet_Feats = []\n",
    "y_num = []\n",
    "for n in range(len(dataset)):\n",
    "    d = dataset.__getitem__(n)\n",
    "    inarr = d[0]\n",
    "    inputr = torch.moveaxis(inarr, 2, 0) # move axis to have channels come first\n",
    "    inputr = inputr.to(device)\n",
    "    \n",
    "    out = resnet50(inputr)\n",
    "    ResNet_Feats.append(np.array(out))\n",
    "    y_num.append(np.array(d[1]))\n",
    "\n",
    "ResNet_Feats = np.array(ResNet_Feats)\n",
    "y_num = np.array(y_num)\n",
    "\n",
    "# flatten the middle dimension\n",
    "ResNet_Feats = resnet_feats.reshape(ResNet_Feats.shape[0], ResNet_Feats.shape[-1])\n",
    "# invert labels back to categorical\n",
    "# y_cat = dataset.le.inverse_transform(y_num.astype(np.int64))\n",
    "resnet_y_cat = np.array([dataset.idx_to_class[i] for i in ResNet_Feats])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be6ec2",
   "metadata": {},
   "source": [
    "### Run Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b769a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Input Features: (n sample x n feats): (36778, 25088)\n"
     ]
    }
   ],
   "source": [
    "Xs_feat = Vgg_Feats # which features to use for logit reg\n",
    "y_cat = Vgg_y_cat\n",
    "print('Shape of Input Features: (n sample x n feats):', Xs_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d3eea904",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cs: [0.01, 0.1, 1, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [1:01:27, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     scaler \u001b[38;5;241m=\u001b[39m preprocessing\u001b[38;5;241m.\u001b[39mStandardScaler()\u001b[38;5;241m.\u001b[39mfit(Xs_feat[train_ix])\n\u001b[1;32m     24\u001b[0m     X_train_scale \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(Xs_feat[train_ix])\n\u001b[0;32m---> 26\u001b[0m     \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_cat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_ix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#     print(clf.best_params_)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#     best_params_ls.append(clf.best_params_)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# predict on the test data\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     X_test_scale \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(Xs_feat[test_ix])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1233\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1231\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1233\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1258\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/joblib/parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:436\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    432\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C\n\u001b[1;32m    433\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[1;32m    434\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[1;32m    435\u001b[0m ]\n\u001b[0;32m--> 436\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miprint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[1;32m    445\u001b[0m     solver,\n\u001b[1;32m    446\u001b[0m     opt_res,\n\u001b[1;32m    447\u001b[0m     max_iter,\n\u001b[1;32m    448\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[1;32m    449\u001b[0m )\n\u001b[1;32m    450\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/scipy/optimize/_minimize.py:692\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    689\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    690\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 692\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    695\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    696\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py:362\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    356\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    365\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 285\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/scipy/optimize/_optimize.py:76\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;124;03m\"\"\" returns the the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/scipy/optimize/_optimize.py:70\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 70\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/envs/main/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py:207\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads)\u001b[0m\n\u001b[1;32m    205\u001b[0m grad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((n_classes, n_dof), dtype\u001b[38;5;241m=\u001b[39mweights\u001b[38;5;241m.\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    206\u001b[0m \u001b[38;5;66;03m# grad_per_sample.shape = (n_samples, n_classes)\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m grad[:, :n_features] \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_per_sample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m \u001b[38;5;241m+\u001b[39m l2_reg_strength \u001b[38;5;241m*\u001b[39m weights\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept:\n\u001b[1;32m    209\u001b[0m     grad[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m grad_per_sample\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# split data into K-fold\n",
    "k_fold = 5\n",
    "cv = KFold(n_splits=k_fold, random_state=1, shuffle=True)\n",
    "\n",
    "# model parameters\n",
    "Cs=list(map(lambda x:pow(10,x),range(-2,2,1)))\n",
    "print('Cs:', Cs)\n",
    "\n",
    "best_params_ls = []\n",
    "acc_ls = []\n",
    "f1_ls = []\n",
    "runt_ls = []\n",
    "\n",
    "parameters = {'C':Cs}\n",
    "\n",
    "for train_ix, test_ix in tqdm(cv.split(Xs_feat)):\n",
    "    \n",
    "    # find the optimal hypber parameters\n",
    "    lr = LogisticRegression(solver='saga')\n",
    "#     clf = GridSearchCV(lr, parameters, n_jobs=1) # gridsearch cv\n",
    "    clf = LogisticRegression(C =1.0, max_iter=5000, class_weight = 'balanced',n_jobs=1) # fixed parameter\n",
    "    \n",
    "    scaler = preprocessing.StandardScaler().fit(Xs_feat[train_ix])\n",
    "    X_train_scale = scaler.transform(Xs_feat[train_ix])\n",
    "    \n",
    "    clf.fit(X_train_scale, y_cat[train_ix])\n",
    "    \n",
    "#     print(clf.best_params_)\n",
    "#     best_params_ls.append(clf.best_params_)\n",
    "    \n",
    "    # predict on the test data\n",
    "    X_test_scale = scaler.transform(Xs_feat[test_ix])\n",
    "    y_pred, runtimes = atomic_benchmark_estimator(clf, X_test_scale, output_type= '<U3', \n",
    "                                                  verbose=False)\n",
    "    runt_ls.append(np.mean(runtimes))\n",
    "    \n",
    "    acc = accuracy_score(y_cat[test_ix], y_pred)\n",
    "    f1 = f1_score(y_cat[test_ix], y_pred, average='weighted')\n",
    "    print('Accuracy: {:.3},\\t F1: {:.3}'.format(acc,f1))\n",
    "    acc_ls.append(acc)\n",
    "    f1_ls.append(f1)\n",
    "    \n",
    "out_msg = 'Net+LR: average test acc: {:.2}, F1: {:.2}, Run-time: {:.2}ms'.format(np.mean(acc_ls), np.mean(f1_ls), np.mean(runt_ls)*1e3)\n",
    "print(out_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7017a2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe2c7e6",
   "metadata": {},
   "source": [
    "## Run kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ce4b401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# neigh = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfedc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of neighbours: [100]\n"
     ]
    }
   ],
   "source": [
    "## Fixed parameter kNN\n",
    "k_fold = 5\n",
    "cv = KFold(n_splits=k_fold, random_state=10, shuffle=True)\n",
    "\n",
    "# Ns=list(range(2,100,20))\n",
    "# Ns = [100]\n",
    "parameters = {'n_neighbors':Ns}\n",
    "print('list of neighbours:', Ns)\n",
    "\n",
    "Xs_arr = Vgg_Feats\n",
    "y_arr = Vgg_y_cat\n",
    "\n",
    "best_params_ls = []\n",
    "score_ls = []\n",
    "f1_ls = []\n",
    "\n",
    "for train_ix, test_ix in cv.split(Xs_arr):\n",
    "    # scale data\n",
    "    scaler = preprocessing.StandardScaler().fit(Xs_arr[train_ix])\n",
    "    X_train_scale = scaler.transform(Xs_arr[train_ix])\n",
    "    \n",
    "    # find the optimal hypber parameters\n",
    "    clf = KNeighborsClassifier(n_neighbors=5)\n",
    "#     clf = GridSearchCV(neigh, parameters, n_jobs=1)\n",
    "    clf.fit(X_train_scale, y_arr[train_ix])\n",
    "#     print(clf.best_parameters)\n",
    "    \n",
    "    # predict on the test data\n",
    "    X_test_scale = scaler.transform(Xs_arr[test_ix])\n",
    "#     y_pred = clf.predict(X_test_scale)\n",
    "    y_pred, runtimes = atomic_benchmark_estimator(clf, X_test_scale, output_type= '<U3', \n",
    "                                                  verbose=False)\n",
    "    acc = accuracy_score(y_arr[test_ix], y_pred)\n",
    "    f1 = f1_score(y_arr[test_ix], y_pred, average='weighted')\n",
    "    f1_ls.append(f1)\n",
    "    print('Accuracy: {:.3},\\t F1: {:.3}'.format(acc,f1))\n",
    "    score_ls.append(acc)\n",
    "    \n",
    "print('VGG feats+kNN K-fold average test score:', np.mean(score_ls))\n",
    "print('VGG feats+kNN K-fold average test F1:', np.mean(f1_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80076188",
   "metadata": {},
   "source": [
    "## Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8392adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model in Torch_Models\n",
    "# class VGGFC(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(VGGFC,self).__init__()\n",
    "#         self.num_classes = num_classes\n",
    "#         self.vggfull = models.vgg16(pretrained=True)\n",
    "#         modules=list(self.vggfull.children())[:-1] # remove the fully connected layer & adaptive averaging\n",
    "#         self.vggfeats=nn.Sequential(*modules)\n",
    "        \n",
    "#         for param in self.vggfeats.parameters():\n",
    "#             param.requires_grad_(False)\n",
    "        \n",
    "#         self._fc = nn.Linear(25088, num_classes)\n",
    "#     def forward(self, x):\n",
    "#         if len(x.shape)==4:\n",
    "#             x = torch.moveaxis(x,-1, 1)\n",
    "#         else:\n",
    "#             x = torch.moveaxis(x, -1, 0)\n",
    "#         x = self.vggfeats(x)\n",
    "# #         print(x.shape)\n",
    "#         x = x.reshape(-1,25088)\n",
    "#         x = self._fc(x)\n",
    "        \n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1762c320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ResNetFC(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(ResNetFC,self).__init__()\n",
    "#         self.num_classes = num_classes\n",
    "#         self.resnetfull = models.resnet50(pretrained=True)\n",
    "#         modules=list(self.resnetfull.children())[:-2] # remove the fully connected layer & adaptive averaging\n",
    "#         self.resnetfeats=nn.Sequential(*modules)\n",
    "        \n",
    "#         for param in self.resnetfeats.parameters():\n",
    "#             param.requires_grad_(False)\n",
    "        \n",
    "#         self._fc = nn.Linear(100352, num_classes)\n",
    "#     def forward(self, x):\n",
    "#         if len(x.shape)==4:\n",
    "#             x = torch.moveaxis(x,-1, 1)\n",
    "#         else:\n",
    "#             x = torch.moveaxis(x, -1, 0)\n",
    "#         x = self.resnetfeats(x)\n",
    "#         x = x.reshape(-1,100352)\n",
    "#         x = self._fc(x)\n",
    "        \n",
    "#         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057fdafd",
   "metadata": {},
   "source": [
    "### Kfold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c1f7ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_functions import runkfoldcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f67796ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration options\n",
    "k_folds = 5\n",
    "\n",
    "batch_size = 128 # 128\n",
    "num_classes = 7\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10 # 0\n",
    "momentum = 0.95\n",
    "l2reg = 1e-4\n",
    "\n",
    "Model = VGGFC(num_classes)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece73702",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "    Loss after mini-batch    50: 1.21579\n",
      "    Loss after mini-batch   100: 0.90260\n",
      "    Loss after mini-batch   150: 0.81941\n",
      "    Loss after mini-batch   200: 0.76867\n",
      "Starting epoch 2\n",
      "    Loss after mini-batch    50: 0.68741\n",
      "    Loss after mini-batch   100: 0.67422\n",
      "    Loss after mini-batch   150: 0.63289\n",
      "    Loss after mini-batch   200: 0.63230\n",
      "Starting epoch 3\n",
      "    Loss after mini-batch    50: 0.59855\n",
      "    Loss after mini-batch   100: 0.56032\n",
      "    Loss after mini-batch   150: 0.57207\n",
      "    Loss after mini-batch   200: 0.55438\n",
      "Starting epoch 4\n",
      "    Loss after mini-batch    50: 0.52294\n",
      "    Loss after mini-batch   100: 0.51635\n",
      "    Loss after mini-batch   150: 0.52538\n",
      "    Loss after mini-batch   200: 0.53060\n",
      "Starting epoch 5\n",
      "    Loss after mini-batch    50: 0.48562\n",
      "    Loss after mini-batch   100: 0.49572\n",
      "    Loss after mini-batch   150: 0.47895\n",
      "    Loss after mini-batch   200: 0.47642\n",
      "Starting epoch 6\n",
      "    Loss after mini-batch    50: 0.46480\n",
      "    Loss after mini-batch   100: 0.46207\n",
      "    Loss after mini-batch   150: 0.45192\n",
      "    Loss after mini-batch   200: 0.45446\n",
      "Starting epoch 7\n",
      "    Loss after mini-batch    50: 0.43126\n",
      "    Loss after mini-batch   100: 0.44767\n",
      "    Loss after mini-batch   150: 0.44708\n",
      "    Loss after mini-batch   200: 0.42351\n",
      "Starting epoch 8\n",
      "    Loss after mini-batch    50: 0.41462\n",
      "    Loss after mini-batch   100: 0.41695\n",
      "    Loss after mini-batch   150: 0.41302\n",
      "    Loss after mini-batch   200: 0.41768\n",
      "Starting epoch 9\n",
      "    Loss after mini-batch    50: 0.40326\n",
      "    Loss after mini-batch   100: 0.40255\n",
      "    Loss after mini-batch   150: 0.39336\n",
      "    Loss after mini-batch   200: 0.40323\n",
      "Starting epoch 10\n",
      "    Loss after mini-batch    50: 0.38849\n",
      "    Loss after mini-batch   100: 0.39041\n",
      "    Loss after mini-batch   150: 0.38358\n",
      "    Loss after mini-batch   200: 0.37186\n",
      "Starting testing\n",
      "----------------\n",
      "Accuracy for fold 0: 84.03 %\n",
      "F1 for fold 0: 0.84 \n",
      "Runtime for fold 0: 0.0057 s\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "    Loss after mini-batch    50: 0.39370\n",
      "    Loss after mini-batch   100: 0.37057\n",
      "    Loss after mini-batch   150: 0.39254\n",
      "    Loss after mini-batch   200: 0.38610\n",
      "Starting epoch 2\n",
      "    Loss after mini-batch    50: 0.36548\n",
      "    Loss after mini-batch   100: 0.36645\n",
      "    Loss after mini-batch   150: 0.37203\n",
      "    Loss after mini-batch   200: 0.37794\n",
      "Starting epoch 3\n",
      "    Loss after mini-batch    50: 0.35987\n",
      "    Loss after mini-batch   100: 0.34972\n",
      "    Loss after mini-batch   150: 0.35387\n",
      "    Loss after mini-batch   200: 0.36531\n",
      "Starting epoch 4\n",
      "    Loss after mini-batch    50: 0.35373\n",
      "    Loss after mini-batch   100: 0.35434\n",
      "    Loss after mini-batch   150: 0.34332\n",
      "    Loss after mini-batch   200: 0.34643\n",
      "Starting epoch 5\n",
      "    Loss after mini-batch    50: 0.33238\n",
      "    Loss after mini-batch   100: 0.33943\n",
      "    Loss after mini-batch   150: 0.33284\n",
      "    Loss after mini-batch   200: 0.33989\n",
      "Starting epoch 6\n",
      "    Loss after mini-batch    50: 0.32948\n",
      "    Loss after mini-batch   100: 0.33785\n",
      "    Loss after mini-batch   150: 0.33678\n",
      "    Loss after mini-batch   200: 0.31149\n",
      "Starting epoch 7\n"
     ]
    }
   ],
   "source": [
    "trainedModel, res_acc, res_f1, res_runtime = runkfoldcv(Model, dataset, device, k_folds, batch_size, learning_rate, num_epochs, momentum, l2reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3dcfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26916480",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_acc, res_f1, res_runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cec40d",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8ef036d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as: PSD_ResNetFC_1024_20\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "model_type = 'ResNetFC'\n",
    "model_name = model_type+'_'+str(feat_name)+'_'+str(n_per_seg)+'_'+str(seg_len)\n",
    "model_path = '../saved_models/'\n",
    "trainedModel = trainedModel.cpu()\n",
    "torch.save(trainedModel, model_path+model_name)\n",
    "print('Model saved as:', model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "195f509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test reload\n",
    "# m2 = torch.load(model_path+model_name)\n",
    "# in2 = dataset.__getitem__(0)[0]\n",
    "# out = m2(in2)\n",
    "# _,pred = torch.max(out,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152ae3e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
